{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative AI with *ktrain*\n",
    "\n",
    "*ktrain* supports a Generative AI that is currently based on an instruction-fine-tuned version of GPT-J. Think of it as a lightweight version of ChatGPT that can be run locally on your own machine. As a smaller model, it will not perform as well as GPT-4, ChatGPT, etc.  However, since it does not communicate with external APIs like OpenAI, it can be used with non-public data.\n",
    "\n",
    "The model requires a GPU with at least 16GB of GPU memory or VRAM.  If you have less than this, you can use a CPU (provided it has at least 16GB of RAM), but output will be generated **very** slowly.  We will use a CPU in this example, but you should supply `device=cuda` if you have a GPU with at least 16GB of GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ktrain.text.generative_ai import GenerativeAI\n",
    "model = GenerativeAI(device='cpu') # use device='cuda' if you have a good GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this model is instruction-fine-tuned, you should supply prompts in the form of instructions of what you want the model to do for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grammar and Spelling Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Zero-shot* prompting is when you do not provide any examples for how to complete the instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not want to go.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Correct spelling and grammar from the following text.\n",
    "I do not wan to go\n",
    "\"\"\"\n",
    "print(model.execute(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model returned the right answer.  If the model answers **incorrectly**, you can provide some illustrative examples to help it perform its assigned task (known as *few-shot* prompting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not want to go.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Correct the grammar and spelling in the supplied sentences.  Here are some examples.\n",
    "[Sentence]:\n",
    "I love goin to the beach.\n",
    "[Correction]:\n",
    "I love going to the beach.\n",
    "###\n",
    "[Sentence]:\n",
    "Let me hav it!\n",
    "[Correction]:\n",
    "Let me have it!\n",
    "###\n",
    "[Sentence]:\n",
    "It have too many drawbacks.\n",
    "[Correction]:\n",
    "It has too many drawbacks.\n",
    "###\n",
    "[Sentence]:\n",
    "I do not wan to go\n",
    "[Correction]:\"\"\"\n",
    "print(model.execute(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This default model for Generative AI is small enough to run on a single GPU/CPU, but is also sensitive to the structure of the prompt and where newlines are inserted.  You can use the examples in this notebook for guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Tell me whether the following sentence is positive,  negative, or neutral in sentiment.\n",
    "The reactivity of  your team has been amazing, thanks!\"\"\"\n",
    "print(model.execute(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Name]: David Melvin\n",
      "[Position]: Senior Adviser of CITIC CLSA\n",
      "[Company]: CITIC CLSA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Extract the Name, Position, and Company from the following sentences.  Here are some examples.\n",
    "[Text]: Fred is a serial entrepreneur. Co-founder and CEO of Platform.sh, he previously co-founded Commerce Guys, a leading Drupal ecommerce provider. His mission is to guarantee that as we continue on an ambitious journey to profoundly transform how cloud computing is used and perceived, we keep our feet well on the ground continuing the rapid growth we have enjoyed up until now. \n",
    "[Name]: Fred\n",
    "[Position]: Co-founder and CEO\n",
    "[Company]: Platform.sh\n",
    "###\n",
    "[Text]: Microsoft (the word being a portmanteau of \"microcomputer software\") was founded by Bill Gates on April 4, 1975, to develop and sell BASIC interpreters for the Altair 8800. Steve Ballmer replaced Gates as CEO in 2000, and later envisioned a \"devices and services\" strategy.\n",
    "[Name]:  Steve Ballmer\n",
    "[Position]: CEO\n",
    "[Company]: Microsoft\n",
    "###\n",
    "[Text]: Franck Riboud was born on 7 November 1955 in Lyon. He is the son of Antoine Riboud, the previous CEO, who transformed the former European glassmaker BSN Group into a leading player in the food industry. He is the CEO at Danone.\n",
    "[Name]:  Franck Riboud\n",
    "[Position]: CEO\n",
    "[Company]: Danone\n",
    "###\n",
    "[Text]: David Melvin is an investment and financial services professional at CITIC CLSA with over 30 yearsâ€™ experience in investment banking and private equity. He is currently a Senior Adviser of CITIC CLSA.\n",
    "\"\"\"\n",
    "print(model.execute(prompt))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Gandolfini\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Extract the names of people in the supplied sentences. Here is an example:\n",
    "Sentence:Paul Newman is a great actor.\n",
    "People:\n",
    "Paul Newman\n",
    "Sentence:\n",
    "I like James Gandolfini's acting.\n",
    "People:\"\"\"\n",
    "print(model.execute(prompt))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paraphrasing\n",
    "**Pro-Tip**: Do not embed any newlines in the text you're paraphrasing or it will confuse the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After a 20-year war, Trump and Biden's decisions to withdraw American troops from Afghanistan resulted in Kabul falling to the Taliban without resistance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Paraphrase the following text. \n",
    "After a war lasting 20 years, following the decision taken first by President Trump and then by President Biden to withdraw American troops, Kabul, the capital of Afghanistan, fell within a few hours to the Taliban, without resistance.\"\"\"\n",
    "print(model.execute(prompt))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a GPU plan is recommended for GPT-J.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Answer the Question based on the Context.  Here are some examples.\n",
    "[Context]: \n",
    "NLP Cloud was founded in 2021 when the team realized there was no easy way to reliably leverage Natural Language Processing in production.\n",
    "Question: When was NLP Cloud founded?\n",
    "[Answer]: \n",
    "2021\n",
    "###\n",
    "[Context]:\n",
    "NLP Cloud developed their API by mid-2020 and they added many pre-trained open-source models since then.\n",
    "[Question]: \n",
    "What did NLP Cloud develop?\n",
    "[Answer]:\n",
    "API\n",
    "###\n",
    "[Context]:\n",
    "All plans can be stopped anytime. You only pay for the time you used the service. In case of a downgrade, you will get a discount on your next invoice.\n",
    "[Question]:\n",
    "When can plans be stopped?\n",
    "[Answer]:\n",
    "Anytime\n",
    "###\n",
    "[Context]:\n",
    "The main challenge with GPT-J is memory consumption. Using a GPU plan is recommended.\n",
    "[Question]:\n",
    "Which plan is recommended for GPT-J?\n",
    "Answer:\"\"\"\n",
    "print(model.execute(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Product Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A t-shirt for men, with a message of strength and power at $39.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Generate a Sentence from the Keywords. Here are some examples.\n",
    "[Keywords]:\n",
    "shoes, women, $59\n",
    "[Sentence]:\n",
    "Beautiful shoes for women at the price of $59.\n",
    "###\n",
    "[Keywords]:\n",
    "trousers, men, $69\n",
    "[Sentence]:\n",
    "Modern trousers for men, for $69 only.\n",
    "###\n",
    "[Keywords]:\n",
    "gloves, winter, $19\n",
    "[Sentence]: \n",
    "Amazingly hot gloves for cold winters, at $19.\n",
    "###\n",
    "[Keywords]: \n",
    "t-shirt, men, $39\n",
    "[Sentence]:\"\"\"\n",
    "print(model.execute(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the words \"strength\" and \"power\" were used in this description of this men's shirt.  We call attention to this, as output of this model may potentially be biased.  Such bias may reveal itself more in tasks that are more generative and less extractive in nature like this and the next examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a young scientist named Harold who was working on a grand experiment to control time. He had spent years collecting data and researching the past, in hopes of one day rewriting history. But one day, he stumbled upon a mysterious paper that suggested his experiment was not just possible, but also likely to happen. Harold was determined to find out the truth, and so he decided to embark on a daring adventure full of excitement and possibility. What will happen when Harold attempts to alter the future? Will the changes be for the better or the worse? Time will tell what destiny awaits beneath the stars!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about time travel.\"\n",
    "print(model.execute(prompt))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate change is real and not a distant threat--it's happening now and will affect everyone.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Generate a tweet based on the supplied Keyword. Here are some examples.\n",
    "[Keyword]:\n",
    "markets\n",
    "[Tweet]:\n",
    "Take feedback from nature and markets, not from people\n",
    "###\n",
    "[Keyword]:\n",
    "children\n",
    "[Tweet]:\n",
    "Maybe we die so we can come back as children.\n",
    "###\n",
    "[Keyword]:\n",
    "startups\n",
    "[Tweet]: \n",
    "Startups should not worry about how to put out fires, they should worry about how to start them.\n",
    "###\n",
    "[Keyword]: \n",
    "climate change\n",
    "[Tweet]:\"\"\"\n",
    "print(model.execute(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Comments\n",
    "The `execute` method accepts parameters that are fed directly to the generative model.  You can change them as necessary.  The default value for `max_new_tokens` (the upper limt on generated answers) has been set to 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
