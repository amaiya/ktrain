<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ktrain.text.eda API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ktrain.text.eda</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from ..imports import *
from .. import utils as U
from . import textutils as TU
from . import preprocessor as pp
import time

class TopicModel():


    def __init__(self,texts=None, n_topics=None, n_features=10000, 
                 min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
                 model_type=&#39;lda&#39;,
                 lda_max_iter=5, lda_mode=&#39;online&#39;,
                 token_pattern=None, verbose=1,
                 hyperparam_kwargs=None
    ):
        &#34;&#34;&#34;
        Fits a topic model to documents in &lt;texts&gt;.
        Example:
            tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                            n_features=1000, min_df=2, max_df=0.95)
        Args:
            texts (list of str): list of texts
            n_topics (int): number of topics.
                            If None, n_topics = min{400, sqrt[# documents/2]})
            n_features (int):  maximum words to consider
            max_df (float): words in more than max_df proportion of docs discarded
            stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                      a list of stop words to ignore
            model_type(str): type of topic model to fit. One of {&#39;lda&#39;, &#39;nmf&#39;}.  Default:&#39;lda&#39;
            lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                                If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                                Ignored if model_type != &#39;lda&#39;
            lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored if model_type !=&#39;lda&#39;
            token_pattern(str): regex pattern to use to tokenize documents. 
            verbose(bool): verbosity

        &#34;&#34;&#34;
        self.verbose=verbose

        # estimate n_topics
        if n_topics is None:
            if texts is None:
                raise ValueError(&#39;If n_topics is None, texts must be supplied&#39;)
            estimated = max(1, int(math.floor(math.sqrt(len(texts) / 2))))
            n_topics = min(400, estimated)
            print(&#39;n_topics automatically set to %s&#39; % (n_topics))

        # train model
        if texts is not None:
            (model, vectorizer) = self.train(texts, model_type=model_type,
                                             n_topics=n_topics, n_features=n_features,
                                             min_df = min_df, max_df = max_df, 
                                             stop_words=stop_words,
                                             lda_max_iter=lda_max_iter, lda_mode=lda_mode,
                                             token_pattern=token_pattern,
                                             hyperparam_kwargs=hyperparam_kwargs)
        else:
            vectorizer = None
            model = None



        # save model and vectorizer and hyperparameter settings
        self.vectorizer = vectorizer
        self.model = model
        self.n_topics = n_topics
        self.n_features = n_features
        if verbose: print(&#39;done.&#39;)

        # these variables are set by self.build():
        self.topic_dict = None
        self.doc_topics = None
        self.bool_array = None

        self.scorer = None       # set by self.train_scorer()
        self.recommender = None  # set by self.train_recommender()
        return


    def train(self,texts, model_type=&#39;lda&#39;, n_topics=None, n_features=10000,
              min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
              lda_max_iter=5, lda_mode=&#39;online&#39;,
              token_pattern=None, hyperparam_kwargs=None):
        &#34;&#34;&#34;
        Fits a topic model to documents in &lt;texts&gt;.
        Example:
            tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                            n_features=1000, min_df=2, max_df=0.95)
        Args:
            texts (list of str): list of texts
            n_topics (int): number of topics.
                            If None, n_topics = min{400, sqrt[# documents/2]})
            n_features (int):  maximum words to consider
            max_df (float): words in more than max_df proportion of docs discarded
            stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                      a list of stop words to ignore
            lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                                If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                                Ignored if model_type != &#39;lda&#39;
            lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored of model_type !=&#39;lda&#39;
            token_pattern(str): regex pattern to use to tokenize documents. 
                                If None, a default tokenizer will be used
            hyperparam_kwargs(dict): hyperparameters for LDA/NMF
                                     Keys in this dict can be any of the following:
                                         alpha: alpha for LDA  default: 5./n_topics
                                         beta: beta for LDA.  default:0.01
                                         nmf_alpha: alpha for NMF.  default:0
                                         l1_ratio: l1_ratio for NMF. default: 0
                                         ngram_range:  whether to consider bigrams, trigrams. default: (1,1) 
                                    
        Returns:
            tuple: (model, vectorizer)
        &#34;&#34;&#34;
        if hyperparam_kwargs is None:
            hyperparam_kwargs = {}
        alpha = hyperparam_kwargs.get(&#39;alpha&#39;, 5.0 / n_topics)
        beta = hyperparam_kwargs.get(&#39;beta&#39;, 0.01)
        nmf_alpha = hyperparam_kwargs.get(&#39;nmf_alpha&#39;, 0)
        l1_ratio = hyperparam_kwargs.get(&#39;l1_ratio&#39;, 0)
        ngram_range = hyperparam_kwargs.get(&#39;ngram_range&#39;, (1,1))

        # adjust defaults based on language detected
        if texts is not None:
            lang = TU.detect_lang(texts)
            if lang != &#39;en&#39;:
                stopwords = None if stop_words==&#39;english&#39; else stop_words
                token_pattern = r&#39;(?u)\b\w+\b&#39; if token_pattern is None else token_pattern
            if pp.is_nospace_lang(lang):
                text_list = []
                for t in texts:
                    text_list.append(&#39; &#39;.join(jieba.cut(t, HMM=False)))
                texts = text_list
            if self.verbose: print(&#39;lang: %s&#39; % (lang))


        # preprocess texts
        if self.verbose: print(&#39;preprocessing texts...&#39;)
        if token_pattern is None: token_pattern = TU.DEFAULT_TOKEN_PATTERN
        #if token_pattern is None: token_pattern = r&#39;(?u)\b\w\w+\b&#39;
        vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,
                                 max_features=n_features, stop_words=stop_words,
                                 token_pattern=token_pattern, ngram_range=ngram_range)
        

        x_train = vectorizer.fit_transform(texts)

        # fit model

        if self.verbose: print(&#39;fitting model...&#39;)
        if model_type == &#39;lda&#39;:
            model = LatentDirichletAllocation(n_components=n_topics, max_iter=lda_max_iter,
                                              learning_method=lda_mode, learning_offset=50.,
                                              doc_topic_prior=alpha,
                                              topic_word_prior=beta,
                                              verbose=self.verbose, random_state=0)
        elif model_type == &#39;nmf&#39;:
            model = NMF(
                n_components=n_topics,
                max_iter=lda_max_iter,
                verbose=self.verbose,
                alpha=nmf_alpha,
                l1_ratio=l1_ratio,
                random_state=0)
        else:
            raise ValueError(&#34;unknown model type:&#34;, str(model_type))
        model.fit(x_train)

        # save model and vectorizer and hyperparameter settings
        return (model, vectorizer)


    @property
    def topics(self):
        &#34;&#34;&#34;
        convenience method/property
        &#34;&#34;&#34;
        return self.get_topics()


    def get_document_topic_distribution(self):
        &#34;&#34;&#34;
        Gets the document-topic distribution.
        Each row is a document and each column is a topic
        The output of this method is equivalent to invoking get_doctopics with no arguments.
        &#34;&#34;&#34;
        self._check_build()
        return self.doc_topics


    def get_sorted_docs(self, topic_id):
        &#34;&#34;&#34;
        Returns all docs sorted by relevance to &lt;topic_id&gt;.
        Unlike get_docs, this ranks documents by the supplied topic_id rather
        than the topic_id to which document is most relevant.
        &#34;&#34;&#34;
        docs = self.get_docs()
        d = {}
        for doc in docs: d[doc[&#39;doc_id&#39;]] = doc
        m = self.get_document_topic_distribution()
        doc_ids = (-m[:,topic_id]).argsort()
        return [d[doc_id] for doc_id in doc_ids]



    def get_word_weights(self, topic_id, n_words=100):
        &#34;&#34;&#34;
        Returns a list tuples of the form: (word, weight) for given topic_id.
        The weight can be interpreted as the number of times word was assigned to topic with given topic_id.
        REFERENCE: https://stackoverflow.com/a/48890889/13550699
        Args:
            topic_id(int): topic ID
            n_words=int): number of top words
        &#34;&#34;&#34;
        self._check_model()
        if topic_id+1 &gt; len(self.model.components_): 
            raise ValueError(&#39;topic_id must be less than %s&#39; % (len(self.model.components_)))
        feature_names = self.vectorizer.get_feature_names()
        word_probs = self.model.components_[topic_id]
        word_ids = [i for i in word_probs.argsort()[:-n_words - 1:-1]]
        words = [feature_names[i] for i in word_ids]
        probs = [word_probs[i] for i in word_ids]
        return list( zip(words, probs) )


    def get_topics(self, n_words=10, as_string=True):
        &#34;&#34;&#34;
        Returns a list of discovered topics
        Args:
            n_words(int): number of words to use in topic summary
            as_string(bool): If True, each summary is a space-delimited string instead of list of words
        &#34;&#34;&#34;
        self._check_model()
        feature_names = self.vectorizer.get_feature_names()
        topic_summaries = []
        for topic_idx, topic in enumerate(self.model.components_):
            summary = [feature_names[i] for i in topic.argsort()[:-n_words - 1:-1]]
            if as_string: summary = &#34; &#34;.join(summary)
            topic_summaries.append(summary)
        return topic_summaries


    def print_topics(self, n_words=10, show_counts=False):
        &#34;&#34;&#34;
        print topics
        n_words(int): number of words to describe each topic
        show_counts(bool): If True, print topics with document counts, where
                           the count is the number of documents with that topic as primary.
        &#34;&#34;&#34;
        topics = self.get_topics(n_words=n_words, as_string=True)
        if show_counts:
            self._check_build()
            topic_counts = sorted([ (k, topics[k], len(v)) for k,v in self.topic_dict.items()], 
                                    key=lambda kv:kv[-1], reverse=True)
            for (idx, topic, count) in topic_counts:
                print(&#34;topic:%s | count:%s | %s&#34; %(idx, count, topic))
        else:
            for i, t in enumerate(topics):
                print(&#39;topic %s | %s&#39; % (i, t))
        return


    def build(self, texts, threshold=None):
        &#34;&#34;&#34;
        Builds the document-topic distribution showing the topic probability distirbution
        for each document in &lt;texts&gt; with respect to the learned topic space.
        Args:
            texts (list of str): list of text documents
            threshold (float): If not None, documents with whose highest topic probability
                               is less than threshold are filtered out.
        &#34;&#34;&#34;
        doc_topics, bool_array = self.predict(texts, threshold=threshold)
        self.doc_topics = doc_topics
        self.bool_array = bool_array

        texts = [text for i, text in enumerate(texts) if bool_array[i]]
        self.topic_dict = self._rank_documents(texts, doc_topics=doc_topics)
        return


    def filter(self, lst):
        &#34;&#34;&#34;
        The build method may prune documents based on threshold.
        This method prunes other lists based on how build pruned documents.
        This is useful to filter lists containing metadata associated with documents
        for use with visualize_documents.
        Args:
            lst(list): a list of data
        Returns:
            list:  a filtered list of data based on how build filtered the documents
        &#34;&#34;&#34;
        if len(lst) != self.bool_array.shape[0]:
            raise ValueError(&#39;Length of lst is not consistent with the number of documents &#39; +
                             &#39;supplied to get_topic_model&#39;)
        arr = np.array(lst)
        return list(arr[self.bool_array])
                           

    
    def get_docs(self, topic_ids=[], doc_ids=[], rank=False):
        &#34;&#34;&#34;
        Returns document entries for supplied topic_ids.
        Documents returned are those whose primary topic is topic with given topic_id
        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
            rank(bool): If True, the list is sorted first by topic_id (ascending)
                        and then ty topic probability (descending).
                        Otherwise, list is sorted by doc_id (i.e., the order
                        of texts supplied to self.build (which is the order of self.doc_topics).

        Returns:
            list of dicts:  list of dicts with keys:
                            &#39;text&#39;: text of document
                            &#39;doc_id&#39;: ID of document
                            &#39;topic_proba&#39;: topic probability (or score)
                            &#39;topic_id&#39;: ID of topic
            
        &#34;&#34;&#34;
        self._check_build()
        if not topic_ids:
            topic_ids = list(range(self.n_topics))
        result_texts = []
        for topic_id in topic_ids:
            if topic_id not in self.topic_dict: continue
            texts = [{&#39;text&#39;:tup[0], &#39;doc_id&#39;:tup[1], &#39;topic_proba&#39;:tup[2], &#39;topic_id&#39;:topic_id} for tup in self.topic_dict[topic_id] 
                                                                                                     if not doc_ids or tup[1] in doc_ids]
            result_texts.extend(texts)
        if not rank:
            result_texts = sorted(result_texts, key=lambda x:x[&#39;doc_id&#39;])
        return result_texts


    def get_doctopics(self,  topic_ids=[], doc_ids=[]):
        &#34;&#34;&#34;
        Returns a topic probability distribution for documents
        with primary topic that is one of &lt;topic_ids&gt; and with doc_id in &lt;doc_ids&gt;.

        If no topic_ids or doc_ids are provided, then topic distributions for all documents
        are returned (which equivalent to the output of get_document_topic_distribution).

        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
        Returns:
            np.ndarray: Each row is the topic probability distribution of a document.
                        Array is sorted in the order returned by self.get_docs.
                        
        &#34;&#34;&#34;
        docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)
        return np.array([self.doc_topics[idx] for idx in [x[&#39;doc_id&#39;] for x in docs]])


    def get_texts(self,  topic_ids=[]):
        &#34;&#34;&#34;
        Returns texts for documents
        with primary topic that is one of &lt;topic_ids&gt;
        Args:
            topic_ids(list of ints): list of topic IDs
        Returns:
            list of str
        &#34;&#34;&#34;
        if not topic_ids: topic_ids = list(range(self.n_topics))
        docs = self.get_docs(topic_ids)
        return [x[0] for x in docs]



    def predict(self, texts, threshold=None, harden=False):
        &#34;&#34;&#34;
        Args:
            texts (list of str): list of texts
            threshold (float): If not None, documents with maximum topic scores
                                less than &lt;threshold&gt; are filtered out
            harden(bool): If True, each document is assigned to a single topic for which
                          it has the highest score
        Returns:
            if threshold is None:
                np.ndarray: topic distribution for each text document
            else:
                (np.ndarray, np.ndarray): topic distribution and boolean array
        &#34;&#34;&#34;
        self._check_model()
        transformed_texts = self.vectorizer.transform(texts)
        X_topics = self.model.transform(transformed_texts)
        #if self.model_type == &#39;nmf&#39;:
            #scores = np.matrix(X_topics)
            #scores_normalized= scores/scores.sum(axis=1)
            #X_topics = scores_normalized
        _idx = np.array([True] * len(texts))
        if threshold is not None:
            _idx = np.amax(X_topics, axis=1) &gt; threshold  # idx of doc that above the threshold
            _idx = np.array(_idx)
            X_topics = X_topics[_idx]
        if harden: X_topics = self._harden_topics(X_topics)
        if threshold is not None:
            return (X_topics, _idx)
        else:
            return X_topics


    def visualize_documents(self, texts=None, doc_topics=None, 
                            width=700, height=700, point_size=5, title=&#39;Document Visualization&#39;,
                            extra_info={},
                            colors=None,
                            filepath=None,):
        &#34;&#34;&#34;
        Generates a visualization of a set of documents based on model.
        If &lt;texts&gt; is supplied, raw documents will be first transformed into document-topic
        matrix.  If &lt;doc_topics&gt; is supplied, then this will be used for visualization instead.
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
            width(int): width of image
            height(int): height of image
            point_size(int): size of circles in plot
            title(str):  title of visualization
            extra_info(dict of lists): A user-supplied information for each datapoint (attributes of the datapoint).
                                       The keys are field names.  The values are lists - each of which must
                                       be the same number of elements as &lt;texts&gt; or &lt;doc_topics&gt;. These fields are displayed
                                       when hovering over datapoints in the visualization.
            colors(list of str):  list of Hex color codes for each datapoint.
                                  Length of list must match either len(texts) or doc_topics.shape[0]
            filepath(str):             Optional filepath to save the interactive visualization
        &#34;&#34;&#34;

        # error-checking
        if texts is not None: length = len(texts)
        else: length = doc_topics.shape[0]
        if colors is not None and len(colors) != length:
            raise ValueError(&#39;length of colors is not consistent with length of texts or doctopics&#39;)
        if texts is not None and doc_topics is not None:
            raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
        if texts is None and doc_topics is None:
            raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
        if extra_info:
            invalid_keys = [&#39;x&#39;, &#39;y&#39;, &#39;topic&#39;, &#39;fill_color&#39;]
            for k in extra_info.keys():
                if k in invalid_keys:
                    raise ValueError(&#39;cannot use &#34;%s&#34; as key in extra_info&#39; %(k))
                lst = extra_info[k]
                if len(lst) != length:
                    raise ValueError(&#39;texts and extra_info lists must be same size&#39;)

        # check fo bokeh
        try:
            import bokeh.plotting as bp
            from bokeh.plotting import save
            from bokeh.models import HoverTool
            from bokeh.io import output_notebook
        except:
            warnings.warn(&#39;visualize_documents method requires bokeh package: pip install bokeh&#39;)
            return

        # prepare data
        if doc_topics is not None:
            X_topics = doc_topics
        else:
            if self.verbose:  print(&#39;transforming texts...&#39;, end=&#39;&#39;)
            X_topics = self.predict(texts, harden=False)
            if self.verbose: print(&#39;done.&#39;)

        # reduce to 2-D
        if self.verbose:  print(&#39;reducing to 2 dimensions...&#39;, end=&#39;&#39;)
        tsne_model = TSNE(n_components=2, verbose=self.verbose, random_state=0, angle=.99, init=&#39;pca&#39;)
        tsne_lda = tsne_model.fit_transform(X_topics)
        print(&#39;done.&#39;)

        # get random colormap
        colormap = U.get_random_colors(self.n_topics)

        # generate inline visualization in Jupyter notebook
        lda_keys = self._harden_topics(X_topics)
        if colors is None: colors = colormap[lda_keys]
        topic_summaries = self.get_topics(n_words=5)
        os.environ[&#34;BOKEH_RESOURCES&#34;]=&#34;inline&#34;
        output_notebook()
        dct = { 
                &#39;x&#39;:tsne_lda[:,0],
                &#39;y&#39;:tsne_lda[:, 1],
                &#39;topic&#39;:[topic_summaries[tid] for tid in lda_keys],
                &#39;fill_color&#39;:colors,}
        tool_tups = [(&#39;index&#39;, &#39;$index&#39;),
                     (&#39;(x,y)&#39;,&#39;($x,$y)&#39;),
                     (&#39;topic&#39;, &#39;@topic&#39;)]
        for k in extra_info.keys():
            dct[k] = extra_info[k]
            tool_tups.append((k, &#39;@&#39;+k))

        source = bp.ColumnDataSource(data=dct)
        hover = HoverTool( tooltips=tool_tups)
        p = bp.figure(plot_width=width, plot_height=height, 
                      tools=[hover, &#39;save&#39;, &#39;pan&#39;, &#39;wheel_zoom&#39;, &#39;box_zoom&#39;, &#39;reset&#39;],
                      #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                      title=title)
        #plot_lda = bp.figure(plot_width=1400, plot_height=1100,
                           #title=title,
                           #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                           #x_axis_type=None, y_axis_type=None, min_border=1)
        p.circle(&#39;x&#39;, &#39;y&#39;, size=point_size, source=source, fill_color= &#39;fill_color&#39;)
        bp.show(p)
        if filepath is not None:
            bp.output_file(filepath)
            bp.save(p)
        return


    def train_recommender(self, n_neighbors=20, metric=&#39;minkowski&#39;, p=2):
        &#34;&#34;&#34;
        Trains a recommender that, given a single document, will return
        documents in the corpus that are semantically similar to it.

        Args:
            n_neighbors (int): 
        Returns:
            None
        &#34;&#34;&#34;
        from sklearn.neighbors import NearestNeighbors
        rec = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, p=p)
        probs = self.get_doctopics()
        rec.fit(probs)
        self.recommender = rec
        return



    def recommend(self, text=None, doc_topic=None, n=5, n_neighbors=100):
        &#34;&#34;&#34;
        Given an example document, recommends documents similar to it
        from the set of documents supplied to build().
 
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
            n (int): number of recommendations to return
        Returns:
            list of tuples: each tuple is of the form:
                            (text, doc_id, topic_probability, topic_id)

        &#34;&#34;&#34;
        # error-checks
        if text is not None and doc_topic is not None:
            raise ValueError(&#39;text is mutually-exclusive with doc_topic&#39;)
        if text is None and doc_topic is None:
            raise ValueError(&#39;One of text or doc_topic is required.&#39;)
        if text is not None and type(text) not in [str]:
            raise ValueError(&#39;text must be a str &#39;)
        if  doc_topic is not None and type(doc_topic) not in [np.ndarray]:
            raise ValueError(&#39;doc_topic must be a np.ndarray&#39;)

        if n &gt; n_neighbors: n_neighbors = n

        x_test = [doc_topic]
        if text:
            x_test = self.predict([text])
        docs = self.get_docs()
        indices = self.recommender.kneighbors(x_test, return_distance=False, n_neighbors=n_neighbors)
        results = [doc for i, doc in enumerate(docs) if i in indices]
        return results[:n]




    def train_scorer(self, topic_ids=[], doc_ids=[], n_neighbors=20):
        &#34;&#34;&#34;
        Trains a scorer that can score documents based on similarity to a
        seed set of documents represented by topic_ids and doc_ids.

        NOTE: The score method currently employs the use of LocalOutLierFactor, which
        means you should not try to score documents that were used in training. Only
        new, unseen documents should be scored for similarity. 
        REFERENCE: 
        https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor

        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).  Documents associated
                                     with these topic_ids will be used as seed set.
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics.  Documents associated 
                                    with these doc_ids will be used as seed set.
        Returns:
            None
        &#34;&#34;&#34;
        from sklearn.neighbors import LocalOutlierFactor
        clf = LocalOutlierFactor(n_neighbors=n_neighbors, novelty=True, contamination=0.1)
        probs = self.get_doctopics(topic_ids=topic_ids, doc_ids=doc_ids)
        clf.fit(probs)
        self.scorer = clf
        return



    def score(self, texts=None, doc_topics=None):
        &#34;&#34;&#34;
        Given a new set of documents (supplied as texts or doc_topics), the score method
        uses a One-Class classifier to score documents based on similarity to a
        seed set of documents (where seed set is computed by train_scorer() method).

        Higher scores indicate a higher degree of similarity.
        Positive values represent a binary decision of similar.
        Negative values represent a binary decision of dissimlar.
        In practice, negative scores closer to zer will also be simlar as One-Class
        classifiers are more strict than traditional binary classifiers.
        Documents with negative scores closer to zero are good candidates for
        inclusion in a training set for binary classification (e.g., active labeling).

        NOTE: The score method currently employs the use of LocalOutLierFactor, which
        means you should not try to score documents that were used in training. Only
        new, unseen documents should be scored for similarity.
 
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
        Returns:
            list of floats:  larger values indicate higher degree of similarity
                             positive values indicate a binary decision of similar
                             negative values indicate binary decision of dissimilar
                             In practice, negative scores closer to zero will also 
                             be similar as One-class classifiers are more strict
                             than traditional binary classifiers.

        &#34;&#34;&#34;
        # error-checks
        if texts is not None and doc_topics is not None:
            raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
        if texts is None and doc_topics is None:
            raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
        if texts is not None and type(texts) not in [list, np.ndarray]:
            raise ValueError(&#39;texts must be either a list or numpy ndarray&#39;)
        if  doc_topics is not None and type(doc_topics) not in [np.ndarray]:
            raise ValueError(&#39;doc_topics must be a np.ndarray&#39;)

        x_test = doc_topics
        if texts:
            x_test = self.predict(texts)
        return self.scorer.decision_function(x_test)


    def search(self, query, topic_ids=[], doc_ids=[], case_sensitive=False):
        &#34;&#34;&#34;
        search documents for query string.
        Args:
            query(str):  the word or phrase to search
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
            case_sensitive(bool):  If True, case sensitive search
        &#34;&#34;&#34;

        # setup pattern
        if not case_sensitive: query = query.lower()
        pattern = re.compile(r&#39;\b%s\b&#39; % query)

        # retrive docs
        docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)

        # search
        mb = master_bar(range(1))
        results = []
        for i in mb:
            for doc in progress_bar(docs, parent=mb):
                text = doc[&#39;text&#39;]
                if not case_sensitive: text = text.lower()
                matches = pattern.findall(text)
                if matches: results.append(doc)
            if self.verbose: mb.write(&#39;done.&#39;)
        return results



    def _rank_documents(self, 
                       texts,
                       doc_topics=None):
        &#34;&#34;&#34;
        Rank documents by topic score.
        If topic_index is supplied, rank documents based on relevance to supplied topic.
        Otherwise, rank all texts by their highest topic score (for any topic).
        Args:
            texts(list of str): list of document texts.
            doc_topics(ndarray): pre-computed topic distribution for each document
                                 If None, re-computed from texts.
                              
        Returns:
            dict of lists: each element in list is a tuple of (doc_index, topic_index, score)
            ... where doc_index is an index into either texts 
        &#34;&#34;&#34;
        if doc_topics is not None:
            X_topics = doc_topics
        else:
            if self.verbose: print(&#39;transforming texts to topic space...&#39;)
            X_topics = self.predict(texts)
        topics = np.argmax(X_topics, axis=1)
        scores = np.amax(X_topics, axis=1)
        doc_ids = np.array([i for i, x in enumerate(texts)])
        result = list(zip(texts, doc_ids, topics, scores))
        if self.verbose: print(&#39;done.&#39;)
        result = sorted(result, key=lambda x: x[-1], reverse=True)
        result_dict = {}
        for r in result:
            text = r[0]
            doc_id = r[1]
            topic_id = r[2]
            score = r[3]
            lst = result_dict.get(topic_id, [])
            lst.append((text, doc_id, score))
            result_dict[topic_id] = lst
        return result_dict


    def _harden_topics(self, X_topics):
        &#34;&#34;&#34;
        Transforms soft-clustering to hard-clustering
        &#34;&#34;&#34;
        max_topics = []
        for i in range(X_topics.shape[0]):
            max_topics.append(X_topics[i].argmax())
        X_topics = np.array(max_topics)
        return X_topics


    def _check_build(self):
        self._check_model()
        if self.topic_dict is None: 
            raise Exception(&#39;Must call build() method.&#39;)

    def _check_scorer(self):
        if self.scorer is None:
            raise Exception(&#39;Must call train_scorer()&#39;)

    def _check_recommender(self):
        if self.recommender is None:
            raise Exception(&#39;Must call train_recommender()&#39;)


    def _check_model(self):
        if self.model is None or self.vectorizer is None:
            raise Exception(&#39;Must call train()&#39;)



    def save(self, fname):
        &#34;&#34;&#34;
        save TopicModel object
        &#34;&#34;&#34;

        
        with open(fname+&#39;.tm_vect&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.vectorizer, f)
        with open(fname+&#39;.tm_model&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.model, f)
        params = {&#39;n_topics&#39;: self.n_topics,
                  &#39;n_features&#39;: self.n_features,
                  &#39;verbose&#39;: self.verbose}
        with open(fname+&#39;.tm_params&#39;, &#39;wb&#39;) as f:
            pickle.dump(params, f)

        return

get_topic_model = TopicModel </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ktrain.text.eda.TopicModel"><code class="flex name class">
<span>class <span class="ident">TopicModel</span></span>
<span>(</span><span>texts=None, n_topics=None, n_features=10000, min_df=5, max_df=0.5, stop_words='english', model_type='lda', lda_max_iter=5, lda_mode='online', token_pattern=None, verbose=1, hyperparam_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fits a topic model to documents in <texts>.</p>
<h2 id="example">Example</h2>
<p>tm = ktrain.text.get_topic_model(docs, n_topics=20,
n_features=1000, min_df=2, max_df=0.95)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of texts</dd>
<dt><strong><code>n_topics</code></strong> :&ensp;<code>int</code></dt>
<dd>number of topics.
If None, n_topics = min{400, sqrt[# documents/2]})</dd>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum words to consider</dd>
<dt><strong><code>max_df</code></strong> :&ensp;<code>float</code></dt>
<dd>words in more than max_df proportion of docs discarded</dd>
<dt><strong><code>stop_words</code></strong> :&ensp;<code>str</code> or <code>list</code></dt>
<dd>either 'english' for built-in stop words or
a list of stop words to ignore</dd>
<dt>model_type(str): type of topic model to fit. One of {'lda', 'nmf'}.
Default:'lda'</dt>
<dt><strong><code>lda_max_iter</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum iterations for 'lda'.
5 is default if using lda_mode='online'.
If lda_mode='batch', this should be increased (e.g., 1500).
Ignored if model_type != 'lda'</dd>
<dt><strong><code>lda_mode</code></strong> :&ensp;<code>str</code></dt>
<dd>one of {'online', 'batch'}. Ignored if model_type !='lda'</dd>
</dl>
<p>token_pattern(str): regex pattern to use to tokenize documents.
verbose(bool): verbosity</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TopicModel():


    def __init__(self,texts=None, n_topics=None, n_features=10000, 
                 min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
                 model_type=&#39;lda&#39;,
                 lda_max_iter=5, lda_mode=&#39;online&#39;,
                 token_pattern=None, verbose=1,
                 hyperparam_kwargs=None
    ):
        &#34;&#34;&#34;
        Fits a topic model to documents in &lt;texts&gt;.
        Example:
            tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                            n_features=1000, min_df=2, max_df=0.95)
        Args:
            texts (list of str): list of texts
            n_topics (int): number of topics.
                            If None, n_topics = min{400, sqrt[# documents/2]})
            n_features (int):  maximum words to consider
            max_df (float): words in more than max_df proportion of docs discarded
            stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                      a list of stop words to ignore
            model_type(str): type of topic model to fit. One of {&#39;lda&#39;, &#39;nmf&#39;}.  Default:&#39;lda&#39;
            lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                                If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                                Ignored if model_type != &#39;lda&#39;
            lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored if model_type !=&#39;lda&#39;
            token_pattern(str): regex pattern to use to tokenize documents. 
            verbose(bool): verbosity

        &#34;&#34;&#34;
        self.verbose=verbose

        # estimate n_topics
        if n_topics is None:
            if texts is None:
                raise ValueError(&#39;If n_topics is None, texts must be supplied&#39;)
            estimated = max(1, int(math.floor(math.sqrt(len(texts) / 2))))
            n_topics = min(400, estimated)
            print(&#39;n_topics automatically set to %s&#39; % (n_topics))

        # train model
        if texts is not None:
            (model, vectorizer) = self.train(texts, model_type=model_type,
                                             n_topics=n_topics, n_features=n_features,
                                             min_df = min_df, max_df = max_df, 
                                             stop_words=stop_words,
                                             lda_max_iter=lda_max_iter, lda_mode=lda_mode,
                                             token_pattern=token_pattern,
                                             hyperparam_kwargs=hyperparam_kwargs)
        else:
            vectorizer = None
            model = None



        # save model and vectorizer and hyperparameter settings
        self.vectorizer = vectorizer
        self.model = model
        self.n_topics = n_topics
        self.n_features = n_features
        if verbose: print(&#39;done.&#39;)

        # these variables are set by self.build():
        self.topic_dict = None
        self.doc_topics = None
        self.bool_array = None

        self.scorer = None       # set by self.train_scorer()
        self.recommender = None  # set by self.train_recommender()
        return


    def train(self,texts, model_type=&#39;lda&#39;, n_topics=None, n_features=10000,
              min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
              lda_max_iter=5, lda_mode=&#39;online&#39;,
              token_pattern=None, hyperparam_kwargs=None):
        &#34;&#34;&#34;
        Fits a topic model to documents in &lt;texts&gt;.
        Example:
            tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                            n_features=1000, min_df=2, max_df=0.95)
        Args:
            texts (list of str): list of texts
            n_topics (int): number of topics.
                            If None, n_topics = min{400, sqrt[# documents/2]})
            n_features (int):  maximum words to consider
            max_df (float): words in more than max_df proportion of docs discarded
            stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                      a list of stop words to ignore
            lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                                If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                                Ignored if model_type != &#39;lda&#39;
            lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored of model_type !=&#39;lda&#39;
            token_pattern(str): regex pattern to use to tokenize documents. 
                                If None, a default tokenizer will be used
            hyperparam_kwargs(dict): hyperparameters for LDA/NMF
                                     Keys in this dict can be any of the following:
                                         alpha: alpha for LDA  default: 5./n_topics
                                         beta: beta for LDA.  default:0.01
                                         nmf_alpha: alpha for NMF.  default:0
                                         l1_ratio: l1_ratio for NMF. default: 0
                                         ngram_range:  whether to consider bigrams, trigrams. default: (1,1) 
                                    
        Returns:
            tuple: (model, vectorizer)
        &#34;&#34;&#34;
        if hyperparam_kwargs is None:
            hyperparam_kwargs = {}
        alpha = hyperparam_kwargs.get(&#39;alpha&#39;, 5.0 / n_topics)
        beta = hyperparam_kwargs.get(&#39;beta&#39;, 0.01)
        nmf_alpha = hyperparam_kwargs.get(&#39;nmf_alpha&#39;, 0)
        l1_ratio = hyperparam_kwargs.get(&#39;l1_ratio&#39;, 0)
        ngram_range = hyperparam_kwargs.get(&#39;ngram_range&#39;, (1,1))

        # adjust defaults based on language detected
        if texts is not None:
            lang = TU.detect_lang(texts)
            if lang != &#39;en&#39;:
                stopwords = None if stop_words==&#39;english&#39; else stop_words
                token_pattern = r&#39;(?u)\b\w+\b&#39; if token_pattern is None else token_pattern
            if pp.is_nospace_lang(lang):
                text_list = []
                for t in texts:
                    text_list.append(&#39; &#39;.join(jieba.cut(t, HMM=False)))
                texts = text_list
            if self.verbose: print(&#39;lang: %s&#39; % (lang))


        # preprocess texts
        if self.verbose: print(&#39;preprocessing texts...&#39;)
        if token_pattern is None: token_pattern = TU.DEFAULT_TOKEN_PATTERN
        #if token_pattern is None: token_pattern = r&#39;(?u)\b\w\w+\b&#39;
        vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,
                                 max_features=n_features, stop_words=stop_words,
                                 token_pattern=token_pattern, ngram_range=ngram_range)
        

        x_train = vectorizer.fit_transform(texts)

        # fit model

        if self.verbose: print(&#39;fitting model...&#39;)
        if model_type == &#39;lda&#39;:
            model = LatentDirichletAllocation(n_components=n_topics, max_iter=lda_max_iter,
                                              learning_method=lda_mode, learning_offset=50.,
                                              doc_topic_prior=alpha,
                                              topic_word_prior=beta,
                                              verbose=self.verbose, random_state=0)
        elif model_type == &#39;nmf&#39;:
            model = NMF(
                n_components=n_topics,
                max_iter=lda_max_iter,
                verbose=self.verbose,
                alpha=nmf_alpha,
                l1_ratio=l1_ratio,
                random_state=0)
        else:
            raise ValueError(&#34;unknown model type:&#34;, str(model_type))
        model.fit(x_train)

        # save model and vectorizer and hyperparameter settings
        return (model, vectorizer)


    @property
    def topics(self):
        &#34;&#34;&#34;
        convenience method/property
        &#34;&#34;&#34;
        return self.get_topics()


    def get_document_topic_distribution(self):
        &#34;&#34;&#34;
        Gets the document-topic distribution.
        Each row is a document and each column is a topic
        The output of this method is equivalent to invoking get_doctopics with no arguments.
        &#34;&#34;&#34;
        self._check_build()
        return self.doc_topics


    def get_sorted_docs(self, topic_id):
        &#34;&#34;&#34;
        Returns all docs sorted by relevance to &lt;topic_id&gt;.
        Unlike get_docs, this ranks documents by the supplied topic_id rather
        than the topic_id to which document is most relevant.
        &#34;&#34;&#34;
        docs = self.get_docs()
        d = {}
        for doc in docs: d[doc[&#39;doc_id&#39;]] = doc
        m = self.get_document_topic_distribution()
        doc_ids = (-m[:,topic_id]).argsort()
        return [d[doc_id] for doc_id in doc_ids]



    def get_word_weights(self, topic_id, n_words=100):
        &#34;&#34;&#34;
        Returns a list tuples of the form: (word, weight) for given topic_id.
        The weight can be interpreted as the number of times word was assigned to topic with given topic_id.
        REFERENCE: https://stackoverflow.com/a/48890889/13550699
        Args:
            topic_id(int): topic ID
            n_words=int): number of top words
        &#34;&#34;&#34;
        self._check_model()
        if topic_id+1 &gt; len(self.model.components_): 
            raise ValueError(&#39;topic_id must be less than %s&#39; % (len(self.model.components_)))
        feature_names = self.vectorizer.get_feature_names()
        word_probs = self.model.components_[topic_id]
        word_ids = [i for i in word_probs.argsort()[:-n_words - 1:-1]]
        words = [feature_names[i] for i in word_ids]
        probs = [word_probs[i] for i in word_ids]
        return list( zip(words, probs) )


    def get_topics(self, n_words=10, as_string=True):
        &#34;&#34;&#34;
        Returns a list of discovered topics
        Args:
            n_words(int): number of words to use in topic summary
            as_string(bool): If True, each summary is a space-delimited string instead of list of words
        &#34;&#34;&#34;
        self._check_model()
        feature_names = self.vectorizer.get_feature_names()
        topic_summaries = []
        for topic_idx, topic in enumerate(self.model.components_):
            summary = [feature_names[i] for i in topic.argsort()[:-n_words - 1:-1]]
            if as_string: summary = &#34; &#34;.join(summary)
            topic_summaries.append(summary)
        return topic_summaries


    def print_topics(self, n_words=10, show_counts=False):
        &#34;&#34;&#34;
        print topics
        n_words(int): number of words to describe each topic
        show_counts(bool): If True, print topics with document counts, where
                           the count is the number of documents with that topic as primary.
        &#34;&#34;&#34;
        topics = self.get_topics(n_words=n_words, as_string=True)
        if show_counts:
            self._check_build()
            topic_counts = sorted([ (k, topics[k], len(v)) for k,v in self.topic_dict.items()], 
                                    key=lambda kv:kv[-1], reverse=True)
            for (idx, topic, count) in topic_counts:
                print(&#34;topic:%s | count:%s | %s&#34; %(idx, count, topic))
        else:
            for i, t in enumerate(topics):
                print(&#39;topic %s | %s&#39; % (i, t))
        return


    def build(self, texts, threshold=None):
        &#34;&#34;&#34;
        Builds the document-topic distribution showing the topic probability distirbution
        for each document in &lt;texts&gt; with respect to the learned topic space.
        Args:
            texts (list of str): list of text documents
            threshold (float): If not None, documents with whose highest topic probability
                               is less than threshold are filtered out.
        &#34;&#34;&#34;
        doc_topics, bool_array = self.predict(texts, threshold=threshold)
        self.doc_topics = doc_topics
        self.bool_array = bool_array

        texts = [text for i, text in enumerate(texts) if bool_array[i]]
        self.topic_dict = self._rank_documents(texts, doc_topics=doc_topics)
        return


    def filter(self, lst):
        &#34;&#34;&#34;
        The build method may prune documents based on threshold.
        This method prunes other lists based on how build pruned documents.
        This is useful to filter lists containing metadata associated with documents
        for use with visualize_documents.
        Args:
            lst(list): a list of data
        Returns:
            list:  a filtered list of data based on how build filtered the documents
        &#34;&#34;&#34;
        if len(lst) != self.bool_array.shape[0]:
            raise ValueError(&#39;Length of lst is not consistent with the number of documents &#39; +
                             &#39;supplied to get_topic_model&#39;)
        arr = np.array(lst)
        return list(arr[self.bool_array])
                           

    
    def get_docs(self, topic_ids=[], doc_ids=[], rank=False):
        &#34;&#34;&#34;
        Returns document entries for supplied topic_ids.
        Documents returned are those whose primary topic is topic with given topic_id
        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
            rank(bool): If True, the list is sorted first by topic_id (ascending)
                        and then ty topic probability (descending).
                        Otherwise, list is sorted by doc_id (i.e., the order
                        of texts supplied to self.build (which is the order of self.doc_topics).

        Returns:
            list of dicts:  list of dicts with keys:
                            &#39;text&#39;: text of document
                            &#39;doc_id&#39;: ID of document
                            &#39;topic_proba&#39;: topic probability (or score)
                            &#39;topic_id&#39;: ID of topic
            
        &#34;&#34;&#34;
        self._check_build()
        if not topic_ids:
            topic_ids = list(range(self.n_topics))
        result_texts = []
        for topic_id in topic_ids:
            if topic_id not in self.topic_dict: continue
            texts = [{&#39;text&#39;:tup[0], &#39;doc_id&#39;:tup[1], &#39;topic_proba&#39;:tup[2], &#39;topic_id&#39;:topic_id} for tup in self.topic_dict[topic_id] 
                                                                                                     if not doc_ids or tup[1] in doc_ids]
            result_texts.extend(texts)
        if not rank:
            result_texts = sorted(result_texts, key=lambda x:x[&#39;doc_id&#39;])
        return result_texts


    def get_doctopics(self,  topic_ids=[], doc_ids=[]):
        &#34;&#34;&#34;
        Returns a topic probability distribution for documents
        with primary topic that is one of &lt;topic_ids&gt; and with doc_id in &lt;doc_ids&gt;.

        If no topic_ids or doc_ids are provided, then topic distributions for all documents
        are returned (which equivalent to the output of get_document_topic_distribution).

        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
        Returns:
            np.ndarray: Each row is the topic probability distribution of a document.
                        Array is sorted in the order returned by self.get_docs.
                        
        &#34;&#34;&#34;
        docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)
        return np.array([self.doc_topics[idx] for idx in [x[&#39;doc_id&#39;] for x in docs]])


    def get_texts(self,  topic_ids=[]):
        &#34;&#34;&#34;
        Returns texts for documents
        with primary topic that is one of &lt;topic_ids&gt;
        Args:
            topic_ids(list of ints): list of topic IDs
        Returns:
            list of str
        &#34;&#34;&#34;
        if not topic_ids: topic_ids = list(range(self.n_topics))
        docs = self.get_docs(topic_ids)
        return [x[0] for x in docs]



    def predict(self, texts, threshold=None, harden=False):
        &#34;&#34;&#34;
        Args:
            texts (list of str): list of texts
            threshold (float): If not None, documents with maximum topic scores
                                less than &lt;threshold&gt; are filtered out
            harden(bool): If True, each document is assigned to a single topic for which
                          it has the highest score
        Returns:
            if threshold is None:
                np.ndarray: topic distribution for each text document
            else:
                (np.ndarray, np.ndarray): topic distribution and boolean array
        &#34;&#34;&#34;
        self._check_model()
        transformed_texts = self.vectorizer.transform(texts)
        X_topics = self.model.transform(transformed_texts)
        #if self.model_type == &#39;nmf&#39;:
            #scores = np.matrix(X_topics)
            #scores_normalized= scores/scores.sum(axis=1)
            #X_topics = scores_normalized
        _idx = np.array([True] * len(texts))
        if threshold is not None:
            _idx = np.amax(X_topics, axis=1) &gt; threshold  # idx of doc that above the threshold
            _idx = np.array(_idx)
            X_topics = X_topics[_idx]
        if harden: X_topics = self._harden_topics(X_topics)
        if threshold is not None:
            return (X_topics, _idx)
        else:
            return X_topics


    def visualize_documents(self, texts=None, doc_topics=None, 
                            width=700, height=700, point_size=5, title=&#39;Document Visualization&#39;,
                            extra_info={},
                            colors=None,
                            filepath=None,):
        &#34;&#34;&#34;
        Generates a visualization of a set of documents based on model.
        If &lt;texts&gt; is supplied, raw documents will be first transformed into document-topic
        matrix.  If &lt;doc_topics&gt; is supplied, then this will be used for visualization instead.
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
            width(int): width of image
            height(int): height of image
            point_size(int): size of circles in plot
            title(str):  title of visualization
            extra_info(dict of lists): A user-supplied information for each datapoint (attributes of the datapoint).
                                       The keys are field names.  The values are lists - each of which must
                                       be the same number of elements as &lt;texts&gt; or &lt;doc_topics&gt;. These fields are displayed
                                       when hovering over datapoints in the visualization.
            colors(list of str):  list of Hex color codes for each datapoint.
                                  Length of list must match either len(texts) or doc_topics.shape[0]
            filepath(str):             Optional filepath to save the interactive visualization
        &#34;&#34;&#34;

        # error-checking
        if texts is not None: length = len(texts)
        else: length = doc_topics.shape[0]
        if colors is not None and len(colors) != length:
            raise ValueError(&#39;length of colors is not consistent with length of texts or doctopics&#39;)
        if texts is not None and doc_topics is not None:
            raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
        if texts is None and doc_topics is None:
            raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
        if extra_info:
            invalid_keys = [&#39;x&#39;, &#39;y&#39;, &#39;topic&#39;, &#39;fill_color&#39;]
            for k in extra_info.keys():
                if k in invalid_keys:
                    raise ValueError(&#39;cannot use &#34;%s&#34; as key in extra_info&#39; %(k))
                lst = extra_info[k]
                if len(lst) != length:
                    raise ValueError(&#39;texts and extra_info lists must be same size&#39;)

        # check fo bokeh
        try:
            import bokeh.plotting as bp
            from bokeh.plotting import save
            from bokeh.models import HoverTool
            from bokeh.io import output_notebook
        except:
            warnings.warn(&#39;visualize_documents method requires bokeh package: pip install bokeh&#39;)
            return

        # prepare data
        if doc_topics is not None:
            X_topics = doc_topics
        else:
            if self.verbose:  print(&#39;transforming texts...&#39;, end=&#39;&#39;)
            X_topics = self.predict(texts, harden=False)
            if self.verbose: print(&#39;done.&#39;)

        # reduce to 2-D
        if self.verbose:  print(&#39;reducing to 2 dimensions...&#39;, end=&#39;&#39;)
        tsne_model = TSNE(n_components=2, verbose=self.verbose, random_state=0, angle=.99, init=&#39;pca&#39;)
        tsne_lda = tsne_model.fit_transform(X_topics)
        print(&#39;done.&#39;)

        # get random colormap
        colormap = U.get_random_colors(self.n_topics)

        # generate inline visualization in Jupyter notebook
        lda_keys = self._harden_topics(X_topics)
        if colors is None: colors = colormap[lda_keys]
        topic_summaries = self.get_topics(n_words=5)
        os.environ[&#34;BOKEH_RESOURCES&#34;]=&#34;inline&#34;
        output_notebook()
        dct = { 
                &#39;x&#39;:tsne_lda[:,0],
                &#39;y&#39;:tsne_lda[:, 1],
                &#39;topic&#39;:[topic_summaries[tid] for tid in lda_keys],
                &#39;fill_color&#39;:colors,}
        tool_tups = [(&#39;index&#39;, &#39;$index&#39;),
                     (&#39;(x,y)&#39;,&#39;($x,$y)&#39;),
                     (&#39;topic&#39;, &#39;@topic&#39;)]
        for k in extra_info.keys():
            dct[k] = extra_info[k]
            tool_tups.append((k, &#39;@&#39;+k))

        source = bp.ColumnDataSource(data=dct)
        hover = HoverTool( tooltips=tool_tups)
        p = bp.figure(plot_width=width, plot_height=height, 
                      tools=[hover, &#39;save&#39;, &#39;pan&#39;, &#39;wheel_zoom&#39;, &#39;box_zoom&#39;, &#39;reset&#39;],
                      #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                      title=title)
        #plot_lda = bp.figure(plot_width=1400, plot_height=1100,
                           #title=title,
                           #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                           #x_axis_type=None, y_axis_type=None, min_border=1)
        p.circle(&#39;x&#39;, &#39;y&#39;, size=point_size, source=source, fill_color= &#39;fill_color&#39;)
        bp.show(p)
        if filepath is not None:
            bp.output_file(filepath)
            bp.save(p)
        return


    def train_recommender(self, n_neighbors=20, metric=&#39;minkowski&#39;, p=2):
        &#34;&#34;&#34;
        Trains a recommender that, given a single document, will return
        documents in the corpus that are semantically similar to it.

        Args:
            n_neighbors (int): 
        Returns:
            None
        &#34;&#34;&#34;
        from sklearn.neighbors import NearestNeighbors
        rec = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, p=p)
        probs = self.get_doctopics()
        rec.fit(probs)
        self.recommender = rec
        return



    def recommend(self, text=None, doc_topic=None, n=5, n_neighbors=100):
        &#34;&#34;&#34;
        Given an example document, recommends documents similar to it
        from the set of documents supplied to build().
 
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
            n (int): number of recommendations to return
        Returns:
            list of tuples: each tuple is of the form:
                            (text, doc_id, topic_probability, topic_id)

        &#34;&#34;&#34;
        # error-checks
        if text is not None and doc_topic is not None:
            raise ValueError(&#39;text is mutually-exclusive with doc_topic&#39;)
        if text is None and doc_topic is None:
            raise ValueError(&#39;One of text or doc_topic is required.&#39;)
        if text is not None and type(text) not in [str]:
            raise ValueError(&#39;text must be a str &#39;)
        if  doc_topic is not None and type(doc_topic) not in [np.ndarray]:
            raise ValueError(&#39;doc_topic must be a np.ndarray&#39;)

        if n &gt; n_neighbors: n_neighbors = n

        x_test = [doc_topic]
        if text:
            x_test = self.predict([text])
        docs = self.get_docs()
        indices = self.recommender.kneighbors(x_test, return_distance=False, n_neighbors=n_neighbors)
        results = [doc for i, doc in enumerate(docs) if i in indices]
        return results[:n]




    def train_scorer(self, topic_ids=[], doc_ids=[], n_neighbors=20):
        &#34;&#34;&#34;
        Trains a scorer that can score documents based on similarity to a
        seed set of documents represented by topic_ids and doc_ids.

        NOTE: The score method currently employs the use of LocalOutLierFactor, which
        means you should not try to score documents that were used in training. Only
        new, unseen documents should be scored for similarity. 
        REFERENCE: 
        https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor

        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).  Documents associated
                                     with these topic_ids will be used as seed set.
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics.  Documents associated 
                                    with these doc_ids will be used as seed set.
        Returns:
            None
        &#34;&#34;&#34;
        from sklearn.neighbors import LocalOutlierFactor
        clf = LocalOutlierFactor(n_neighbors=n_neighbors, novelty=True, contamination=0.1)
        probs = self.get_doctopics(topic_ids=topic_ids, doc_ids=doc_ids)
        clf.fit(probs)
        self.scorer = clf
        return



    def score(self, texts=None, doc_topics=None):
        &#34;&#34;&#34;
        Given a new set of documents (supplied as texts or doc_topics), the score method
        uses a One-Class classifier to score documents based on similarity to a
        seed set of documents (where seed set is computed by train_scorer() method).

        Higher scores indicate a higher degree of similarity.
        Positive values represent a binary decision of similar.
        Negative values represent a binary decision of dissimlar.
        In practice, negative scores closer to zer will also be simlar as One-Class
        classifiers are more strict than traditional binary classifiers.
        Documents with negative scores closer to zero are good candidates for
        inclusion in a training set for binary classification (e.g., active labeling).

        NOTE: The score method currently employs the use of LocalOutLierFactor, which
        means you should not try to score documents that were used in training. Only
        new, unseen documents should be scored for similarity.
 
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
        Returns:
            list of floats:  larger values indicate higher degree of similarity
                             positive values indicate a binary decision of similar
                             negative values indicate binary decision of dissimilar
                             In practice, negative scores closer to zero will also 
                             be similar as One-class classifiers are more strict
                             than traditional binary classifiers.

        &#34;&#34;&#34;
        # error-checks
        if texts is not None and doc_topics is not None:
            raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
        if texts is None and doc_topics is None:
            raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
        if texts is not None and type(texts) not in [list, np.ndarray]:
            raise ValueError(&#39;texts must be either a list or numpy ndarray&#39;)
        if  doc_topics is not None and type(doc_topics) not in [np.ndarray]:
            raise ValueError(&#39;doc_topics must be a np.ndarray&#39;)

        x_test = doc_topics
        if texts:
            x_test = self.predict(texts)
        return self.scorer.decision_function(x_test)


    def search(self, query, topic_ids=[], doc_ids=[], case_sensitive=False):
        &#34;&#34;&#34;
        search documents for query string.
        Args:
            query(str):  the word or phrase to search
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
            case_sensitive(bool):  If True, case sensitive search
        &#34;&#34;&#34;

        # setup pattern
        if not case_sensitive: query = query.lower()
        pattern = re.compile(r&#39;\b%s\b&#39; % query)

        # retrive docs
        docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)

        # search
        mb = master_bar(range(1))
        results = []
        for i in mb:
            for doc in progress_bar(docs, parent=mb):
                text = doc[&#39;text&#39;]
                if not case_sensitive: text = text.lower()
                matches = pattern.findall(text)
                if matches: results.append(doc)
            if self.verbose: mb.write(&#39;done.&#39;)
        return results



    def _rank_documents(self, 
                       texts,
                       doc_topics=None):
        &#34;&#34;&#34;
        Rank documents by topic score.
        If topic_index is supplied, rank documents based on relevance to supplied topic.
        Otherwise, rank all texts by their highest topic score (for any topic).
        Args:
            texts(list of str): list of document texts.
            doc_topics(ndarray): pre-computed topic distribution for each document
                                 If None, re-computed from texts.
                              
        Returns:
            dict of lists: each element in list is a tuple of (doc_index, topic_index, score)
            ... where doc_index is an index into either texts 
        &#34;&#34;&#34;
        if doc_topics is not None:
            X_topics = doc_topics
        else:
            if self.verbose: print(&#39;transforming texts to topic space...&#39;)
            X_topics = self.predict(texts)
        topics = np.argmax(X_topics, axis=1)
        scores = np.amax(X_topics, axis=1)
        doc_ids = np.array([i for i, x in enumerate(texts)])
        result = list(zip(texts, doc_ids, topics, scores))
        if self.verbose: print(&#39;done.&#39;)
        result = sorted(result, key=lambda x: x[-1], reverse=True)
        result_dict = {}
        for r in result:
            text = r[0]
            doc_id = r[1]
            topic_id = r[2]
            score = r[3]
            lst = result_dict.get(topic_id, [])
            lst.append((text, doc_id, score))
            result_dict[topic_id] = lst
        return result_dict


    def _harden_topics(self, X_topics):
        &#34;&#34;&#34;
        Transforms soft-clustering to hard-clustering
        &#34;&#34;&#34;
        max_topics = []
        for i in range(X_topics.shape[0]):
            max_topics.append(X_topics[i].argmax())
        X_topics = np.array(max_topics)
        return X_topics


    def _check_build(self):
        self._check_model()
        if self.topic_dict is None: 
            raise Exception(&#39;Must call build() method.&#39;)

    def _check_scorer(self):
        if self.scorer is None:
            raise Exception(&#39;Must call train_scorer()&#39;)

    def _check_recommender(self):
        if self.recommender is None:
            raise Exception(&#39;Must call train_recommender()&#39;)


    def _check_model(self):
        if self.model is None or self.vectorizer is None:
            raise Exception(&#39;Must call train()&#39;)



    def save(self, fname):
        &#34;&#34;&#34;
        save TopicModel object
        &#34;&#34;&#34;

        
        with open(fname+&#39;.tm_vect&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.vectorizer, f)
        with open(fname+&#39;.tm_model&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.model, f)
        params = {&#39;n_topics&#39;: self.n_topics,
                  &#39;n_features&#39;: self.n_features,
                  &#39;verbose&#39;: self.verbose}
        with open(fname+&#39;.tm_params&#39;, &#39;wb&#39;) as f:
            pickle.dump(params, f)

        return</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="ktrain.text.eda.TopicModel.topics"><code class="name">var <span class="ident">topics</span></code></dt>
<dd>
<div class="desc"><p>convenience method/property</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def topics(self):
    &#34;&#34;&#34;
    convenience method/property
    &#34;&#34;&#34;
    return self.get_topics()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="ktrain.text.eda.TopicModel.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, texts, threshold=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the document-topic distribution showing the topic probability distirbution
for each document in <texts> with respect to the learned topic space.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of text documents</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>If not None, documents with whose highest topic probability
is less than threshold are filtered out.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self, texts, threshold=None):
    &#34;&#34;&#34;
    Builds the document-topic distribution showing the topic probability distirbution
    for each document in &lt;texts&gt; with respect to the learned topic space.
    Args:
        texts (list of str): list of text documents
        threshold (float): If not None, documents with whose highest topic probability
                           is less than threshold are filtered out.
    &#34;&#34;&#34;
    doc_topics, bool_array = self.predict(texts, threshold=threshold)
    self.doc_topics = doc_topics
    self.bool_array = bool_array

    texts = [text for i, text in enumerate(texts) if bool_array[i]]
    self.topic_dict = self._rank_documents(texts, doc_topics=doc_topics)
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, lst)</span>
</code></dt>
<dd>
<div class="desc"><p>The build method may prune documents based on threshold.
This method prunes other lists based on how build pruned documents.
This is useful to filter lists containing metadata associated with documents
for use with visualize_documents.</p>
<h2 id="args">Args</h2>
<p>lst(list): a list of data</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>a filtered list of data based on how build filtered the documents</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, lst):
    &#34;&#34;&#34;
    The build method may prune documents based on threshold.
    This method prunes other lists based on how build pruned documents.
    This is useful to filter lists containing metadata associated with documents
    for use with visualize_documents.
    Args:
        lst(list): a list of data
    Returns:
        list:  a filtered list of data based on how build filtered the documents
    &#34;&#34;&#34;
    if len(lst) != self.bool_array.shape[0]:
        raise ValueError(&#39;Length of lst is not consistent with the number of documents &#39; +
                         &#39;supplied to get_topic_model&#39;)
    arr = np.array(lst)
    return list(arr[self.bool_array])</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_docs"><code class="name flex">
<span>def <span class="ident">get_docs</span></span>(<span>self, topic_ids=[], doc_ids=[], rank=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns document entries for supplied topic_ids.
Documents returned are those whose primary topic is topic with given topic_id</p>
<h2 id="args">Args</h2>
<dl>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics</dd>
</dl>
<p>rank(bool): If True, the list is sorted first by topic_id (ascending)
and then ty topic probability (descending).
Otherwise, list is sorted by doc_id (i.e., the order
of texts supplied to self.build (which is the order of self.doc_topics).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>dicts</code></dt>
<dd>list of dicts with keys:
'text': text of document
'doc_id': ID of document
'topic_proba': topic probability (or score)
'topic_id': ID of topic</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_docs(self, topic_ids=[], doc_ids=[], rank=False):
    &#34;&#34;&#34;
    Returns document entries for supplied topic_ids.
    Documents returned are those whose primary topic is topic with given topic_id
    Args:
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics
        rank(bool): If True, the list is sorted first by topic_id (ascending)
                    and then ty topic probability (descending).
                    Otherwise, list is sorted by doc_id (i.e., the order
                    of texts supplied to self.build (which is the order of self.doc_topics).

    Returns:
        list of dicts:  list of dicts with keys:
                        &#39;text&#39;: text of document
                        &#39;doc_id&#39;: ID of document
                        &#39;topic_proba&#39;: topic probability (or score)
                        &#39;topic_id&#39;: ID of topic
        
    &#34;&#34;&#34;
    self._check_build()
    if not topic_ids:
        topic_ids = list(range(self.n_topics))
    result_texts = []
    for topic_id in topic_ids:
        if topic_id not in self.topic_dict: continue
        texts = [{&#39;text&#39;:tup[0], &#39;doc_id&#39;:tup[1], &#39;topic_proba&#39;:tup[2], &#39;topic_id&#39;:topic_id} for tup in self.topic_dict[topic_id] 
                                                                                                 if not doc_ids or tup[1] in doc_ids]
        result_texts.extend(texts)
    if not rank:
        result_texts = sorted(result_texts, key=lambda x:x[&#39;doc_id&#39;])
    return result_texts</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_doctopics"><code class="name flex">
<span>def <span class="ident">get_doctopics</span></span>(<span>self, topic_ids=[], doc_ids=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a topic probability distribution for documents
with primary topic that is one of <topic_ids> and with doc_id in <doc_ids>.</p>
<p>If no topic_ids or doc_ids are provided, then topic distributions for all documents
are returned (which equivalent to the output of get_document_topic_distribution).</p>
<h2 id="args">Args</h2>
<dl>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Each row is the topic probability distribution of a document.
Array is sorted in the order returned by self.get_docs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_doctopics(self,  topic_ids=[], doc_ids=[]):
    &#34;&#34;&#34;
    Returns a topic probability distribution for documents
    with primary topic that is one of &lt;topic_ids&gt; and with doc_id in &lt;doc_ids&gt;.

    If no topic_ids or doc_ids are provided, then topic distributions for all documents
    are returned (which equivalent to the output of get_document_topic_distribution).

    Args:
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics
    Returns:
        np.ndarray: Each row is the topic probability distribution of a document.
                    Array is sorted in the order returned by self.get_docs.
                    
    &#34;&#34;&#34;
    docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)
    return np.array([self.doc_topics[idx] for idx in [x[&#39;doc_id&#39;] for x in docs]])</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_document_topic_distribution"><code class="name flex">
<span>def <span class="ident">get_document_topic_distribution</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the document-topic distribution.
Each row is a document and each column is a topic
The output of this method is equivalent to invoking get_doctopics with no arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_document_topic_distribution(self):
    &#34;&#34;&#34;
    Gets the document-topic distribution.
    Each row is a document and each column is a topic
    The output of this method is equivalent to invoking get_doctopics with no arguments.
    &#34;&#34;&#34;
    self._check_build()
    return self.doc_topics</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_sorted_docs"><code class="name flex">
<span>def <span class="ident">get_sorted_docs</span></span>(<span>self, topic_id)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns all docs sorted by relevance to <topic_id>.
Unlike get_docs, this ranks documents by the supplied topic_id rather
than the topic_id to which document is most relevant.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sorted_docs(self, topic_id):
    &#34;&#34;&#34;
    Returns all docs sorted by relevance to &lt;topic_id&gt;.
    Unlike get_docs, this ranks documents by the supplied topic_id rather
    than the topic_id to which document is most relevant.
    &#34;&#34;&#34;
    docs = self.get_docs()
    d = {}
    for doc in docs: d[doc[&#39;doc_id&#39;]] = doc
    m = self.get_document_topic_distribution()
    doc_ids = (-m[:,topic_id]).argsort()
    return [d[doc_id] for doc_id in doc_ids]</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_texts"><code class="name flex">
<span>def <span class="ident">get_texts</span></span>(<span>self, topic_ids=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Returns texts for documents
with primary topic that is one of <topic_ids></p>
<h2 id="args">Args</h2>
<p>topic_ids(list of ints): list of topic IDs</p>
<h2 id="returns">Returns</h2>
<p>list of str</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_texts(self,  topic_ids=[]):
    &#34;&#34;&#34;
    Returns texts for documents
    with primary topic that is one of &lt;topic_ids&gt;
    Args:
        topic_ids(list of ints): list of topic IDs
    Returns:
        list of str
    &#34;&#34;&#34;
    if not topic_ids: topic_ids = list(range(self.n_topics))
    docs = self.get_docs(topic_ids)
    return [x[0] for x in docs]</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_topics"><code class="name flex">
<span>def <span class="ident">get_topics</span></span>(<span>self, n_words=10, as_string=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of discovered topics</p>
<h2 id="args">Args</h2>
<p>n_words(int): number of words to use in topic summary
as_string(bool): If True, each summary is a space-delimited string instead of list of words</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_topics(self, n_words=10, as_string=True):
    &#34;&#34;&#34;
    Returns a list of discovered topics
    Args:
        n_words(int): number of words to use in topic summary
        as_string(bool): If True, each summary is a space-delimited string instead of list of words
    &#34;&#34;&#34;
    self._check_model()
    feature_names = self.vectorizer.get_feature_names()
    topic_summaries = []
    for topic_idx, topic in enumerate(self.model.components_):
        summary = [feature_names[i] for i in topic.argsort()[:-n_words - 1:-1]]
        if as_string: summary = &#34; &#34;.join(summary)
        topic_summaries.append(summary)
    return topic_summaries</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_word_weights"><code class="name flex">
<span>def <span class="ident">get_word_weights</span></span>(<span>self, topic_id, n_words=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list tuples of the form: (word, weight) for given topic_id.
The weight can be interpreted as the number of times word was assigned to topic with given topic_id.
REFERENCE: <a href="https://stackoverflow.com/a/48890889/13550699">https://stackoverflow.com/a/48890889/13550699</a></p>
<h2 id="args">Args</h2>
<p>topic_id(int): topic ID
n_words=int): number of top words</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_word_weights(self, topic_id, n_words=100):
    &#34;&#34;&#34;
    Returns a list tuples of the form: (word, weight) for given topic_id.
    The weight can be interpreted as the number of times word was assigned to topic with given topic_id.
    REFERENCE: https://stackoverflow.com/a/48890889/13550699
    Args:
        topic_id(int): topic ID
        n_words=int): number of top words
    &#34;&#34;&#34;
    self._check_model()
    if topic_id+1 &gt; len(self.model.components_): 
        raise ValueError(&#39;topic_id must be less than %s&#39; % (len(self.model.components_)))
    feature_names = self.vectorizer.get_feature_names()
    word_probs = self.model.components_[topic_id]
    word_ids = [i for i in word_probs.argsort()[:-n_words - 1:-1]]
    words = [feature_names[i] for i in word_ids]
    probs = [word_probs[i] for i in word_ids]
    return list( zip(words, probs) )</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, texts, threshold=None, harden=False)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of texts</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>If not None, documents with maximum topic scores
less than <threshold> are filtered out</dd>
</dl>
<p>harden(bool): If True, each document is assigned to a single topic for which
it has the highest score</p>
<h2 id="returns">Returns</h2>
<dl>
<dt>if threshold is None:</dt>
<dt><code>
np.ndarray</code></dt>
<dd>topic distribution for each text document</dd>
</dl>
<p>else:
(np.ndarray, np.ndarray): topic distribution and boolean array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, texts, threshold=None, harden=False):
    &#34;&#34;&#34;
    Args:
        texts (list of str): list of texts
        threshold (float): If not None, documents with maximum topic scores
                            less than &lt;threshold&gt; are filtered out
        harden(bool): If True, each document is assigned to a single topic for which
                      it has the highest score
    Returns:
        if threshold is None:
            np.ndarray: topic distribution for each text document
        else:
            (np.ndarray, np.ndarray): topic distribution and boolean array
    &#34;&#34;&#34;
    self._check_model()
    transformed_texts = self.vectorizer.transform(texts)
    X_topics = self.model.transform(transformed_texts)
    #if self.model_type == &#39;nmf&#39;:
        #scores = np.matrix(X_topics)
        #scores_normalized= scores/scores.sum(axis=1)
        #X_topics = scores_normalized
    _idx = np.array([True] * len(texts))
    if threshold is not None:
        _idx = np.amax(X_topics, axis=1) &gt; threshold  # idx of doc that above the threshold
        _idx = np.array(_idx)
        X_topics = X_topics[_idx]
    if harden: X_topics = self._harden_topics(X_topics)
    if threshold is not None:
        return (X_topics, _idx)
    else:
        return X_topics</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.print_topics"><code class="name flex">
<span>def <span class="ident">print_topics</span></span>(<span>self, n_words=10, show_counts=False)</span>
</code></dt>
<dd>
<div class="desc"><p>print topics
n_words(int): number of words to describe each topic
show_counts(bool): If True, print topics with document counts, where
the count is the number of documents with that topic as primary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_topics(self, n_words=10, show_counts=False):
    &#34;&#34;&#34;
    print topics
    n_words(int): number of words to describe each topic
    show_counts(bool): If True, print topics with document counts, where
                       the count is the number of documents with that topic as primary.
    &#34;&#34;&#34;
    topics = self.get_topics(n_words=n_words, as_string=True)
    if show_counts:
        self._check_build()
        topic_counts = sorted([ (k, topics[k], len(v)) for k,v in self.topic_dict.items()], 
                                key=lambda kv:kv[-1], reverse=True)
        for (idx, topic, count) in topic_counts:
            print(&#34;topic:%s | count:%s | %s&#34; %(idx, count, topic))
    else:
        for i, t in enumerate(topics):
            print(&#39;topic %s | %s&#39; % (i, t))
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.recommend"><code class="name flex">
<span>def <span class="ident">recommend</span></span>(<span>self, text=None, doc_topic=None, n=5, n_neighbors=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Given an example document, recommends documents similar to it
from the set of documents supplied to build().</p>
<h2 id="args">Args</h2>
<dl>
<dt>texts(list of str): list of document texts.
Mutually-exclusive with <doc_topics></dt>
<dt>doc_topics(ndarray): pre-computed topic distribution for each document in texts.</dt>
<dt>Mutually-exclusive with <texts>.</dt>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>number of recommendations to return</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>tuples</code></dt>
<dd>each tuple is of the form:
(text, doc_id, topic_probability, topic_id)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def recommend(self, text=None, doc_topic=None, n=5, n_neighbors=100):
    &#34;&#34;&#34;
    Given an example document, recommends documents similar to it
    from the set of documents supplied to build().

    Args:
        texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
        doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                             Mutually-exclusive with &lt;texts&gt;.
        n (int): number of recommendations to return
    Returns:
        list of tuples: each tuple is of the form:
                        (text, doc_id, topic_probability, topic_id)

    &#34;&#34;&#34;
    # error-checks
    if text is not None and doc_topic is not None:
        raise ValueError(&#39;text is mutually-exclusive with doc_topic&#39;)
    if text is None and doc_topic is None:
        raise ValueError(&#39;One of text or doc_topic is required.&#39;)
    if text is not None and type(text) not in [str]:
        raise ValueError(&#39;text must be a str &#39;)
    if  doc_topic is not None and type(doc_topic) not in [np.ndarray]:
        raise ValueError(&#39;doc_topic must be a np.ndarray&#39;)

    if n &gt; n_neighbors: n_neighbors = n

    x_test = [doc_topic]
    if text:
        x_test = self.predict([text])
    docs = self.get_docs()
    indices = self.recommender.kneighbors(x_test, return_distance=False, n_neighbors=n_neighbors)
    results = [doc for i, doc in enumerate(docs) if i in indices]
    return results[:n]</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, fname)</span>
</code></dt>
<dd>
<div class="desc"><p>save TopicModel object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, fname):
    &#34;&#34;&#34;
    save TopicModel object
    &#34;&#34;&#34;

    
    with open(fname+&#39;.tm_vect&#39;, &#39;wb&#39;) as f:
        pickle.dump(self.vectorizer, f)
    with open(fname+&#39;.tm_model&#39;, &#39;wb&#39;) as f:
        pickle.dump(self.model, f)
    params = {&#39;n_topics&#39;: self.n_topics,
              &#39;n_features&#39;: self.n_features,
              &#39;verbose&#39;: self.verbose}
    with open(fname+&#39;.tm_params&#39;, &#39;wb&#39;) as f:
        pickle.dump(params, f)

    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.score"><code class="name flex">
<span>def <span class="ident">score</span></span>(<span>self, texts=None, doc_topics=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a new set of documents (supplied as texts or doc_topics), the score method
uses a One-Class classifier to score documents based on similarity to a
seed set of documents (where seed set is computed by train_scorer() method).</p>
<p>Higher scores indicate a higher degree of similarity.
Positive values represent a binary decision of similar.
Negative values represent a binary decision of dissimlar.
In practice, negative scores closer to zer will also be simlar as One-Class
classifiers are more strict than traditional binary classifiers.
Documents with negative scores closer to zero are good candidates for
inclusion in a training set for binary classification (e.g., active labeling).</p>
<p>NOTE: The score method currently employs the use of LocalOutLierFactor, which
means you should not try to score documents that were used in training. Only
new, unseen documents should be scored for similarity.</p>
<h2 id="args">Args</h2>
<p>texts(list of str): list of document texts.
Mutually-exclusive with <doc_topics>
doc_topics(ndarray): pre-computed topic distribution for each document in texts.
Mutually-exclusive with <texts>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>floats</code></dt>
<dd>larger values indicate higher degree of similarity
positive values indicate a binary decision of similar
negative values indicate binary decision of dissimilar
In practice, negative scores closer to zero will also
be similar as One-class classifiers are more strict
than traditional binary classifiers.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score(self, texts=None, doc_topics=None):
    &#34;&#34;&#34;
    Given a new set of documents (supplied as texts or doc_topics), the score method
    uses a One-Class classifier to score documents based on similarity to a
    seed set of documents (where seed set is computed by train_scorer() method).

    Higher scores indicate a higher degree of similarity.
    Positive values represent a binary decision of similar.
    Negative values represent a binary decision of dissimlar.
    In practice, negative scores closer to zer will also be simlar as One-Class
    classifiers are more strict than traditional binary classifiers.
    Documents with negative scores closer to zero are good candidates for
    inclusion in a training set for binary classification (e.g., active labeling).

    NOTE: The score method currently employs the use of LocalOutLierFactor, which
    means you should not try to score documents that were used in training. Only
    new, unseen documents should be scored for similarity.

    Args:
        texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
        doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                             Mutually-exclusive with &lt;texts&gt;.
    Returns:
        list of floats:  larger values indicate higher degree of similarity
                         positive values indicate a binary decision of similar
                         negative values indicate binary decision of dissimilar
                         In practice, negative scores closer to zero will also 
                         be similar as One-class classifiers are more strict
                         than traditional binary classifiers.

    &#34;&#34;&#34;
    # error-checks
    if texts is not None and doc_topics is not None:
        raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
    if texts is None and doc_topics is None:
        raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
    if texts is not None and type(texts) not in [list, np.ndarray]:
        raise ValueError(&#39;texts must be either a list or numpy ndarray&#39;)
    if  doc_topics is not None and type(doc_topics) not in [np.ndarray]:
        raise ValueError(&#39;doc_topics must be a np.ndarray&#39;)

    x_test = doc_topics
    if texts:
        x_test = self.predict(texts)
    return self.scorer.decision_function(x_test)</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.search"><code class="name flex">
<span>def <span class="ident">search</span></span>(<span>self, query, topic_ids=[], doc_ids=[], case_sensitive=False)</span>
</code></dt>
<dd>
<div class="desc"><p>search documents for query string.</p>
<h2 id="args">Args</h2>
<dl>
<dt>query(str):
the word or phrase to search</dt>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics</dd>
</dl>
<p>case_sensitive(bool):
If True, case sensitive search</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search(self, query, topic_ids=[], doc_ids=[], case_sensitive=False):
    &#34;&#34;&#34;
    search documents for query string.
    Args:
        query(str):  the word or phrase to search
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics
        case_sensitive(bool):  If True, case sensitive search
    &#34;&#34;&#34;

    # setup pattern
    if not case_sensitive: query = query.lower()
    pattern = re.compile(r&#39;\b%s\b&#39; % query)

    # retrive docs
    docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)

    # search
    mb = master_bar(range(1))
    results = []
    for i in mb:
        for doc in progress_bar(docs, parent=mb):
            text = doc[&#39;text&#39;]
            if not case_sensitive: text = text.lower()
            matches = pattern.findall(text)
            if matches: results.append(doc)
        if self.verbose: mb.write(&#39;done.&#39;)
    return results</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, texts, model_type='lda', n_topics=None, n_features=10000, min_df=5, max_df=0.5, stop_words='english', lda_max_iter=5, lda_mode='online', token_pattern=None, hyperparam_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fits a topic model to documents in <texts>.</p>
<h2 id="example">Example</h2>
<p>tm = ktrain.text.get_topic_model(docs, n_topics=20,
n_features=1000, min_df=2, max_df=0.95)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of texts</dd>
<dt><strong><code>n_topics</code></strong> :&ensp;<code>int</code></dt>
<dd>number of topics.
If None, n_topics = min{400, sqrt[# documents/2]})</dd>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum words to consider</dd>
<dt><strong><code>max_df</code></strong> :&ensp;<code>float</code></dt>
<dd>words in more than max_df proportion of docs discarded</dd>
<dt><strong><code>stop_words</code></strong> :&ensp;<code>str</code> or <code>list</code></dt>
<dd>either 'english' for built-in stop words or
a list of stop words to ignore</dd>
<dt><strong><code>lda_max_iter</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum iterations for 'lda'.
5 is default if using lda_mode='online'.
If lda_mode='batch', this should be increased (e.g., 1500).
Ignored if model_type != 'lda'</dd>
<dt><strong><code>lda_mode</code></strong> :&ensp;<code>str</code></dt>
<dd>one of {'online', 'batch'}. Ignored of model_type !='lda'</dd>
</dl>
<p>token_pattern(str): regex pattern to use to tokenize documents.
If None, a default tokenizer will be used
hyperparam_kwargs(dict): hyperparameters for LDA/NMF
Keys in this dict can be any of the following:
alpha: alpha for LDA
default: 5./n_topics
beta: beta for LDA.
default:0.01
nmf_alpha: alpha for NMF.
default:0
l1_ratio: l1_ratio for NMF. default: 0
ngram_range:
whether to consider bigrams, trigrams. default: (1,1) </p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(model, vectorizer)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self,texts, model_type=&#39;lda&#39;, n_topics=None, n_features=10000,
          min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
          lda_max_iter=5, lda_mode=&#39;online&#39;,
          token_pattern=None, hyperparam_kwargs=None):
    &#34;&#34;&#34;
    Fits a topic model to documents in &lt;texts&gt;.
    Example:
        tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                        n_features=1000, min_df=2, max_df=0.95)
    Args:
        texts (list of str): list of texts
        n_topics (int): number of topics.
                        If None, n_topics = min{400, sqrt[# documents/2]})
        n_features (int):  maximum words to consider
        max_df (float): words in more than max_df proportion of docs discarded
        stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                  a list of stop words to ignore
        lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                            If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                            Ignored if model_type != &#39;lda&#39;
        lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored of model_type !=&#39;lda&#39;
        token_pattern(str): regex pattern to use to tokenize documents. 
                            If None, a default tokenizer will be used
        hyperparam_kwargs(dict): hyperparameters for LDA/NMF
                                 Keys in this dict can be any of the following:
                                     alpha: alpha for LDA  default: 5./n_topics
                                     beta: beta for LDA.  default:0.01
                                     nmf_alpha: alpha for NMF.  default:0
                                     l1_ratio: l1_ratio for NMF. default: 0
                                     ngram_range:  whether to consider bigrams, trigrams. default: (1,1) 
                                
    Returns:
        tuple: (model, vectorizer)
    &#34;&#34;&#34;
    if hyperparam_kwargs is None:
        hyperparam_kwargs = {}
    alpha = hyperparam_kwargs.get(&#39;alpha&#39;, 5.0 / n_topics)
    beta = hyperparam_kwargs.get(&#39;beta&#39;, 0.01)
    nmf_alpha = hyperparam_kwargs.get(&#39;nmf_alpha&#39;, 0)
    l1_ratio = hyperparam_kwargs.get(&#39;l1_ratio&#39;, 0)
    ngram_range = hyperparam_kwargs.get(&#39;ngram_range&#39;, (1,1))

    # adjust defaults based on language detected
    if texts is not None:
        lang = TU.detect_lang(texts)
        if lang != &#39;en&#39;:
            stopwords = None if stop_words==&#39;english&#39; else stop_words
            token_pattern = r&#39;(?u)\b\w+\b&#39; if token_pattern is None else token_pattern
        if pp.is_nospace_lang(lang):
            text_list = []
            for t in texts:
                text_list.append(&#39; &#39;.join(jieba.cut(t, HMM=False)))
            texts = text_list
        if self.verbose: print(&#39;lang: %s&#39; % (lang))


    # preprocess texts
    if self.verbose: print(&#39;preprocessing texts...&#39;)
    if token_pattern is None: token_pattern = TU.DEFAULT_TOKEN_PATTERN
    #if token_pattern is None: token_pattern = r&#39;(?u)\b\w\w+\b&#39;
    vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,
                             max_features=n_features, stop_words=stop_words,
                             token_pattern=token_pattern, ngram_range=ngram_range)
    

    x_train = vectorizer.fit_transform(texts)

    # fit model

    if self.verbose: print(&#39;fitting model...&#39;)
    if model_type == &#39;lda&#39;:
        model = LatentDirichletAllocation(n_components=n_topics, max_iter=lda_max_iter,
                                          learning_method=lda_mode, learning_offset=50.,
                                          doc_topic_prior=alpha,
                                          topic_word_prior=beta,
                                          verbose=self.verbose, random_state=0)
    elif model_type == &#39;nmf&#39;:
        model = NMF(
            n_components=n_topics,
            max_iter=lda_max_iter,
            verbose=self.verbose,
            alpha=nmf_alpha,
            l1_ratio=l1_ratio,
            random_state=0)
    else:
        raise ValueError(&#34;unknown model type:&#34;, str(model_type))
    model.fit(x_train)

    # save model and vectorizer and hyperparameter settings
    return (model, vectorizer)</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.train_recommender"><code class="name flex">
<span>def <span class="ident">train_recommender</span></span>(<span>self, n_neighbors=20, metric='minkowski', p=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains a recommender that, given a single document, will return
documents in the corpus that are semantically similar to it.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_neighbors</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_recommender(self, n_neighbors=20, metric=&#39;minkowski&#39;, p=2):
    &#34;&#34;&#34;
    Trains a recommender that, given a single document, will return
    documents in the corpus that are semantically similar to it.

    Args:
        n_neighbors (int): 
    Returns:
        None
    &#34;&#34;&#34;
    from sklearn.neighbors import NearestNeighbors
    rec = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, p=p)
    probs = self.get_doctopics()
    rec.fit(probs)
    self.recommender = rec
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.train_scorer"><code class="name flex">
<span>def <span class="ident">train_scorer</span></span>(<span>self, topic_ids=[], doc_ids=[], n_neighbors=20)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains a scorer that can score documents based on similarity to a
seed set of documents represented by topic_ids and doc_ids.</p>
<p>NOTE: The score method currently employs the use of LocalOutLierFactor, which
means you should not try to score documents that were used in training. Only
new, unseen documents should be scored for similarity.
REFERENCE:
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor</a></p>
<h2 id="args">Args</h2>
<dl>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).
Documents associated</dt>
<dt>with these topic_ids will be used as seed set.</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics.
Documents associated
with these doc_ids will be used as seed set.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_scorer(self, topic_ids=[], doc_ids=[], n_neighbors=20):
    &#34;&#34;&#34;
    Trains a scorer that can score documents based on similarity to a
    seed set of documents represented by topic_ids and doc_ids.

    NOTE: The score method currently employs the use of LocalOutLierFactor, which
    means you should not try to score documents that were used in training. Only
    new, unseen documents should be scored for similarity. 
    REFERENCE: 
    https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor

    Args:
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).  Documents associated
                                 with these topic_ids will be used as seed set.
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics.  Documents associated 
                                with these doc_ids will be used as seed set.
    Returns:
        None
    &#34;&#34;&#34;
    from sklearn.neighbors import LocalOutlierFactor
    clf = LocalOutlierFactor(n_neighbors=n_neighbors, novelty=True, contamination=0.1)
    probs = self.get_doctopics(topic_ids=topic_ids, doc_ids=doc_ids)
    clf.fit(probs)
    self.scorer = clf
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.visualize_documents"><code class="name flex">
<span>def <span class="ident">visualize_documents</span></span>(<span>self, texts=None, doc_topics=None, width=700, height=700, point_size=5, title='Document Visualization', extra_info={}, colors=None, filepath=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a visualization of a set of documents based on model.
If <texts> is supplied, raw documents will be first transformed into document-topic
matrix.
If <doc_topics> is supplied, then this will be used for visualization instead.</p>
<h2 id="args">Args</h2>
<p>texts(list of str): list of document texts.
Mutually-exclusive with <doc_topics>
doc_topics(ndarray): pre-computed topic distribution for each document in texts.
Mutually-exclusive with <texts>.
width(int): width of image
height(int): height of image
point_size(int): size of circles in plot
title(str):
title of visualization
extra_info(dict of lists): A user-supplied information for each datapoint (attributes of the datapoint).
The keys are field names.
The values are lists - each of which must
be the same number of elements as <texts> or <doc_topics>. These fields are displayed
when hovering over datapoints in the visualization.
colors(list of str):
list of Hex color codes for each datapoint.
Length of list must match either len(texts) or doc_topics.shape[0]
filepath(str):
Optional filepath to save the interactive visualization</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize_documents(self, texts=None, doc_topics=None, 
                        width=700, height=700, point_size=5, title=&#39;Document Visualization&#39;,
                        extra_info={},
                        colors=None,
                        filepath=None,):
    &#34;&#34;&#34;
    Generates a visualization of a set of documents based on model.
    If &lt;texts&gt; is supplied, raw documents will be first transformed into document-topic
    matrix.  If &lt;doc_topics&gt; is supplied, then this will be used for visualization instead.
    Args:
        texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
        doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                             Mutually-exclusive with &lt;texts&gt;.
        width(int): width of image
        height(int): height of image
        point_size(int): size of circles in plot
        title(str):  title of visualization
        extra_info(dict of lists): A user-supplied information for each datapoint (attributes of the datapoint).
                                   The keys are field names.  The values are lists - each of which must
                                   be the same number of elements as &lt;texts&gt; or &lt;doc_topics&gt;. These fields are displayed
                                   when hovering over datapoints in the visualization.
        colors(list of str):  list of Hex color codes for each datapoint.
                              Length of list must match either len(texts) or doc_topics.shape[0]
        filepath(str):             Optional filepath to save the interactive visualization
    &#34;&#34;&#34;

    # error-checking
    if texts is not None: length = len(texts)
    else: length = doc_topics.shape[0]
    if colors is not None and len(colors) != length:
        raise ValueError(&#39;length of colors is not consistent with length of texts or doctopics&#39;)
    if texts is not None and doc_topics is not None:
        raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
    if texts is None and doc_topics is None:
        raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
    if extra_info:
        invalid_keys = [&#39;x&#39;, &#39;y&#39;, &#39;topic&#39;, &#39;fill_color&#39;]
        for k in extra_info.keys():
            if k in invalid_keys:
                raise ValueError(&#39;cannot use &#34;%s&#34; as key in extra_info&#39; %(k))
            lst = extra_info[k]
            if len(lst) != length:
                raise ValueError(&#39;texts and extra_info lists must be same size&#39;)

    # check fo bokeh
    try:
        import bokeh.plotting as bp
        from bokeh.plotting import save
        from bokeh.models import HoverTool
        from bokeh.io import output_notebook
    except:
        warnings.warn(&#39;visualize_documents method requires bokeh package: pip install bokeh&#39;)
        return

    # prepare data
    if doc_topics is not None:
        X_topics = doc_topics
    else:
        if self.verbose:  print(&#39;transforming texts...&#39;, end=&#39;&#39;)
        X_topics = self.predict(texts, harden=False)
        if self.verbose: print(&#39;done.&#39;)

    # reduce to 2-D
    if self.verbose:  print(&#39;reducing to 2 dimensions...&#39;, end=&#39;&#39;)
    tsne_model = TSNE(n_components=2, verbose=self.verbose, random_state=0, angle=.99, init=&#39;pca&#39;)
    tsne_lda = tsne_model.fit_transform(X_topics)
    print(&#39;done.&#39;)

    # get random colormap
    colormap = U.get_random_colors(self.n_topics)

    # generate inline visualization in Jupyter notebook
    lda_keys = self._harden_topics(X_topics)
    if colors is None: colors = colormap[lda_keys]
    topic_summaries = self.get_topics(n_words=5)
    os.environ[&#34;BOKEH_RESOURCES&#34;]=&#34;inline&#34;
    output_notebook()
    dct = { 
            &#39;x&#39;:tsne_lda[:,0],
            &#39;y&#39;:tsne_lda[:, 1],
            &#39;topic&#39;:[topic_summaries[tid] for tid in lda_keys],
            &#39;fill_color&#39;:colors,}
    tool_tups = [(&#39;index&#39;, &#39;$index&#39;),
                 (&#39;(x,y)&#39;,&#39;($x,$y)&#39;),
                 (&#39;topic&#39;, &#39;@topic&#39;)]
    for k in extra_info.keys():
        dct[k] = extra_info[k]
        tool_tups.append((k, &#39;@&#39;+k))

    source = bp.ColumnDataSource(data=dct)
    hover = HoverTool( tooltips=tool_tups)
    p = bp.figure(plot_width=width, plot_height=height, 
                  tools=[hover, &#39;save&#39;, &#39;pan&#39;, &#39;wheel_zoom&#39;, &#39;box_zoom&#39;, &#39;reset&#39;],
                  #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                  title=title)
    #plot_lda = bp.figure(plot_width=1400, plot_height=1100,
                       #title=title,
                       #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                       #x_axis_type=None, y_axis_type=None, min_border=1)
    p.circle(&#39;x&#39;, &#39;y&#39;, size=point_size, source=source, fill_color= &#39;fill_color&#39;)
    bp.show(p)
    if filepath is not None:
        bp.output_file(filepath)
        bp.save(p)
    return</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="ktrain.text.eda.TopicModel"><code class="flex name class">
<span>class <span class="ident">get_topic_model</span></span>
<span>(</span><span>texts=None, n_topics=None, n_features=10000, min_df=5, max_df=0.5, stop_words='english', model_type='lda', lda_max_iter=5, lda_mode='online', token_pattern=None, verbose=1, hyperparam_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fits a topic model to documents in <texts>.</p>
<h2 id="example">Example</h2>
<p>tm = ktrain.text.get_topic_model(docs, n_topics=20,
n_features=1000, min_df=2, max_df=0.95)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of texts</dd>
<dt><strong><code>n_topics</code></strong> :&ensp;<code>int</code></dt>
<dd>number of topics.
If None, n_topics = min{400, sqrt[# documents/2]})</dd>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum words to consider</dd>
<dt><strong><code>max_df</code></strong> :&ensp;<code>float</code></dt>
<dd>words in more than max_df proportion of docs discarded</dd>
<dt><strong><code>stop_words</code></strong> :&ensp;<code>str</code> or <code>list</code></dt>
<dd>either 'english' for built-in stop words or
a list of stop words to ignore</dd>
<dt>model_type(str): type of topic model to fit. One of {'lda', 'nmf'}.
Default:'lda'</dt>
<dt><strong><code>lda_max_iter</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum iterations for 'lda'.
5 is default if using lda_mode='online'.
If lda_mode='batch', this should be increased (e.g., 1500).
Ignored if model_type != 'lda'</dd>
<dt><strong><code>lda_mode</code></strong> :&ensp;<code>str</code></dt>
<dd>one of {'online', 'batch'}. Ignored if model_type !='lda'</dd>
</dl>
<p>token_pattern(str): regex pattern to use to tokenize documents.
verbose(bool): verbosity</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TopicModel():


    def __init__(self,texts=None, n_topics=None, n_features=10000, 
                 min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
                 model_type=&#39;lda&#39;,
                 lda_max_iter=5, lda_mode=&#39;online&#39;,
                 token_pattern=None, verbose=1,
                 hyperparam_kwargs=None
    ):
        &#34;&#34;&#34;
        Fits a topic model to documents in &lt;texts&gt;.
        Example:
            tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                            n_features=1000, min_df=2, max_df=0.95)
        Args:
            texts (list of str): list of texts
            n_topics (int): number of topics.
                            If None, n_topics = min{400, sqrt[# documents/2]})
            n_features (int):  maximum words to consider
            max_df (float): words in more than max_df proportion of docs discarded
            stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                      a list of stop words to ignore
            model_type(str): type of topic model to fit. One of {&#39;lda&#39;, &#39;nmf&#39;}.  Default:&#39;lda&#39;
            lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                                If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                                Ignored if model_type != &#39;lda&#39;
            lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored if model_type !=&#39;lda&#39;
            token_pattern(str): regex pattern to use to tokenize documents. 
            verbose(bool): verbosity

        &#34;&#34;&#34;
        self.verbose=verbose

        # estimate n_topics
        if n_topics is None:
            if texts is None:
                raise ValueError(&#39;If n_topics is None, texts must be supplied&#39;)
            estimated = max(1, int(math.floor(math.sqrt(len(texts) / 2))))
            n_topics = min(400, estimated)
            print(&#39;n_topics automatically set to %s&#39; % (n_topics))

        # train model
        if texts is not None:
            (model, vectorizer) = self.train(texts, model_type=model_type,
                                             n_topics=n_topics, n_features=n_features,
                                             min_df = min_df, max_df = max_df, 
                                             stop_words=stop_words,
                                             lda_max_iter=lda_max_iter, lda_mode=lda_mode,
                                             token_pattern=token_pattern,
                                             hyperparam_kwargs=hyperparam_kwargs)
        else:
            vectorizer = None
            model = None



        # save model and vectorizer and hyperparameter settings
        self.vectorizer = vectorizer
        self.model = model
        self.n_topics = n_topics
        self.n_features = n_features
        if verbose: print(&#39;done.&#39;)

        # these variables are set by self.build():
        self.topic_dict = None
        self.doc_topics = None
        self.bool_array = None

        self.scorer = None       # set by self.train_scorer()
        self.recommender = None  # set by self.train_recommender()
        return


    def train(self,texts, model_type=&#39;lda&#39;, n_topics=None, n_features=10000,
              min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
              lda_max_iter=5, lda_mode=&#39;online&#39;,
              token_pattern=None, hyperparam_kwargs=None):
        &#34;&#34;&#34;
        Fits a topic model to documents in &lt;texts&gt;.
        Example:
            tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                            n_features=1000, min_df=2, max_df=0.95)
        Args:
            texts (list of str): list of texts
            n_topics (int): number of topics.
                            If None, n_topics = min{400, sqrt[# documents/2]})
            n_features (int):  maximum words to consider
            max_df (float): words in more than max_df proportion of docs discarded
            stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                      a list of stop words to ignore
            lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                                If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                                Ignored if model_type != &#39;lda&#39;
            lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored of model_type !=&#39;lda&#39;
            token_pattern(str): regex pattern to use to tokenize documents. 
                                If None, a default tokenizer will be used
            hyperparam_kwargs(dict): hyperparameters for LDA/NMF
                                     Keys in this dict can be any of the following:
                                         alpha: alpha for LDA  default: 5./n_topics
                                         beta: beta for LDA.  default:0.01
                                         nmf_alpha: alpha for NMF.  default:0
                                         l1_ratio: l1_ratio for NMF. default: 0
                                         ngram_range:  whether to consider bigrams, trigrams. default: (1,1) 
                                    
        Returns:
            tuple: (model, vectorizer)
        &#34;&#34;&#34;
        if hyperparam_kwargs is None:
            hyperparam_kwargs = {}
        alpha = hyperparam_kwargs.get(&#39;alpha&#39;, 5.0 / n_topics)
        beta = hyperparam_kwargs.get(&#39;beta&#39;, 0.01)
        nmf_alpha = hyperparam_kwargs.get(&#39;nmf_alpha&#39;, 0)
        l1_ratio = hyperparam_kwargs.get(&#39;l1_ratio&#39;, 0)
        ngram_range = hyperparam_kwargs.get(&#39;ngram_range&#39;, (1,1))

        # adjust defaults based on language detected
        if texts is not None:
            lang = TU.detect_lang(texts)
            if lang != &#39;en&#39;:
                stopwords = None if stop_words==&#39;english&#39; else stop_words
                token_pattern = r&#39;(?u)\b\w+\b&#39; if token_pattern is None else token_pattern
            if pp.is_nospace_lang(lang):
                text_list = []
                for t in texts:
                    text_list.append(&#39; &#39;.join(jieba.cut(t, HMM=False)))
                texts = text_list
            if self.verbose: print(&#39;lang: %s&#39; % (lang))


        # preprocess texts
        if self.verbose: print(&#39;preprocessing texts...&#39;)
        if token_pattern is None: token_pattern = TU.DEFAULT_TOKEN_PATTERN
        #if token_pattern is None: token_pattern = r&#39;(?u)\b\w\w+\b&#39;
        vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,
                                 max_features=n_features, stop_words=stop_words,
                                 token_pattern=token_pattern, ngram_range=ngram_range)
        

        x_train = vectorizer.fit_transform(texts)

        # fit model

        if self.verbose: print(&#39;fitting model...&#39;)
        if model_type == &#39;lda&#39;:
            model = LatentDirichletAllocation(n_components=n_topics, max_iter=lda_max_iter,
                                              learning_method=lda_mode, learning_offset=50.,
                                              doc_topic_prior=alpha,
                                              topic_word_prior=beta,
                                              verbose=self.verbose, random_state=0)
        elif model_type == &#39;nmf&#39;:
            model = NMF(
                n_components=n_topics,
                max_iter=lda_max_iter,
                verbose=self.verbose,
                alpha=nmf_alpha,
                l1_ratio=l1_ratio,
                random_state=0)
        else:
            raise ValueError(&#34;unknown model type:&#34;, str(model_type))
        model.fit(x_train)

        # save model and vectorizer and hyperparameter settings
        return (model, vectorizer)


    @property
    def topics(self):
        &#34;&#34;&#34;
        convenience method/property
        &#34;&#34;&#34;
        return self.get_topics()


    def get_document_topic_distribution(self):
        &#34;&#34;&#34;
        Gets the document-topic distribution.
        Each row is a document and each column is a topic
        The output of this method is equivalent to invoking get_doctopics with no arguments.
        &#34;&#34;&#34;
        self._check_build()
        return self.doc_topics


    def get_sorted_docs(self, topic_id):
        &#34;&#34;&#34;
        Returns all docs sorted by relevance to &lt;topic_id&gt;.
        Unlike get_docs, this ranks documents by the supplied topic_id rather
        than the topic_id to which document is most relevant.
        &#34;&#34;&#34;
        docs = self.get_docs()
        d = {}
        for doc in docs: d[doc[&#39;doc_id&#39;]] = doc
        m = self.get_document_topic_distribution()
        doc_ids = (-m[:,topic_id]).argsort()
        return [d[doc_id] for doc_id in doc_ids]



    def get_word_weights(self, topic_id, n_words=100):
        &#34;&#34;&#34;
        Returns a list tuples of the form: (word, weight) for given topic_id.
        The weight can be interpreted as the number of times word was assigned to topic with given topic_id.
        REFERENCE: https://stackoverflow.com/a/48890889/13550699
        Args:
            topic_id(int): topic ID
            n_words=int): number of top words
        &#34;&#34;&#34;
        self._check_model()
        if topic_id+1 &gt; len(self.model.components_): 
            raise ValueError(&#39;topic_id must be less than %s&#39; % (len(self.model.components_)))
        feature_names = self.vectorizer.get_feature_names()
        word_probs = self.model.components_[topic_id]
        word_ids = [i for i in word_probs.argsort()[:-n_words - 1:-1]]
        words = [feature_names[i] for i in word_ids]
        probs = [word_probs[i] for i in word_ids]
        return list( zip(words, probs) )


    def get_topics(self, n_words=10, as_string=True):
        &#34;&#34;&#34;
        Returns a list of discovered topics
        Args:
            n_words(int): number of words to use in topic summary
            as_string(bool): If True, each summary is a space-delimited string instead of list of words
        &#34;&#34;&#34;
        self._check_model()
        feature_names = self.vectorizer.get_feature_names()
        topic_summaries = []
        for topic_idx, topic in enumerate(self.model.components_):
            summary = [feature_names[i] for i in topic.argsort()[:-n_words - 1:-1]]
            if as_string: summary = &#34; &#34;.join(summary)
            topic_summaries.append(summary)
        return topic_summaries


    def print_topics(self, n_words=10, show_counts=False):
        &#34;&#34;&#34;
        print topics
        n_words(int): number of words to describe each topic
        show_counts(bool): If True, print topics with document counts, where
                           the count is the number of documents with that topic as primary.
        &#34;&#34;&#34;
        topics = self.get_topics(n_words=n_words, as_string=True)
        if show_counts:
            self._check_build()
            topic_counts = sorted([ (k, topics[k], len(v)) for k,v in self.topic_dict.items()], 
                                    key=lambda kv:kv[-1], reverse=True)
            for (idx, topic, count) in topic_counts:
                print(&#34;topic:%s | count:%s | %s&#34; %(idx, count, topic))
        else:
            for i, t in enumerate(topics):
                print(&#39;topic %s | %s&#39; % (i, t))
        return


    def build(self, texts, threshold=None):
        &#34;&#34;&#34;
        Builds the document-topic distribution showing the topic probability distirbution
        for each document in &lt;texts&gt; with respect to the learned topic space.
        Args:
            texts (list of str): list of text documents
            threshold (float): If not None, documents with whose highest topic probability
                               is less than threshold are filtered out.
        &#34;&#34;&#34;
        doc_topics, bool_array = self.predict(texts, threshold=threshold)
        self.doc_topics = doc_topics
        self.bool_array = bool_array

        texts = [text for i, text in enumerate(texts) if bool_array[i]]
        self.topic_dict = self._rank_documents(texts, doc_topics=doc_topics)
        return


    def filter(self, lst):
        &#34;&#34;&#34;
        The build method may prune documents based on threshold.
        This method prunes other lists based on how build pruned documents.
        This is useful to filter lists containing metadata associated with documents
        for use with visualize_documents.
        Args:
            lst(list): a list of data
        Returns:
            list:  a filtered list of data based on how build filtered the documents
        &#34;&#34;&#34;
        if len(lst) != self.bool_array.shape[0]:
            raise ValueError(&#39;Length of lst is not consistent with the number of documents &#39; +
                             &#39;supplied to get_topic_model&#39;)
        arr = np.array(lst)
        return list(arr[self.bool_array])
                           

    
    def get_docs(self, topic_ids=[], doc_ids=[], rank=False):
        &#34;&#34;&#34;
        Returns document entries for supplied topic_ids.
        Documents returned are those whose primary topic is topic with given topic_id
        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
            rank(bool): If True, the list is sorted first by topic_id (ascending)
                        and then ty topic probability (descending).
                        Otherwise, list is sorted by doc_id (i.e., the order
                        of texts supplied to self.build (which is the order of self.doc_topics).

        Returns:
            list of dicts:  list of dicts with keys:
                            &#39;text&#39;: text of document
                            &#39;doc_id&#39;: ID of document
                            &#39;topic_proba&#39;: topic probability (or score)
                            &#39;topic_id&#39;: ID of topic
            
        &#34;&#34;&#34;
        self._check_build()
        if not topic_ids:
            topic_ids = list(range(self.n_topics))
        result_texts = []
        for topic_id in topic_ids:
            if topic_id not in self.topic_dict: continue
            texts = [{&#39;text&#39;:tup[0], &#39;doc_id&#39;:tup[1], &#39;topic_proba&#39;:tup[2], &#39;topic_id&#39;:topic_id} for tup in self.topic_dict[topic_id] 
                                                                                                     if not doc_ids or tup[1] in doc_ids]
            result_texts.extend(texts)
        if not rank:
            result_texts = sorted(result_texts, key=lambda x:x[&#39;doc_id&#39;])
        return result_texts


    def get_doctopics(self,  topic_ids=[], doc_ids=[]):
        &#34;&#34;&#34;
        Returns a topic probability distribution for documents
        with primary topic that is one of &lt;topic_ids&gt; and with doc_id in &lt;doc_ids&gt;.

        If no topic_ids or doc_ids are provided, then topic distributions for all documents
        are returned (which equivalent to the output of get_document_topic_distribution).

        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
        Returns:
            np.ndarray: Each row is the topic probability distribution of a document.
                        Array is sorted in the order returned by self.get_docs.
                        
        &#34;&#34;&#34;
        docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)
        return np.array([self.doc_topics[idx] for idx in [x[&#39;doc_id&#39;] for x in docs]])


    def get_texts(self,  topic_ids=[]):
        &#34;&#34;&#34;
        Returns texts for documents
        with primary topic that is one of &lt;topic_ids&gt;
        Args:
            topic_ids(list of ints): list of topic IDs
        Returns:
            list of str
        &#34;&#34;&#34;
        if not topic_ids: topic_ids = list(range(self.n_topics))
        docs = self.get_docs(topic_ids)
        return [x[0] for x in docs]



    def predict(self, texts, threshold=None, harden=False):
        &#34;&#34;&#34;
        Args:
            texts (list of str): list of texts
            threshold (float): If not None, documents with maximum topic scores
                                less than &lt;threshold&gt; are filtered out
            harden(bool): If True, each document is assigned to a single topic for which
                          it has the highest score
        Returns:
            if threshold is None:
                np.ndarray: topic distribution for each text document
            else:
                (np.ndarray, np.ndarray): topic distribution and boolean array
        &#34;&#34;&#34;
        self._check_model()
        transformed_texts = self.vectorizer.transform(texts)
        X_topics = self.model.transform(transformed_texts)
        #if self.model_type == &#39;nmf&#39;:
            #scores = np.matrix(X_topics)
            #scores_normalized= scores/scores.sum(axis=1)
            #X_topics = scores_normalized
        _idx = np.array([True] * len(texts))
        if threshold is not None:
            _idx = np.amax(X_topics, axis=1) &gt; threshold  # idx of doc that above the threshold
            _idx = np.array(_idx)
            X_topics = X_topics[_idx]
        if harden: X_topics = self._harden_topics(X_topics)
        if threshold is not None:
            return (X_topics, _idx)
        else:
            return X_topics


    def visualize_documents(self, texts=None, doc_topics=None, 
                            width=700, height=700, point_size=5, title=&#39;Document Visualization&#39;,
                            extra_info={},
                            colors=None,
                            filepath=None,):
        &#34;&#34;&#34;
        Generates a visualization of a set of documents based on model.
        If &lt;texts&gt; is supplied, raw documents will be first transformed into document-topic
        matrix.  If &lt;doc_topics&gt; is supplied, then this will be used for visualization instead.
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
            width(int): width of image
            height(int): height of image
            point_size(int): size of circles in plot
            title(str):  title of visualization
            extra_info(dict of lists): A user-supplied information for each datapoint (attributes of the datapoint).
                                       The keys are field names.  The values are lists - each of which must
                                       be the same number of elements as &lt;texts&gt; or &lt;doc_topics&gt;. These fields are displayed
                                       when hovering over datapoints in the visualization.
            colors(list of str):  list of Hex color codes for each datapoint.
                                  Length of list must match either len(texts) or doc_topics.shape[0]
            filepath(str):             Optional filepath to save the interactive visualization
        &#34;&#34;&#34;

        # error-checking
        if texts is not None: length = len(texts)
        else: length = doc_topics.shape[0]
        if colors is not None and len(colors) != length:
            raise ValueError(&#39;length of colors is not consistent with length of texts or doctopics&#39;)
        if texts is not None and doc_topics is not None:
            raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
        if texts is None and doc_topics is None:
            raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
        if extra_info:
            invalid_keys = [&#39;x&#39;, &#39;y&#39;, &#39;topic&#39;, &#39;fill_color&#39;]
            for k in extra_info.keys():
                if k in invalid_keys:
                    raise ValueError(&#39;cannot use &#34;%s&#34; as key in extra_info&#39; %(k))
                lst = extra_info[k]
                if len(lst) != length:
                    raise ValueError(&#39;texts and extra_info lists must be same size&#39;)

        # check fo bokeh
        try:
            import bokeh.plotting as bp
            from bokeh.plotting import save
            from bokeh.models import HoverTool
            from bokeh.io import output_notebook
        except:
            warnings.warn(&#39;visualize_documents method requires bokeh package: pip install bokeh&#39;)
            return

        # prepare data
        if doc_topics is not None:
            X_topics = doc_topics
        else:
            if self.verbose:  print(&#39;transforming texts...&#39;, end=&#39;&#39;)
            X_topics = self.predict(texts, harden=False)
            if self.verbose: print(&#39;done.&#39;)

        # reduce to 2-D
        if self.verbose:  print(&#39;reducing to 2 dimensions...&#39;, end=&#39;&#39;)
        tsne_model = TSNE(n_components=2, verbose=self.verbose, random_state=0, angle=.99, init=&#39;pca&#39;)
        tsne_lda = tsne_model.fit_transform(X_topics)
        print(&#39;done.&#39;)

        # get random colormap
        colormap = U.get_random_colors(self.n_topics)

        # generate inline visualization in Jupyter notebook
        lda_keys = self._harden_topics(X_topics)
        if colors is None: colors = colormap[lda_keys]
        topic_summaries = self.get_topics(n_words=5)
        os.environ[&#34;BOKEH_RESOURCES&#34;]=&#34;inline&#34;
        output_notebook()
        dct = { 
                &#39;x&#39;:tsne_lda[:,0],
                &#39;y&#39;:tsne_lda[:, 1],
                &#39;topic&#39;:[topic_summaries[tid] for tid in lda_keys],
                &#39;fill_color&#39;:colors,}
        tool_tups = [(&#39;index&#39;, &#39;$index&#39;),
                     (&#39;(x,y)&#39;,&#39;($x,$y)&#39;),
                     (&#39;topic&#39;, &#39;@topic&#39;)]
        for k in extra_info.keys():
            dct[k] = extra_info[k]
            tool_tups.append((k, &#39;@&#39;+k))

        source = bp.ColumnDataSource(data=dct)
        hover = HoverTool( tooltips=tool_tups)
        p = bp.figure(plot_width=width, plot_height=height, 
                      tools=[hover, &#39;save&#39;, &#39;pan&#39;, &#39;wheel_zoom&#39;, &#39;box_zoom&#39;, &#39;reset&#39;],
                      #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                      title=title)
        #plot_lda = bp.figure(plot_width=1400, plot_height=1100,
                           #title=title,
                           #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                           #x_axis_type=None, y_axis_type=None, min_border=1)
        p.circle(&#39;x&#39;, &#39;y&#39;, size=point_size, source=source, fill_color= &#39;fill_color&#39;)
        bp.show(p)
        if filepath is not None:
            bp.output_file(filepath)
            bp.save(p)
        return


    def train_recommender(self, n_neighbors=20, metric=&#39;minkowski&#39;, p=2):
        &#34;&#34;&#34;
        Trains a recommender that, given a single document, will return
        documents in the corpus that are semantically similar to it.

        Args:
            n_neighbors (int): 
        Returns:
            None
        &#34;&#34;&#34;
        from sklearn.neighbors import NearestNeighbors
        rec = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, p=p)
        probs = self.get_doctopics()
        rec.fit(probs)
        self.recommender = rec
        return



    def recommend(self, text=None, doc_topic=None, n=5, n_neighbors=100):
        &#34;&#34;&#34;
        Given an example document, recommends documents similar to it
        from the set of documents supplied to build().
 
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
            n (int): number of recommendations to return
        Returns:
            list of tuples: each tuple is of the form:
                            (text, doc_id, topic_probability, topic_id)

        &#34;&#34;&#34;
        # error-checks
        if text is not None and doc_topic is not None:
            raise ValueError(&#39;text is mutually-exclusive with doc_topic&#39;)
        if text is None and doc_topic is None:
            raise ValueError(&#39;One of text or doc_topic is required.&#39;)
        if text is not None and type(text) not in [str]:
            raise ValueError(&#39;text must be a str &#39;)
        if  doc_topic is not None and type(doc_topic) not in [np.ndarray]:
            raise ValueError(&#39;doc_topic must be a np.ndarray&#39;)

        if n &gt; n_neighbors: n_neighbors = n

        x_test = [doc_topic]
        if text:
            x_test = self.predict([text])
        docs = self.get_docs()
        indices = self.recommender.kneighbors(x_test, return_distance=False, n_neighbors=n_neighbors)
        results = [doc for i, doc in enumerate(docs) if i in indices]
        return results[:n]




    def train_scorer(self, topic_ids=[], doc_ids=[], n_neighbors=20):
        &#34;&#34;&#34;
        Trains a scorer that can score documents based on similarity to a
        seed set of documents represented by topic_ids and doc_ids.

        NOTE: The score method currently employs the use of LocalOutLierFactor, which
        means you should not try to score documents that were used in training. Only
        new, unseen documents should be scored for similarity. 
        REFERENCE: 
        https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor

        Args:
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).  Documents associated
                                     with these topic_ids will be used as seed set.
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics.  Documents associated 
                                    with these doc_ids will be used as seed set.
        Returns:
            None
        &#34;&#34;&#34;
        from sklearn.neighbors import LocalOutlierFactor
        clf = LocalOutlierFactor(n_neighbors=n_neighbors, novelty=True, contamination=0.1)
        probs = self.get_doctopics(topic_ids=topic_ids, doc_ids=doc_ids)
        clf.fit(probs)
        self.scorer = clf
        return



    def score(self, texts=None, doc_topics=None):
        &#34;&#34;&#34;
        Given a new set of documents (supplied as texts or doc_topics), the score method
        uses a One-Class classifier to score documents based on similarity to a
        seed set of documents (where seed set is computed by train_scorer() method).

        Higher scores indicate a higher degree of similarity.
        Positive values represent a binary decision of similar.
        Negative values represent a binary decision of dissimlar.
        In practice, negative scores closer to zer will also be simlar as One-Class
        classifiers are more strict than traditional binary classifiers.
        Documents with negative scores closer to zero are good candidates for
        inclusion in a training set for binary classification (e.g., active labeling).

        NOTE: The score method currently employs the use of LocalOutLierFactor, which
        means you should not try to score documents that were used in training. Only
        new, unseen documents should be scored for similarity.
 
        Args:
            texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
            doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                                 Mutually-exclusive with &lt;texts&gt;.
        Returns:
            list of floats:  larger values indicate higher degree of similarity
                             positive values indicate a binary decision of similar
                             negative values indicate binary decision of dissimilar
                             In practice, negative scores closer to zero will also 
                             be similar as One-class classifiers are more strict
                             than traditional binary classifiers.

        &#34;&#34;&#34;
        # error-checks
        if texts is not None and doc_topics is not None:
            raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
        if texts is None and doc_topics is None:
            raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
        if texts is not None and type(texts) not in [list, np.ndarray]:
            raise ValueError(&#39;texts must be either a list or numpy ndarray&#39;)
        if  doc_topics is not None and type(doc_topics) not in [np.ndarray]:
            raise ValueError(&#39;doc_topics must be a np.ndarray&#39;)

        x_test = doc_topics
        if texts:
            x_test = self.predict(texts)
        return self.scorer.decision_function(x_test)


    def search(self, query, topic_ids=[], doc_ids=[], case_sensitive=False):
        &#34;&#34;&#34;
        search documents for query string.
        Args:
            query(str):  the word or phrase to search
            topic_ids(list of ints): list of topid IDs where each id is in the range
                                     of range(self.n_topics).
            doc_ids (list of ints): list of document IDs where each id is an index
                                    into self.doctopics
            case_sensitive(bool):  If True, case sensitive search
        &#34;&#34;&#34;

        # setup pattern
        if not case_sensitive: query = query.lower()
        pattern = re.compile(r&#39;\b%s\b&#39; % query)

        # retrive docs
        docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)

        # search
        mb = master_bar(range(1))
        results = []
        for i in mb:
            for doc in progress_bar(docs, parent=mb):
                text = doc[&#39;text&#39;]
                if not case_sensitive: text = text.lower()
                matches = pattern.findall(text)
                if matches: results.append(doc)
            if self.verbose: mb.write(&#39;done.&#39;)
        return results



    def _rank_documents(self, 
                       texts,
                       doc_topics=None):
        &#34;&#34;&#34;
        Rank documents by topic score.
        If topic_index is supplied, rank documents based on relevance to supplied topic.
        Otherwise, rank all texts by their highest topic score (for any topic).
        Args:
            texts(list of str): list of document texts.
            doc_topics(ndarray): pre-computed topic distribution for each document
                                 If None, re-computed from texts.
                              
        Returns:
            dict of lists: each element in list is a tuple of (doc_index, topic_index, score)
            ... where doc_index is an index into either texts 
        &#34;&#34;&#34;
        if doc_topics is not None:
            X_topics = doc_topics
        else:
            if self.verbose: print(&#39;transforming texts to topic space...&#39;)
            X_topics = self.predict(texts)
        topics = np.argmax(X_topics, axis=1)
        scores = np.amax(X_topics, axis=1)
        doc_ids = np.array([i for i, x in enumerate(texts)])
        result = list(zip(texts, doc_ids, topics, scores))
        if self.verbose: print(&#39;done.&#39;)
        result = sorted(result, key=lambda x: x[-1], reverse=True)
        result_dict = {}
        for r in result:
            text = r[0]
            doc_id = r[1]
            topic_id = r[2]
            score = r[3]
            lst = result_dict.get(topic_id, [])
            lst.append((text, doc_id, score))
            result_dict[topic_id] = lst
        return result_dict


    def _harden_topics(self, X_topics):
        &#34;&#34;&#34;
        Transforms soft-clustering to hard-clustering
        &#34;&#34;&#34;
        max_topics = []
        for i in range(X_topics.shape[0]):
            max_topics.append(X_topics[i].argmax())
        X_topics = np.array(max_topics)
        return X_topics


    def _check_build(self):
        self._check_model()
        if self.topic_dict is None: 
            raise Exception(&#39;Must call build() method.&#39;)

    def _check_scorer(self):
        if self.scorer is None:
            raise Exception(&#39;Must call train_scorer()&#39;)

    def _check_recommender(self):
        if self.recommender is None:
            raise Exception(&#39;Must call train_recommender()&#39;)


    def _check_model(self):
        if self.model is None or self.vectorizer is None:
            raise Exception(&#39;Must call train()&#39;)



    def save(self, fname):
        &#34;&#34;&#34;
        save TopicModel object
        &#34;&#34;&#34;

        
        with open(fname+&#39;.tm_vect&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.vectorizer, f)
        with open(fname+&#39;.tm_model&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.model, f)
        params = {&#39;n_topics&#39;: self.n_topics,
                  &#39;n_features&#39;: self.n_features,
                  &#39;verbose&#39;: self.verbose}
        with open(fname+&#39;.tm_params&#39;, &#39;wb&#39;) as f:
            pickle.dump(params, f)

        return</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="ktrain.text.eda.TopicModel.topics"><code class="name">var <span class="ident">topics</span></code></dt>
<dd>
<div class="desc"><p>convenience method/property</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def topics(self):
    &#34;&#34;&#34;
    convenience method/property
    &#34;&#34;&#34;
    return self.get_topics()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="ktrain.text.eda.TopicModel.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, texts, threshold=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the document-topic distribution showing the topic probability distirbution
for each document in <texts> with respect to the learned topic space.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of text documents</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>If not None, documents with whose highest topic probability
is less than threshold are filtered out.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self, texts, threshold=None):
    &#34;&#34;&#34;
    Builds the document-topic distribution showing the topic probability distirbution
    for each document in &lt;texts&gt; with respect to the learned topic space.
    Args:
        texts (list of str): list of text documents
        threshold (float): If not None, documents with whose highest topic probability
                           is less than threshold are filtered out.
    &#34;&#34;&#34;
    doc_topics, bool_array = self.predict(texts, threshold=threshold)
    self.doc_topics = doc_topics
    self.bool_array = bool_array

    texts = [text for i, text in enumerate(texts) if bool_array[i]]
    self.topic_dict = self._rank_documents(texts, doc_topics=doc_topics)
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, lst)</span>
</code></dt>
<dd>
<div class="desc"><p>The build method may prune documents based on threshold.
This method prunes other lists based on how build pruned documents.
This is useful to filter lists containing metadata associated with documents
for use with visualize_documents.</p>
<h2 id="args">Args</h2>
<p>lst(list): a list of data</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>a filtered list of data based on how build filtered the documents</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, lst):
    &#34;&#34;&#34;
    The build method may prune documents based on threshold.
    This method prunes other lists based on how build pruned documents.
    This is useful to filter lists containing metadata associated with documents
    for use with visualize_documents.
    Args:
        lst(list): a list of data
    Returns:
        list:  a filtered list of data based on how build filtered the documents
    &#34;&#34;&#34;
    if len(lst) != self.bool_array.shape[0]:
        raise ValueError(&#39;Length of lst is not consistent with the number of documents &#39; +
                         &#39;supplied to get_topic_model&#39;)
    arr = np.array(lst)
    return list(arr[self.bool_array])</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_docs"><code class="name flex">
<span>def <span class="ident">get_docs</span></span>(<span>self, topic_ids=[], doc_ids=[], rank=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns document entries for supplied topic_ids.
Documents returned are those whose primary topic is topic with given topic_id</p>
<h2 id="args">Args</h2>
<dl>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics</dd>
</dl>
<p>rank(bool): If True, the list is sorted first by topic_id (ascending)
and then ty topic probability (descending).
Otherwise, list is sorted by doc_id (i.e., the order
of texts supplied to self.build (which is the order of self.doc_topics).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>dicts</code></dt>
<dd>list of dicts with keys:
'text': text of document
'doc_id': ID of document
'topic_proba': topic probability (or score)
'topic_id': ID of topic</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_docs(self, topic_ids=[], doc_ids=[], rank=False):
    &#34;&#34;&#34;
    Returns document entries for supplied topic_ids.
    Documents returned are those whose primary topic is topic with given topic_id
    Args:
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics
        rank(bool): If True, the list is sorted first by topic_id (ascending)
                    and then ty topic probability (descending).
                    Otherwise, list is sorted by doc_id (i.e., the order
                    of texts supplied to self.build (which is the order of self.doc_topics).

    Returns:
        list of dicts:  list of dicts with keys:
                        &#39;text&#39;: text of document
                        &#39;doc_id&#39;: ID of document
                        &#39;topic_proba&#39;: topic probability (or score)
                        &#39;topic_id&#39;: ID of topic
        
    &#34;&#34;&#34;
    self._check_build()
    if not topic_ids:
        topic_ids = list(range(self.n_topics))
    result_texts = []
    for topic_id in topic_ids:
        if topic_id not in self.topic_dict: continue
        texts = [{&#39;text&#39;:tup[0], &#39;doc_id&#39;:tup[1], &#39;topic_proba&#39;:tup[2], &#39;topic_id&#39;:topic_id} for tup in self.topic_dict[topic_id] 
                                                                                                 if not doc_ids or tup[1] in doc_ids]
        result_texts.extend(texts)
    if not rank:
        result_texts = sorted(result_texts, key=lambda x:x[&#39;doc_id&#39;])
    return result_texts</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_doctopics"><code class="name flex">
<span>def <span class="ident">get_doctopics</span></span>(<span>self, topic_ids=[], doc_ids=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a topic probability distribution for documents
with primary topic that is one of <topic_ids> and with doc_id in <doc_ids>.</p>
<p>If no topic_ids or doc_ids are provided, then topic distributions for all documents
are returned (which equivalent to the output of get_document_topic_distribution).</p>
<h2 id="args">Args</h2>
<dl>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Each row is the topic probability distribution of a document.
Array is sorted in the order returned by self.get_docs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_doctopics(self,  topic_ids=[], doc_ids=[]):
    &#34;&#34;&#34;
    Returns a topic probability distribution for documents
    with primary topic that is one of &lt;topic_ids&gt; and with doc_id in &lt;doc_ids&gt;.

    If no topic_ids or doc_ids are provided, then topic distributions for all documents
    are returned (which equivalent to the output of get_document_topic_distribution).

    Args:
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics
    Returns:
        np.ndarray: Each row is the topic probability distribution of a document.
                    Array is sorted in the order returned by self.get_docs.
                    
    &#34;&#34;&#34;
    docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)
    return np.array([self.doc_topics[idx] for idx in [x[&#39;doc_id&#39;] for x in docs]])</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_document_topic_distribution"><code class="name flex">
<span>def <span class="ident">get_document_topic_distribution</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the document-topic distribution.
Each row is a document and each column is a topic
The output of this method is equivalent to invoking get_doctopics with no arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_document_topic_distribution(self):
    &#34;&#34;&#34;
    Gets the document-topic distribution.
    Each row is a document and each column is a topic
    The output of this method is equivalent to invoking get_doctopics with no arguments.
    &#34;&#34;&#34;
    self._check_build()
    return self.doc_topics</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_sorted_docs"><code class="name flex">
<span>def <span class="ident">get_sorted_docs</span></span>(<span>self, topic_id)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns all docs sorted by relevance to <topic_id>.
Unlike get_docs, this ranks documents by the supplied topic_id rather
than the topic_id to which document is most relevant.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sorted_docs(self, topic_id):
    &#34;&#34;&#34;
    Returns all docs sorted by relevance to &lt;topic_id&gt;.
    Unlike get_docs, this ranks documents by the supplied topic_id rather
    than the topic_id to which document is most relevant.
    &#34;&#34;&#34;
    docs = self.get_docs()
    d = {}
    for doc in docs: d[doc[&#39;doc_id&#39;]] = doc
    m = self.get_document_topic_distribution()
    doc_ids = (-m[:,topic_id]).argsort()
    return [d[doc_id] for doc_id in doc_ids]</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_texts"><code class="name flex">
<span>def <span class="ident">get_texts</span></span>(<span>self, topic_ids=[])</span>
</code></dt>
<dd>
<div class="desc"><p>Returns texts for documents
with primary topic that is one of <topic_ids></p>
<h2 id="args">Args</h2>
<p>topic_ids(list of ints): list of topic IDs</p>
<h2 id="returns">Returns</h2>
<p>list of str</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_texts(self,  topic_ids=[]):
    &#34;&#34;&#34;
    Returns texts for documents
    with primary topic that is one of &lt;topic_ids&gt;
    Args:
        topic_ids(list of ints): list of topic IDs
    Returns:
        list of str
    &#34;&#34;&#34;
    if not topic_ids: topic_ids = list(range(self.n_topics))
    docs = self.get_docs(topic_ids)
    return [x[0] for x in docs]</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_topics"><code class="name flex">
<span>def <span class="ident">get_topics</span></span>(<span>self, n_words=10, as_string=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of discovered topics</p>
<h2 id="args">Args</h2>
<p>n_words(int): number of words to use in topic summary
as_string(bool): If True, each summary is a space-delimited string instead of list of words</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_topics(self, n_words=10, as_string=True):
    &#34;&#34;&#34;
    Returns a list of discovered topics
    Args:
        n_words(int): number of words to use in topic summary
        as_string(bool): If True, each summary is a space-delimited string instead of list of words
    &#34;&#34;&#34;
    self._check_model()
    feature_names = self.vectorizer.get_feature_names()
    topic_summaries = []
    for topic_idx, topic in enumerate(self.model.components_):
        summary = [feature_names[i] for i in topic.argsort()[:-n_words - 1:-1]]
        if as_string: summary = &#34; &#34;.join(summary)
        topic_summaries.append(summary)
    return topic_summaries</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.get_word_weights"><code class="name flex">
<span>def <span class="ident">get_word_weights</span></span>(<span>self, topic_id, n_words=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list tuples of the form: (word, weight) for given topic_id.
The weight can be interpreted as the number of times word was assigned to topic with given topic_id.
REFERENCE: <a href="https://stackoverflow.com/a/48890889/13550699">https://stackoverflow.com/a/48890889/13550699</a></p>
<h2 id="args">Args</h2>
<p>topic_id(int): topic ID
n_words=int): number of top words</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_word_weights(self, topic_id, n_words=100):
    &#34;&#34;&#34;
    Returns a list tuples of the form: (word, weight) for given topic_id.
    The weight can be interpreted as the number of times word was assigned to topic with given topic_id.
    REFERENCE: https://stackoverflow.com/a/48890889/13550699
    Args:
        topic_id(int): topic ID
        n_words=int): number of top words
    &#34;&#34;&#34;
    self._check_model()
    if topic_id+1 &gt; len(self.model.components_): 
        raise ValueError(&#39;topic_id must be less than %s&#39; % (len(self.model.components_)))
    feature_names = self.vectorizer.get_feature_names()
    word_probs = self.model.components_[topic_id]
    word_ids = [i for i in word_probs.argsort()[:-n_words - 1:-1]]
    words = [feature_names[i] for i in word_ids]
    probs = [word_probs[i] for i in word_ids]
    return list( zip(words, probs) )</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, texts, threshold=None, harden=False)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of texts</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>If not None, documents with maximum topic scores
less than <threshold> are filtered out</dd>
</dl>
<p>harden(bool): If True, each document is assigned to a single topic for which
it has the highest score</p>
<h2 id="returns">Returns</h2>
<dl>
<dt>if threshold is None:</dt>
<dt><code>
np.ndarray</code></dt>
<dd>topic distribution for each text document</dd>
</dl>
<p>else:
(np.ndarray, np.ndarray): topic distribution and boolean array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, texts, threshold=None, harden=False):
    &#34;&#34;&#34;
    Args:
        texts (list of str): list of texts
        threshold (float): If not None, documents with maximum topic scores
                            less than &lt;threshold&gt; are filtered out
        harden(bool): If True, each document is assigned to a single topic for which
                      it has the highest score
    Returns:
        if threshold is None:
            np.ndarray: topic distribution for each text document
        else:
            (np.ndarray, np.ndarray): topic distribution and boolean array
    &#34;&#34;&#34;
    self._check_model()
    transformed_texts = self.vectorizer.transform(texts)
    X_topics = self.model.transform(transformed_texts)
    #if self.model_type == &#39;nmf&#39;:
        #scores = np.matrix(X_topics)
        #scores_normalized= scores/scores.sum(axis=1)
        #X_topics = scores_normalized
    _idx = np.array([True] * len(texts))
    if threshold is not None:
        _idx = np.amax(X_topics, axis=1) &gt; threshold  # idx of doc that above the threshold
        _idx = np.array(_idx)
        X_topics = X_topics[_idx]
    if harden: X_topics = self._harden_topics(X_topics)
    if threshold is not None:
        return (X_topics, _idx)
    else:
        return X_topics</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.print_topics"><code class="name flex">
<span>def <span class="ident">print_topics</span></span>(<span>self, n_words=10, show_counts=False)</span>
</code></dt>
<dd>
<div class="desc"><p>print topics
n_words(int): number of words to describe each topic
show_counts(bool): If True, print topics with document counts, where
the count is the number of documents with that topic as primary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_topics(self, n_words=10, show_counts=False):
    &#34;&#34;&#34;
    print topics
    n_words(int): number of words to describe each topic
    show_counts(bool): If True, print topics with document counts, where
                       the count is the number of documents with that topic as primary.
    &#34;&#34;&#34;
    topics = self.get_topics(n_words=n_words, as_string=True)
    if show_counts:
        self._check_build()
        topic_counts = sorted([ (k, topics[k], len(v)) for k,v in self.topic_dict.items()], 
                                key=lambda kv:kv[-1], reverse=True)
        for (idx, topic, count) in topic_counts:
            print(&#34;topic:%s | count:%s | %s&#34; %(idx, count, topic))
    else:
        for i, t in enumerate(topics):
            print(&#39;topic %s | %s&#39; % (i, t))
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.recommend"><code class="name flex">
<span>def <span class="ident">recommend</span></span>(<span>self, text=None, doc_topic=None, n=5, n_neighbors=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Given an example document, recommends documents similar to it
from the set of documents supplied to build().</p>
<h2 id="args">Args</h2>
<dl>
<dt>texts(list of str): list of document texts.
Mutually-exclusive with <doc_topics></dt>
<dt>doc_topics(ndarray): pre-computed topic distribution for each document in texts.</dt>
<dt>Mutually-exclusive with <texts>.</dt>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>number of recommendations to return</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>tuples</code></dt>
<dd>each tuple is of the form:
(text, doc_id, topic_probability, topic_id)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def recommend(self, text=None, doc_topic=None, n=5, n_neighbors=100):
    &#34;&#34;&#34;
    Given an example document, recommends documents similar to it
    from the set of documents supplied to build().

    Args:
        texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
        doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                             Mutually-exclusive with &lt;texts&gt;.
        n (int): number of recommendations to return
    Returns:
        list of tuples: each tuple is of the form:
                        (text, doc_id, topic_probability, topic_id)

    &#34;&#34;&#34;
    # error-checks
    if text is not None and doc_topic is not None:
        raise ValueError(&#39;text is mutually-exclusive with doc_topic&#39;)
    if text is None and doc_topic is None:
        raise ValueError(&#39;One of text or doc_topic is required.&#39;)
    if text is not None and type(text) not in [str]:
        raise ValueError(&#39;text must be a str &#39;)
    if  doc_topic is not None and type(doc_topic) not in [np.ndarray]:
        raise ValueError(&#39;doc_topic must be a np.ndarray&#39;)

    if n &gt; n_neighbors: n_neighbors = n

    x_test = [doc_topic]
    if text:
        x_test = self.predict([text])
    docs = self.get_docs()
    indices = self.recommender.kneighbors(x_test, return_distance=False, n_neighbors=n_neighbors)
    results = [doc for i, doc in enumerate(docs) if i in indices]
    return results[:n]</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, fname)</span>
</code></dt>
<dd>
<div class="desc"><p>save TopicModel object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, fname):
    &#34;&#34;&#34;
    save TopicModel object
    &#34;&#34;&#34;

    
    with open(fname+&#39;.tm_vect&#39;, &#39;wb&#39;) as f:
        pickle.dump(self.vectorizer, f)
    with open(fname+&#39;.tm_model&#39;, &#39;wb&#39;) as f:
        pickle.dump(self.model, f)
    params = {&#39;n_topics&#39;: self.n_topics,
              &#39;n_features&#39;: self.n_features,
              &#39;verbose&#39;: self.verbose}
    with open(fname+&#39;.tm_params&#39;, &#39;wb&#39;) as f:
        pickle.dump(params, f)

    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.score"><code class="name flex">
<span>def <span class="ident">score</span></span>(<span>self, texts=None, doc_topics=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a new set of documents (supplied as texts or doc_topics), the score method
uses a One-Class classifier to score documents based on similarity to a
seed set of documents (where seed set is computed by train_scorer() method).</p>
<p>Higher scores indicate a higher degree of similarity.
Positive values represent a binary decision of similar.
Negative values represent a binary decision of dissimlar.
In practice, negative scores closer to zer will also be simlar as One-Class
classifiers are more strict than traditional binary classifiers.
Documents with negative scores closer to zero are good candidates for
inclusion in a training set for binary classification (e.g., active labeling).</p>
<p>NOTE: The score method currently employs the use of LocalOutLierFactor, which
means you should not try to score documents that were used in training. Only
new, unseen documents should be scored for similarity.</p>
<h2 id="args">Args</h2>
<p>texts(list of str): list of document texts.
Mutually-exclusive with <doc_topics>
doc_topics(ndarray): pre-computed topic distribution for each document in texts.
Mutually-exclusive with <texts>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>floats</code></dt>
<dd>larger values indicate higher degree of similarity
positive values indicate a binary decision of similar
negative values indicate binary decision of dissimilar
In practice, negative scores closer to zero will also
be similar as One-class classifiers are more strict
than traditional binary classifiers.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score(self, texts=None, doc_topics=None):
    &#34;&#34;&#34;
    Given a new set of documents (supplied as texts or doc_topics), the score method
    uses a One-Class classifier to score documents based on similarity to a
    seed set of documents (where seed set is computed by train_scorer() method).

    Higher scores indicate a higher degree of similarity.
    Positive values represent a binary decision of similar.
    Negative values represent a binary decision of dissimlar.
    In practice, negative scores closer to zer will also be simlar as One-Class
    classifiers are more strict than traditional binary classifiers.
    Documents with negative scores closer to zero are good candidates for
    inclusion in a training set for binary classification (e.g., active labeling).

    NOTE: The score method currently employs the use of LocalOutLierFactor, which
    means you should not try to score documents that were used in training. Only
    new, unseen documents should be scored for similarity.

    Args:
        texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
        doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                             Mutually-exclusive with &lt;texts&gt;.
    Returns:
        list of floats:  larger values indicate higher degree of similarity
                         positive values indicate a binary decision of similar
                         negative values indicate binary decision of dissimilar
                         In practice, negative scores closer to zero will also 
                         be similar as One-class classifiers are more strict
                         than traditional binary classifiers.

    &#34;&#34;&#34;
    # error-checks
    if texts is not None and doc_topics is not None:
        raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
    if texts is None and doc_topics is None:
        raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
    if texts is not None and type(texts) not in [list, np.ndarray]:
        raise ValueError(&#39;texts must be either a list or numpy ndarray&#39;)
    if  doc_topics is not None and type(doc_topics) not in [np.ndarray]:
        raise ValueError(&#39;doc_topics must be a np.ndarray&#39;)

    x_test = doc_topics
    if texts:
        x_test = self.predict(texts)
    return self.scorer.decision_function(x_test)</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.search"><code class="name flex">
<span>def <span class="ident">search</span></span>(<span>self, query, topic_ids=[], doc_ids=[], case_sensitive=False)</span>
</code></dt>
<dd>
<div class="desc"><p>search documents for query string.</p>
<h2 id="args">Args</h2>
<dl>
<dt>query(str):
the word or phrase to search</dt>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics</dd>
</dl>
<p>case_sensitive(bool):
If True, case sensitive search</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def search(self, query, topic_ids=[], doc_ids=[], case_sensitive=False):
    &#34;&#34;&#34;
    search documents for query string.
    Args:
        query(str):  the word or phrase to search
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics
        case_sensitive(bool):  If True, case sensitive search
    &#34;&#34;&#34;

    # setup pattern
    if not case_sensitive: query = query.lower()
    pattern = re.compile(r&#39;\b%s\b&#39; % query)

    # retrive docs
    docs = self.get_docs(topic_ids=topic_ids, doc_ids=doc_ids)

    # search
    mb = master_bar(range(1))
    results = []
    for i in mb:
        for doc in progress_bar(docs, parent=mb):
            text = doc[&#39;text&#39;]
            if not case_sensitive: text = text.lower()
            matches = pattern.findall(text)
            if matches: results.append(doc)
        if self.verbose: mb.write(&#39;done.&#39;)
    return results</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, texts, model_type='lda', n_topics=None, n_features=10000, min_df=5, max_df=0.5, stop_words='english', lda_max_iter=5, lda_mode='online', token_pattern=None, hyperparam_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fits a topic model to documents in <texts>.</p>
<h2 id="example">Example</h2>
<p>tm = ktrain.text.get_topic_model(docs, n_topics=20,
n_features=1000, min_df=2, max_df=0.95)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>texts</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>list of texts</dd>
<dt><strong><code>n_topics</code></strong> :&ensp;<code>int</code></dt>
<dd>number of topics.
If None, n_topics = min{400, sqrt[# documents/2]})</dd>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum words to consider</dd>
<dt><strong><code>max_df</code></strong> :&ensp;<code>float</code></dt>
<dd>words in more than max_df proportion of docs discarded</dd>
<dt><strong><code>stop_words</code></strong> :&ensp;<code>str</code> or <code>list</code></dt>
<dd>either 'english' for built-in stop words or
a list of stop words to ignore</dd>
<dt><strong><code>lda_max_iter</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum iterations for 'lda'.
5 is default if using lda_mode='online'.
If lda_mode='batch', this should be increased (e.g., 1500).
Ignored if model_type != 'lda'</dd>
<dt><strong><code>lda_mode</code></strong> :&ensp;<code>str</code></dt>
<dd>one of {'online', 'batch'}. Ignored of model_type !='lda'</dd>
</dl>
<p>token_pattern(str): regex pattern to use to tokenize documents.
If None, a default tokenizer will be used
hyperparam_kwargs(dict): hyperparameters for LDA/NMF
Keys in this dict can be any of the following:
alpha: alpha for LDA
default: 5./n_topics
beta: beta for LDA.
default:0.01
nmf_alpha: alpha for NMF.
default:0
l1_ratio: l1_ratio for NMF. default: 0
ngram_range:
whether to consider bigrams, trigrams. default: (1,1) </p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(model, vectorizer)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self,texts, model_type=&#39;lda&#39;, n_topics=None, n_features=10000,
          min_df=5, max_df=0.5,  stop_words=&#39;english&#39;,
          lda_max_iter=5, lda_mode=&#39;online&#39;,
          token_pattern=None, hyperparam_kwargs=None):
    &#34;&#34;&#34;
    Fits a topic model to documents in &lt;texts&gt;.
    Example:
        tm = ktrain.text.get_topic_model(docs, n_topics=20, 
                                        n_features=1000, min_df=2, max_df=0.95)
    Args:
        texts (list of str): list of texts
        n_topics (int): number of topics.
                        If None, n_topics = min{400, sqrt[# documents/2]})
        n_features (int):  maximum words to consider
        max_df (float): words in more than max_df proportion of docs discarded
        stop_words (str or list): either &#39;english&#39; for built-in stop words or
                                  a list of stop words to ignore
        lda_max_iter (int): maximum iterations for &#39;lda&#39;.  5 is default if using lda_mode=&#39;online&#39;.
                            If lda_mode=&#39;batch&#39;, this should be increased (e.g., 1500).
                            Ignored if model_type != &#39;lda&#39;
        lda_mode (str):  one of {&#39;online&#39;, &#39;batch&#39;}. Ignored of model_type !=&#39;lda&#39;
        token_pattern(str): regex pattern to use to tokenize documents. 
                            If None, a default tokenizer will be used
        hyperparam_kwargs(dict): hyperparameters for LDA/NMF
                                 Keys in this dict can be any of the following:
                                     alpha: alpha for LDA  default: 5./n_topics
                                     beta: beta for LDA.  default:0.01
                                     nmf_alpha: alpha for NMF.  default:0
                                     l1_ratio: l1_ratio for NMF. default: 0
                                     ngram_range:  whether to consider bigrams, trigrams. default: (1,1) 
                                
    Returns:
        tuple: (model, vectorizer)
    &#34;&#34;&#34;
    if hyperparam_kwargs is None:
        hyperparam_kwargs = {}
    alpha = hyperparam_kwargs.get(&#39;alpha&#39;, 5.0 / n_topics)
    beta = hyperparam_kwargs.get(&#39;beta&#39;, 0.01)
    nmf_alpha = hyperparam_kwargs.get(&#39;nmf_alpha&#39;, 0)
    l1_ratio = hyperparam_kwargs.get(&#39;l1_ratio&#39;, 0)
    ngram_range = hyperparam_kwargs.get(&#39;ngram_range&#39;, (1,1))

    # adjust defaults based on language detected
    if texts is not None:
        lang = TU.detect_lang(texts)
        if lang != &#39;en&#39;:
            stopwords = None if stop_words==&#39;english&#39; else stop_words
            token_pattern = r&#39;(?u)\b\w+\b&#39; if token_pattern is None else token_pattern
        if pp.is_nospace_lang(lang):
            text_list = []
            for t in texts:
                text_list.append(&#39; &#39;.join(jieba.cut(t, HMM=False)))
            texts = text_list
        if self.verbose: print(&#39;lang: %s&#39; % (lang))


    # preprocess texts
    if self.verbose: print(&#39;preprocessing texts...&#39;)
    if token_pattern is None: token_pattern = TU.DEFAULT_TOKEN_PATTERN
    #if token_pattern is None: token_pattern = r&#39;(?u)\b\w\w+\b&#39;
    vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,
                             max_features=n_features, stop_words=stop_words,
                             token_pattern=token_pattern, ngram_range=ngram_range)
    

    x_train = vectorizer.fit_transform(texts)

    # fit model

    if self.verbose: print(&#39;fitting model...&#39;)
    if model_type == &#39;lda&#39;:
        model = LatentDirichletAllocation(n_components=n_topics, max_iter=lda_max_iter,
                                          learning_method=lda_mode, learning_offset=50.,
                                          doc_topic_prior=alpha,
                                          topic_word_prior=beta,
                                          verbose=self.verbose, random_state=0)
    elif model_type == &#39;nmf&#39;:
        model = NMF(
            n_components=n_topics,
            max_iter=lda_max_iter,
            verbose=self.verbose,
            alpha=nmf_alpha,
            l1_ratio=l1_ratio,
            random_state=0)
    else:
        raise ValueError(&#34;unknown model type:&#34;, str(model_type))
    model.fit(x_train)

    # save model and vectorizer and hyperparameter settings
    return (model, vectorizer)</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.train_recommender"><code class="name flex">
<span>def <span class="ident">train_recommender</span></span>(<span>self, n_neighbors=20, metric='minkowski', p=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains a recommender that, given a single document, will return
documents in the corpus that are semantically similar to it.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_neighbors</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_recommender(self, n_neighbors=20, metric=&#39;minkowski&#39;, p=2):
    &#34;&#34;&#34;
    Trains a recommender that, given a single document, will return
    documents in the corpus that are semantically similar to it.

    Args:
        n_neighbors (int): 
    Returns:
        None
    &#34;&#34;&#34;
    from sklearn.neighbors import NearestNeighbors
    rec = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, p=p)
    probs = self.get_doctopics()
    rec.fit(probs)
    self.recommender = rec
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.train_scorer"><code class="name flex">
<span>def <span class="ident">train_scorer</span></span>(<span>self, topic_ids=[], doc_ids=[], n_neighbors=20)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains a scorer that can score documents based on similarity to a
seed set of documents represented by topic_ids and doc_ids.</p>
<p>NOTE: The score method currently employs the use of LocalOutLierFactor, which
means you should not try to score documents that were used in training. Only
new, unseen documents should be scored for similarity.
REFERENCE:
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor</a></p>
<h2 id="args">Args</h2>
<dl>
<dt>topic_ids(list of ints): list of topid IDs where each id is in the range</dt>
<dt>of range(self.n_topics).
Documents associated</dt>
<dt>with these topic_ids will be used as seed set.</dt>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>list</code> of <code>ints</code></dt>
<dd>list of document IDs where each id is an index
into self.doctopics.
Documents associated
with these doc_ids will be used as seed set.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_scorer(self, topic_ids=[], doc_ids=[], n_neighbors=20):
    &#34;&#34;&#34;
    Trains a scorer that can score documents based on similarity to a
    seed set of documents represented by topic_ids and doc_ids.

    NOTE: The score method currently employs the use of LocalOutLierFactor, which
    means you should not try to score documents that were used in training. Only
    new, unseen documents should be scored for similarity. 
    REFERENCE: 
    https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor

    Args:
        topic_ids(list of ints): list of topid IDs where each id is in the range
                                 of range(self.n_topics).  Documents associated
                                 with these topic_ids will be used as seed set.
        doc_ids (list of ints): list of document IDs where each id is an index
                                into self.doctopics.  Documents associated 
                                with these doc_ids will be used as seed set.
    Returns:
        None
    &#34;&#34;&#34;
    from sklearn.neighbors import LocalOutlierFactor
    clf = LocalOutlierFactor(n_neighbors=n_neighbors, novelty=True, contamination=0.1)
    probs = self.get_doctopics(topic_ids=topic_ids, doc_ids=doc_ids)
    clf.fit(probs)
    self.scorer = clf
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.eda.TopicModel.visualize_documents"><code class="name flex">
<span>def <span class="ident">visualize_documents</span></span>(<span>self, texts=None, doc_topics=None, width=700, height=700, point_size=5, title='Document Visualization', extra_info={}, colors=None, filepath=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a visualization of a set of documents based on model.
If <texts> is supplied, raw documents will be first transformed into document-topic
matrix.
If <doc_topics> is supplied, then this will be used for visualization instead.</p>
<h2 id="args">Args</h2>
<p>texts(list of str): list of document texts.
Mutually-exclusive with <doc_topics>
doc_topics(ndarray): pre-computed topic distribution for each document in texts.
Mutually-exclusive with <texts>.
width(int): width of image
height(int): height of image
point_size(int): size of circles in plot
title(str):
title of visualization
extra_info(dict of lists): A user-supplied information for each datapoint (attributes of the datapoint).
The keys are field names.
The values are lists - each of which must
be the same number of elements as <texts> or <doc_topics>. These fields are displayed
when hovering over datapoints in the visualization.
colors(list of str):
list of Hex color codes for each datapoint.
Length of list must match either len(texts) or doc_topics.shape[0]
filepath(str):
Optional filepath to save the interactive visualization</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize_documents(self, texts=None, doc_topics=None, 
                        width=700, height=700, point_size=5, title=&#39;Document Visualization&#39;,
                        extra_info={},
                        colors=None,
                        filepath=None,):
    &#34;&#34;&#34;
    Generates a visualization of a set of documents based on model.
    If &lt;texts&gt; is supplied, raw documents will be first transformed into document-topic
    matrix.  If &lt;doc_topics&gt; is supplied, then this will be used for visualization instead.
    Args:
        texts(list of str): list of document texts.  Mutually-exclusive with &lt;doc_topics&gt;
        doc_topics(ndarray): pre-computed topic distribution for each document in texts.
                             Mutually-exclusive with &lt;texts&gt;.
        width(int): width of image
        height(int): height of image
        point_size(int): size of circles in plot
        title(str):  title of visualization
        extra_info(dict of lists): A user-supplied information for each datapoint (attributes of the datapoint).
                                   The keys are field names.  The values are lists - each of which must
                                   be the same number of elements as &lt;texts&gt; or &lt;doc_topics&gt;. These fields are displayed
                                   when hovering over datapoints in the visualization.
        colors(list of str):  list of Hex color codes for each datapoint.
                              Length of list must match either len(texts) or doc_topics.shape[0]
        filepath(str):             Optional filepath to save the interactive visualization
    &#34;&#34;&#34;

    # error-checking
    if texts is not None: length = len(texts)
    else: length = doc_topics.shape[0]
    if colors is not None and len(colors) != length:
        raise ValueError(&#39;length of colors is not consistent with length of texts or doctopics&#39;)
    if texts is not None and doc_topics is not None:
        raise ValueError(&#39;texts is mutually-exclusive with doc_topics&#39;)
    if texts is None and doc_topics is None:
        raise ValueError(&#39;One of texts or doc_topics is required.&#39;)
    if extra_info:
        invalid_keys = [&#39;x&#39;, &#39;y&#39;, &#39;topic&#39;, &#39;fill_color&#39;]
        for k in extra_info.keys():
            if k in invalid_keys:
                raise ValueError(&#39;cannot use &#34;%s&#34; as key in extra_info&#39; %(k))
            lst = extra_info[k]
            if len(lst) != length:
                raise ValueError(&#39;texts and extra_info lists must be same size&#39;)

    # check fo bokeh
    try:
        import bokeh.plotting as bp
        from bokeh.plotting import save
        from bokeh.models import HoverTool
        from bokeh.io import output_notebook
    except:
        warnings.warn(&#39;visualize_documents method requires bokeh package: pip install bokeh&#39;)
        return

    # prepare data
    if doc_topics is not None:
        X_topics = doc_topics
    else:
        if self.verbose:  print(&#39;transforming texts...&#39;, end=&#39;&#39;)
        X_topics = self.predict(texts, harden=False)
        if self.verbose: print(&#39;done.&#39;)

    # reduce to 2-D
    if self.verbose:  print(&#39;reducing to 2 dimensions...&#39;, end=&#39;&#39;)
    tsne_model = TSNE(n_components=2, verbose=self.verbose, random_state=0, angle=.99, init=&#39;pca&#39;)
    tsne_lda = tsne_model.fit_transform(X_topics)
    print(&#39;done.&#39;)

    # get random colormap
    colormap = U.get_random_colors(self.n_topics)

    # generate inline visualization in Jupyter notebook
    lda_keys = self._harden_topics(X_topics)
    if colors is None: colors = colormap[lda_keys]
    topic_summaries = self.get_topics(n_words=5)
    os.environ[&#34;BOKEH_RESOURCES&#34;]=&#34;inline&#34;
    output_notebook()
    dct = { 
            &#39;x&#39;:tsne_lda[:,0],
            &#39;y&#39;:tsne_lda[:, 1],
            &#39;topic&#39;:[topic_summaries[tid] for tid in lda_keys],
            &#39;fill_color&#39;:colors,}
    tool_tups = [(&#39;index&#39;, &#39;$index&#39;),
                 (&#39;(x,y)&#39;,&#39;($x,$y)&#39;),
                 (&#39;topic&#39;, &#39;@topic&#39;)]
    for k in extra_info.keys():
        dct[k] = extra_info[k]
        tool_tups.append((k, &#39;@&#39;+k))

    source = bp.ColumnDataSource(data=dct)
    hover = HoverTool( tooltips=tool_tups)
    p = bp.figure(plot_width=width, plot_height=height, 
                  tools=[hover, &#39;save&#39;, &#39;pan&#39;, &#39;wheel_zoom&#39;, &#39;box_zoom&#39;, &#39;reset&#39;],
                  #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                  title=title)
    #plot_lda = bp.figure(plot_width=1400, plot_height=1100,
                       #title=title,
                       #tools=&#34;pan,wheel_zoom,box_zoom,reset,hover,previewsave&#34;,
                       #x_axis_type=None, y_axis_type=None, min_border=1)
    p.circle(&#39;x&#39;, &#39;y&#39;, size=point_size, source=source, fill_color= &#39;fill_color&#39;)
    bp.show(p)
    if filepath is not None:
        bp.output_file(filepath)
        bp.save(p)
    return</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ktrain.text" href="index.html">ktrain.text</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ktrain.text.eda.TopicModel" href="#ktrain.text.eda.TopicModel">TopicModel</a></code></h4>
<ul class="">
<li><code><a title="ktrain.text.eda.TopicModel.build" href="#ktrain.text.eda.TopicModel.build">build</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.filter" href="#ktrain.text.eda.TopicModel.filter">filter</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_docs" href="#ktrain.text.eda.TopicModel.get_docs">get_docs</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_doctopics" href="#ktrain.text.eda.TopicModel.get_doctopics">get_doctopics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_document_topic_distribution" href="#ktrain.text.eda.TopicModel.get_document_topic_distribution">get_document_topic_distribution</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_sorted_docs" href="#ktrain.text.eda.TopicModel.get_sorted_docs">get_sorted_docs</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_texts" href="#ktrain.text.eda.TopicModel.get_texts">get_texts</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_topics" href="#ktrain.text.eda.TopicModel.get_topics">get_topics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_word_weights" href="#ktrain.text.eda.TopicModel.get_word_weights">get_word_weights</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.predict" href="#ktrain.text.eda.TopicModel.predict">predict</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.print_topics" href="#ktrain.text.eda.TopicModel.print_topics">print_topics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.recommend" href="#ktrain.text.eda.TopicModel.recommend">recommend</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.save" href="#ktrain.text.eda.TopicModel.save">save</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.score" href="#ktrain.text.eda.TopicModel.score">score</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.search" href="#ktrain.text.eda.TopicModel.search">search</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.topics" href="#ktrain.text.eda.TopicModel.topics">topics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.train" href="#ktrain.text.eda.TopicModel.train">train</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.train_recommender" href="#ktrain.text.eda.TopicModel.train_recommender">train_recommender</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.train_scorer" href="#ktrain.text.eda.TopicModel.train_scorer">train_scorer</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.visualize_documents" href="#ktrain.text.eda.TopicModel.visualize_documents">visualize_documents</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ktrain.text.eda.TopicModel" href="#ktrain.text.eda.TopicModel">TopicModel</a></code></h4>
<ul class="">
<li><code><a title="ktrain.text.eda.TopicModel.build" href="#ktrain.text.eda.TopicModel.build">build</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.filter" href="#ktrain.text.eda.TopicModel.filter">filter</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_docs" href="#ktrain.text.eda.TopicModel.get_docs">get_docs</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_doctopics" href="#ktrain.text.eda.TopicModel.get_doctopics">get_doctopics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_document_topic_distribution" href="#ktrain.text.eda.TopicModel.get_document_topic_distribution">get_document_topic_distribution</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_sorted_docs" href="#ktrain.text.eda.TopicModel.get_sorted_docs">get_sorted_docs</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_texts" href="#ktrain.text.eda.TopicModel.get_texts">get_texts</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_topics" href="#ktrain.text.eda.TopicModel.get_topics">get_topics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.get_word_weights" href="#ktrain.text.eda.TopicModel.get_word_weights">get_word_weights</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.predict" href="#ktrain.text.eda.TopicModel.predict">predict</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.print_topics" href="#ktrain.text.eda.TopicModel.print_topics">print_topics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.recommend" href="#ktrain.text.eda.TopicModel.recommend">recommend</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.save" href="#ktrain.text.eda.TopicModel.save">save</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.score" href="#ktrain.text.eda.TopicModel.score">score</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.search" href="#ktrain.text.eda.TopicModel.search">search</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.topics" href="#ktrain.text.eda.TopicModel.topics">topics</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.train" href="#ktrain.text.eda.TopicModel.train">train</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.train_recommender" href="#ktrain.text.eda.TopicModel.train_recommender">train_recommender</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.train_scorer" href="#ktrain.text.eda.TopicModel.train_scorer">train_scorer</a></code></li>
<li><code><a title="ktrain.text.eda.TopicModel.visualize_documents" href="#ktrain.text.eda.TopicModel.visualize_documents">visualize_documents</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>