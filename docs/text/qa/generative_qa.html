<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>ktrain.text.qa.generative_qa API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ktrain.text.qa.generative_qa</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import sys
import os
import pickle
from typing import Optional
from pathlib import Path

try:
    from paperqa import Docs

    PAPERQA_INSTALLED = True
except ImportError:
    PAPERQA_INSTALLED = False

DOCS = &#34;docs_obj.pkl&#34;


def is_notebook() -&gt; bool:
    try:
        shell = get_ipython().__class__.__name__
        if &#34;google.colab&#34; in sys.modules:
            return True
        elif shell == &#34;ZMQInteractiveShell&#34;:
            return True  # Jupyter notebook or qtconsole
        elif shell == &#34;TerminalInteractiveShell&#34;:
            return False  # Terminal running IPython
        else:
            return False  # Other type (?)
    except NameError:
        return False  # Probably standard Python interpreter


class GenerativeQA:
    &#34;&#34;&#34;
    Question-answering using OpenAI or open-source GPT or GPT-like generative LLM models
    &#34;&#34;&#34;

    def __init__(self, llm=None):
        &#34;&#34;&#34;
        ```
        GenerativeQA constructor

        Args:
          llm(str):  The LLM to use.  If None, gpt-3.5-turbo is used.
        ```
        &#34;&#34;&#34;
        if not PAPERQA_INSTALLED:
            raise Exception(
                &#34;GenerativeQA in ktrain requires the paper-qa package by Andrew White: pip install paper-qa==2.1.1 langchain==0.0.240&#34;
            )
        self.docs = Docs(llm)
        if is_notebook():
            import nest_asyncio

            nest_asyncio.apply()

    def load(self, path: str):
        &#34;&#34;&#34;
        ```
        load previously-saved document vector database from folder specified by path

        Args:
          path(str): folder path
        ```
        &#34;&#34;&#34;
        with open(os.path.join(path, DOCS), &#34;rb&#34;) as f:
            self.docs = pickle.load(f)

    def save(self, path: str):
        &#34;&#34;&#34;
        ```
        Save current document vector database to folder represented by path
        Save the current vector database to disk

        Args:
          path(str): folder path
        ```
        &#34;&#34;&#34;
        if not os.path.exists(path):
            os.makedirs(path)
        self.docs.index_path = Path(path)
        with open(os.path.join(path, DOCS), &#34;wb&#34;) as f:
            pickle.dump(self.docs, f)

    def clear_index(self):
        &#34;&#34;&#34;
        This will delete the entire index.
        &#34;&#34;&#34;
        if input(&#34;are you sure you want to delete the vector index? (y/n)&#34;) != &#34;y&#34;:
            print(&#34;ok - aborting&#34;)
            return
        index_path = self.docs.index_path.as_posix()
        self.docs.clear()
        self.save(index_path)

    def add_doc(
        self,
        path: Optional[str] = None,
        text: Optional[str] = None,
        citation: Optional[str] = None,
        key: Optional[str] = None,
        disable_check: bool = True,
        chunk_chars: Optional[int] = 3000,
    ):
        &#34;&#34;&#34;
        ```
        Add documents to the data store

        Args:
          path(str): Path to the document.  Mutually-exclusive with text parameter.
          text(str): text of document. Mutually-exclusive with path parameter.
          citation(str):  The citation for document that will appear in references below answer.
                          If omitted, the LLM will be used to infer the correct citation from the document text.
          key(str): The key for the document that will appear within the body of the answer when referenced.
                    If omitted, the LLM will be used to infer the correct citaiton from the document text.
          disable_check(bool): A check of the text of the document.
          chunk_chars(int): This is how many characters documents are split into.

        Returns:
          None
        ```
        &#34;&#34;&#34;
        if (path is not None and text is not None) or (path is None and text is None):
            raise ValueError(
                &#34;The path and text parameters are mutually-exclusive and exactly one must be supplied.&#34;
            )
        if (
            path is not None
            and not path.lower().endswith(&#34;.pdf&#34;)
            and not path.lower().endswith(&#34;.txt&#34;)
        ):
            raise ValueError(
                &#34;Currently, the path parameter only accepts files that end with either a .pdf or .txt extension.&#34;
            )

        if text is not None:
            import os
            import tempfile

            fd, fpath = tempfile.mkstemp()
            os.rename(fpath, fpath + &#34;.txt&#34;)
            fpath = fpath + &#34;.txt&#34;
            try:
                with os.fdopen(fd, &#34;w&#34;) as tmp:
                    # do stuff with temp file
                    tmp.write(text)
                key, citation = self.default_key_and_citation(
                    fpath, key=key, citation=citation
                )
                self.add_doc(
                    fpath,
                    citation=citation,
                    key=key,
                    disable_check=disable_check,
                    chunk_chars=chunk_chars,
                )
            finally:
                pass
            return
        key, citation = self.default_key_and_citation(path, key=key, citation=citation)
        self.docs.add(
            path=path,
            citation=citation,
            key=key,
            disable_check=disable_check,
            chunk_chars=chunk_chars,
        )
        return

    def query(
        self,
        query: str,
        k: int = 10,
        max_sources: int = 5,
        length_prompt: str = &#34;about 100 words&#34;,
        marginal_relevance: bool = True,
        answer=None,
        key_filter: Optional[bool] = None,
        show_token_usage=False,
        # get_callbacks: Callable[[str], AsyncCallbackHandler] = lambda x: [],
    ):
        &#34;&#34;&#34;
        ```
        Query for cited answers
        ```
        &#34;&#34;&#34;
        try:
            result = self.docs.query(
                query=query,
                k=k,
                max_sources=max_sources,
                length_prompt=length_prompt,
                marginal_relevance=marginal_relevance,
                answer=answer,
                key_filter=key_filter,
            )
            if not show_token_usage:
                result.formatted_answer = result.formatted_answer.split(&#34;Tokens Used&#34;)[
                    0
                ]
            return result
        except RuntimeError:
            raise Exception(
                &#34;There was a RuntimeError - try addding  the following to the top of your notebook:\nimport nest_asyncio\nnest_asyncio.apply()&#34;
            )

    def default_key_and_citation(
        self, path: str, key: Optional[str] = None, citation: Optional[str] = None
    ):
        &#34;&#34;&#34;
        ```
        Get default key and citation
        ```
        &#34;&#34;&#34;
        if path.endswith(&#34;.pdf&#34;):
            return (key, citation)
        default_key = self.compute_key(path)
        if key is None:
            key = default_key
        if citation is None:
            citation = f&#34;Document {default_key}&#34;
        return (key, citation)

    def compute_key(self, path: str):
        &#34;&#34;&#34;
        ```
        compute MD5 hash
        ```
        &#34;&#34;&#34;
        from paperqa.utils import md5sum

        return f&#34;md5:{md5sum(path)}&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ktrain.text.qa.generative_qa.is_notebook"><code class="name flex">
<span>def <span class="ident">is_notebook</span></span>(<span>) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_notebook() -&gt; bool:
    try:
        shell = get_ipython().__class__.__name__
        if &#34;google.colab&#34; in sys.modules:
            return True
        elif shell == &#34;ZMQInteractiveShell&#34;:
            return True  # Jupyter notebook or qtconsole
        elif shell == &#34;TerminalInteractiveShell&#34;:
            return False  # Terminal running IPython
        else:
            return False  # Other type (?)
    except NameError:
        return False  # Probably standard Python interpreter</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA"><code class="flex name class">
<span>class <span class="ident">GenerativeQA</span></span>
<span>(</span><span>llm=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Question-answering using OpenAI or open-source GPT or GPT-like generative LLM models</p>
<pre><code>GenerativeQA constructor

Args:
  llm(str):  The LLM to use.  If None, gpt-3.5-turbo is used.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GenerativeQA:
    &#34;&#34;&#34;
    Question-answering using OpenAI or open-source GPT or GPT-like generative LLM models
    &#34;&#34;&#34;

    def __init__(self, llm=None):
        &#34;&#34;&#34;
        ```
        GenerativeQA constructor

        Args:
          llm(str):  The LLM to use.  If None, gpt-3.5-turbo is used.
        ```
        &#34;&#34;&#34;
        if not PAPERQA_INSTALLED:
            raise Exception(
                &#34;GenerativeQA in ktrain requires the paper-qa package by Andrew White: pip install paper-qa==2.1.1 langchain==0.0.240&#34;
            )
        self.docs = Docs(llm)
        if is_notebook():
            import nest_asyncio

            nest_asyncio.apply()

    def load(self, path: str):
        &#34;&#34;&#34;
        ```
        load previously-saved document vector database from folder specified by path

        Args:
          path(str): folder path
        ```
        &#34;&#34;&#34;
        with open(os.path.join(path, DOCS), &#34;rb&#34;) as f:
            self.docs = pickle.load(f)

    def save(self, path: str):
        &#34;&#34;&#34;
        ```
        Save current document vector database to folder represented by path
        Save the current vector database to disk

        Args:
          path(str): folder path
        ```
        &#34;&#34;&#34;
        if not os.path.exists(path):
            os.makedirs(path)
        self.docs.index_path = Path(path)
        with open(os.path.join(path, DOCS), &#34;wb&#34;) as f:
            pickle.dump(self.docs, f)

    def clear_index(self):
        &#34;&#34;&#34;
        This will delete the entire index.
        &#34;&#34;&#34;
        if input(&#34;are you sure you want to delete the vector index? (y/n)&#34;) != &#34;y&#34;:
            print(&#34;ok - aborting&#34;)
            return
        index_path = self.docs.index_path.as_posix()
        self.docs.clear()
        self.save(index_path)

    def add_doc(
        self,
        path: Optional[str] = None,
        text: Optional[str] = None,
        citation: Optional[str] = None,
        key: Optional[str] = None,
        disable_check: bool = True,
        chunk_chars: Optional[int] = 3000,
    ):
        &#34;&#34;&#34;
        ```
        Add documents to the data store

        Args:
          path(str): Path to the document.  Mutually-exclusive with text parameter.
          text(str): text of document. Mutually-exclusive with path parameter.
          citation(str):  The citation for document that will appear in references below answer.
                          If omitted, the LLM will be used to infer the correct citation from the document text.
          key(str): The key for the document that will appear within the body of the answer when referenced.
                    If omitted, the LLM will be used to infer the correct citaiton from the document text.
          disable_check(bool): A check of the text of the document.
          chunk_chars(int): This is how many characters documents are split into.

        Returns:
          None
        ```
        &#34;&#34;&#34;
        if (path is not None and text is not None) or (path is None and text is None):
            raise ValueError(
                &#34;The path and text parameters are mutually-exclusive and exactly one must be supplied.&#34;
            )
        if (
            path is not None
            and not path.lower().endswith(&#34;.pdf&#34;)
            and not path.lower().endswith(&#34;.txt&#34;)
        ):
            raise ValueError(
                &#34;Currently, the path parameter only accepts files that end with either a .pdf or .txt extension.&#34;
            )

        if text is not None:
            import os
            import tempfile

            fd, fpath = tempfile.mkstemp()
            os.rename(fpath, fpath + &#34;.txt&#34;)
            fpath = fpath + &#34;.txt&#34;
            try:
                with os.fdopen(fd, &#34;w&#34;) as tmp:
                    # do stuff with temp file
                    tmp.write(text)
                key, citation = self.default_key_and_citation(
                    fpath, key=key, citation=citation
                )
                self.add_doc(
                    fpath,
                    citation=citation,
                    key=key,
                    disable_check=disable_check,
                    chunk_chars=chunk_chars,
                )
            finally:
                pass
            return
        key, citation = self.default_key_and_citation(path, key=key, citation=citation)
        self.docs.add(
            path=path,
            citation=citation,
            key=key,
            disable_check=disable_check,
            chunk_chars=chunk_chars,
        )
        return

    def query(
        self,
        query: str,
        k: int = 10,
        max_sources: int = 5,
        length_prompt: str = &#34;about 100 words&#34;,
        marginal_relevance: bool = True,
        answer=None,
        key_filter: Optional[bool] = None,
        show_token_usage=False,
        # get_callbacks: Callable[[str], AsyncCallbackHandler] = lambda x: [],
    ):
        &#34;&#34;&#34;
        ```
        Query for cited answers
        ```
        &#34;&#34;&#34;
        try:
            result = self.docs.query(
                query=query,
                k=k,
                max_sources=max_sources,
                length_prompt=length_prompt,
                marginal_relevance=marginal_relevance,
                answer=answer,
                key_filter=key_filter,
            )
            if not show_token_usage:
                result.formatted_answer = result.formatted_answer.split(&#34;Tokens Used&#34;)[
                    0
                ]
            return result
        except RuntimeError:
            raise Exception(
                &#34;There was a RuntimeError - try addding  the following to the top of your notebook:\nimport nest_asyncio\nnest_asyncio.apply()&#34;
            )

    def default_key_and_citation(
        self, path: str, key: Optional[str] = None, citation: Optional[str] = None
    ):
        &#34;&#34;&#34;
        ```
        Get default key and citation
        ```
        &#34;&#34;&#34;
        if path.endswith(&#34;.pdf&#34;):
            return (key, citation)
        default_key = self.compute_key(path)
        if key is None:
            key = default_key
        if citation is None:
            citation = f&#34;Document {default_key}&#34;
        return (key, citation)

    def compute_key(self, path: str):
        &#34;&#34;&#34;
        ```
        compute MD5 hash
        ```
        &#34;&#34;&#34;
        from paperqa.utils import md5sum

        return f&#34;md5:{md5sum(path)}&#34;</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA.add_doc"><code class="name flex">
<span>def <span class="ident">add_doc</span></span>(<span>self, path: Optional[str] = None, text: Optional[str] = None, citation: Optional[str] = None, key: Optional[str] = None, disable_check: bool = True, chunk_chars: Optional[int] = 3000)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Add documents to the data store

Args:
  path(str): Path to the document.  Mutually-exclusive with text parameter.
  text(str): text of document. Mutually-exclusive with path parameter.
  citation(str):  The citation for document that will appear in references below answer.
                  If omitted, the LLM will be used to infer the correct citation from the document text.
  key(str): The key for the document that will appear within the body of the answer when referenced.
            If omitted, the LLM will be used to infer the correct citaiton from the document text.
  disable_check(bool): A check of the text of the document.
  chunk_chars(int): This is how many characters documents are split into.

Returns:
  None
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_doc(
    self,
    path: Optional[str] = None,
    text: Optional[str] = None,
    citation: Optional[str] = None,
    key: Optional[str] = None,
    disable_check: bool = True,
    chunk_chars: Optional[int] = 3000,
):
    &#34;&#34;&#34;
    ```
    Add documents to the data store

    Args:
      path(str): Path to the document.  Mutually-exclusive with text parameter.
      text(str): text of document. Mutually-exclusive with path parameter.
      citation(str):  The citation for document that will appear in references below answer.
                      If omitted, the LLM will be used to infer the correct citation from the document text.
      key(str): The key for the document that will appear within the body of the answer when referenced.
                If omitted, the LLM will be used to infer the correct citaiton from the document text.
      disable_check(bool): A check of the text of the document.
      chunk_chars(int): This is how many characters documents are split into.

    Returns:
      None
    ```
    &#34;&#34;&#34;
    if (path is not None and text is not None) or (path is None and text is None):
        raise ValueError(
            &#34;The path and text parameters are mutually-exclusive and exactly one must be supplied.&#34;
        )
    if (
        path is not None
        and not path.lower().endswith(&#34;.pdf&#34;)
        and not path.lower().endswith(&#34;.txt&#34;)
    ):
        raise ValueError(
            &#34;Currently, the path parameter only accepts files that end with either a .pdf or .txt extension.&#34;
        )

    if text is not None:
        import os
        import tempfile

        fd, fpath = tempfile.mkstemp()
        os.rename(fpath, fpath + &#34;.txt&#34;)
        fpath = fpath + &#34;.txt&#34;
        try:
            with os.fdopen(fd, &#34;w&#34;) as tmp:
                # do stuff with temp file
                tmp.write(text)
            key, citation = self.default_key_and_citation(
                fpath, key=key, citation=citation
            )
            self.add_doc(
                fpath,
                citation=citation,
                key=key,
                disable_check=disable_check,
                chunk_chars=chunk_chars,
            )
        finally:
            pass
        return
    key, citation = self.default_key_and_citation(path, key=key, citation=citation)
    self.docs.add(
        path=path,
        citation=citation,
        key=key,
        disable_check=disable_check,
        chunk_chars=chunk_chars,
    )
    return</code></pre>
</details>
</dd>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA.clear_index"><code class="name flex">
<span>def <span class="ident">clear_index</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This will delete the entire index.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_index(self):
    &#34;&#34;&#34;
    This will delete the entire index.
    &#34;&#34;&#34;
    if input(&#34;are you sure you want to delete the vector index? (y/n)&#34;) != &#34;y&#34;:
        print(&#34;ok - aborting&#34;)
        return
    index_path = self.docs.index_path.as_posix()
    self.docs.clear()
    self.save(index_path)</code></pre>
</details>
</dd>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA.compute_key"><code class="name flex">
<span>def <span class="ident">compute_key</span></span>(<span>self, path: str)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>compute MD5 hash
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_key(self, path: str):
    &#34;&#34;&#34;
    ```
    compute MD5 hash
    ```
    &#34;&#34;&#34;
    from paperqa.utils import md5sum

    return f&#34;md5:{md5sum(path)}&#34;</code></pre>
</details>
</dd>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA.default_key_and_citation"><code class="name flex">
<span>def <span class="ident">default_key_and_citation</span></span>(<span>self, path: str, key: Optional[str] = None, citation: Optional[str] = None)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Get default key and citation
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def default_key_and_citation(
    self, path: str, key: Optional[str] = None, citation: Optional[str] = None
):
    &#34;&#34;&#34;
    ```
    Get default key and citation
    ```
    &#34;&#34;&#34;
    if path.endswith(&#34;.pdf&#34;):
        return (key, citation)
    default_key = self.compute_key(path)
    if key is None:
        key = default_key
    if citation is None:
        citation = f&#34;Document {default_key}&#34;
    return (key, citation)</code></pre>
</details>
</dd>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self, path: str)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>load previously-saved document vector database from folder specified by path

Args:
  path(str): folder path
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(self, path: str):
    &#34;&#34;&#34;
    ```
    load previously-saved document vector database from folder specified by path

    Args:
      path(str): folder path
    ```
    &#34;&#34;&#34;
    with open(os.path.join(path, DOCS), &#34;rb&#34;) as f:
        self.docs = pickle.load(f)</code></pre>
</details>
</dd>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA.query"><code class="name flex">
<span>def <span class="ident">query</span></span>(<span>self, query: str, k: int = 10, max_sources: int = 5, length_prompt: str = 'about 100 words', marginal_relevance: bool = True, answer=None, key_filter: Optional[bool] = None, show_token_usage=False)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Query for cited answers
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def query(
    self,
    query: str,
    k: int = 10,
    max_sources: int = 5,
    length_prompt: str = &#34;about 100 words&#34;,
    marginal_relevance: bool = True,
    answer=None,
    key_filter: Optional[bool] = None,
    show_token_usage=False,
    # get_callbacks: Callable[[str], AsyncCallbackHandler] = lambda x: [],
):
    &#34;&#34;&#34;
    ```
    Query for cited answers
    ```
    &#34;&#34;&#34;
    try:
        result = self.docs.query(
            query=query,
            k=k,
            max_sources=max_sources,
            length_prompt=length_prompt,
            marginal_relevance=marginal_relevance,
            answer=answer,
            key_filter=key_filter,
        )
        if not show_token_usage:
            result.formatted_answer = result.formatted_answer.split(&#34;Tokens Used&#34;)[
                0
            ]
        return result
    except RuntimeError:
        raise Exception(
            &#34;There was a RuntimeError - try addding  the following to the top of your notebook:\nimport nest_asyncio\nnest_asyncio.apply()&#34;
        )</code></pre>
</details>
</dd>
<dt id="ktrain.text.qa.generative_qa.GenerativeQA.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, path: str)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Save current document vector database to folder represented by path
Save the current vector database to disk

Args:
  path(str): folder path
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, path: str):
    &#34;&#34;&#34;
    ```
    Save current document vector database to folder represented by path
    Save the current vector database to disk

    Args:
      path(str): folder path
    ```
    &#34;&#34;&#34;
    if not os.path.exists(path):
        os.makedirs(path)
    self.docs.index_path = Path(path)
    with open(os.path.join(path, DOCS), &#34;wb&#34;) as f:
        pickle.dump(self.docs, f)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ktrain.text.qa" href="index.html">ktrain.text.qa</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ktrain.text.qa.generative_qa.is_notebook" href="#ktrain.text.qa.generative_qa.is_notebook">is_notebook</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ktrain.text.qa.generative_qa.GenerativeQA" href="#ktrain.text.qa.generative_qa.GenerativeQA">GenerativeQA</a></code></h4>
<ul class="">
<li><code><a title="ktrain.text.qa.generative_qa.GenerativeQA.add_doc" href="#ktrain.text.qa.generative_qa.GenerativeQA.add_doc">add_doc</a></code></li>
<li><code><a title="ktrain.text.qa.generative_qa.GenerativeQA.clear_index" href="#ktrain.text.qa.generative_qa.GenerativeQA.clear_index">clear_index</a></code></li>
<li><code><a title="ktrain.text.qa.generative_qa.GenerativeQA.compute_key" href="#ktrain.text.qa.generative_qa.GenerativeQA.compute_key">compute_key</a></code></li>
<li><code><a title="ktrain.text.qa.generative_qa.GenerativeQA.default_key_and_citation" href="#ktrain.text.qa.generative_qa.GenerativeQA.default_key_and_citation">default_key_and_citation</a></code></li>
<li><code><a title="ktrain.text.qa.generative_qa.GenerativeQA.load" href="#ktrain.text.qa.generative_qa.GenerativeQA.load">load</a></code></li>
<li><code><a title="ktrain.text.qa.generative_qa.GenerativeQA.query" href="#ktrain.text.qa.generative_qa.GenerativeQA.query">query</a></code></li>
<li><code><a title="ktrain.text.qa.generative_qa.GenerativeQA.save" href="#ktrain.text.qa.generative_qa.GenerativeQA.save">save</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>