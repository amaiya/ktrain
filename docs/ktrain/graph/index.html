<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ktrain.graph API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ktrain.graph</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .models import *
from .data import *
#from .predictor import *
__all__ = [
           &#39;graph_nodes_from_csv&#39;,
           &#39;graph_links_from_csv&#39;,
           &#39;print_node_classifiers&#39;,
           &#39;print_link_predictors&#39;,
           &#39;graph_node_classifier&#39;,
           &#39;graph_link_predictor&#39;
           ]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="ktrain.graph.data" href="data.html">ktrain.graph.data</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.graph.learner" href="learner.html">ktrain.graph.learner</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.graph.models" href="models.html">ktrain.graph.models</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.graph.predictor" href="predictor.html">ktrain.graph.predictor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.graph.preprocessor" href="preprocessor.html">ktrain.graph.preprocessor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.graph.sg_wrappers" href="sg_wrappers.html">ktrain.graph.sg_wrappers</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ktrain.graph.graph_link_predictor"><code class="name flex">
<span>def <span class="ident">graph_link_predictor</span></span>(<span>name, train_data, preproc, layer_sizes=[20, 20], verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Build and return a neural link prediction model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>one of:
- 'graphsage' for GraphSAGE model
(only GraphSAGE currently supported)</dd>
<dt><strong><code>train_data</code></strong> :&ensp;<code>LinkSequenceWrapper</code></dt>
<dd>a ktrain.graph.sg_wrappers.LinkSequenceWrapper object</dd>
<dt>preproc(LinkPreprocessor): a LinkPreprocessor instance</dt>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>verbosity of output</dd>
</dl>
<h2 id="return">Return</h2>
<p>model (Model): A Keras Model instance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def graph_link_predictor(name, train_data, preproc, layer_sizes=[20,20], verbose=1):
    &#34;&#34;&#34;
    Build and return a neural link prediction model.

    Args:
        name (string): one of:
                      - &#39;graphsage&#39; for GraphSAGE model 
                      (only GraphSAGE currently supported)

        train_data (LinkSequenceWrapper): a ktrain.graph.sg_wrappers.LinkSequenceWrapper object
        preproc(LinkPreprocessor): a LinkPreprocessor instance
        verbose (boolean): verbosity of output
    Return:
        model (Model): A Keras Model instance
    &#34;&#34;&#34;
    from .sg_wrappers import LinkSequenceWrapper

    # check argument
    if not isinstance(train_data, LinkSequenceWrapper):
        err =&#34;&#34;&#34;
            train_data must be a ktrain.graph.sg_wrappers.LinkSequenceWrapper object
            &#34;&#34;&#34;
        raise Exception(err)
    if len(layer_sizes) != len(preproc.sample_sizes):
        raise ValueError(&#39;number of layer_sizes must match len(preproc.sample_sizes)&#39;)

    num_classes = U.nclasses_from_data(train_data)


    # set loss and activations
    loss_func = &#39;categorical_crossentropy&#39;
    activation = &#39;softmax&#39;

    # import stellargraph
    try:
        import stellargraph as sg
        from stellargraph.layer import GraphSAGE, link_classification
    except:
        raise Exception(SG_ERRMSG)
    if version.parse(sg.__version__) &lt; version.parse(&#39;0.8&#39;):
        raise Exception(SG_ERRMSG)



    # build a GraphSAGE link prediction model
    graphsage = GraphSAGE(layer_sizes=layer_sizes, generator=train_data, bias=True, dropout=0.3) 
    x_inp, x_out = graphsage.build()
    prediction = link_classification( output_dim=1, output_act=&#34;relu&#34;, edge_embedding_method=&#39;ip&#39;)(x_out)
    model = Model(inputs=x_inp, outputs=prediction)
    model.compile( optimizer=U.DEFAULT_OPT, loss=&#39;binary_crossentropy&#39;, metrics=[&#34;accuracy&#34;])
    return model</code></pre>
</details>
</dd>
<dt id="ktrain.graph.graph_links_from_csv"><code class="name flex">
<span>def <span class="ident">graph_links_from_csv</span></span>(<span>nodes_filepath, links_filepath, sample_sizes=[10, 20], train_pct=0.1, val_pct=0.1, sep=',', holdout_pct=None, holdout_for_inductive=False, missing_label_value=None, random_state=None, verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads graph data from CSV files.
Returns generators for links in graph for use with GraphSAGE model.</p>
<h2 id="args">Args</h2>
<dl>
<dt>nodes_filepath(str): file path to training CSV containing node attributes</dt>
<dt>links_filepath(str): file path to training CSV describing links among nodes</dt>
<dt>sample_sizes(int): Number of nodes to sample at each neighborhood level.</dt>
<dt>train_pct(float): Proportion of edges to use for training.</dt>
<dt>Default is 0.1.</dt>
<dt>Note that train_pct is applied after val_pct is applied.</dt>
<dt>val_pct(float): Proportion of edges to use for validation</dt>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>delimiter for CSVs. Default is comma.</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code></dt>
<dd>random seed for train/test split</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>verbosity</dd>
</dl>
<h2 id="return">Return</h2>
<p>tuple of EdgeSequenceWrapper objects for train and validation sets and LinkPreprocessor</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def graph_links_from_csv(nodes_filepath, 
                         links_filepath,
                         sample_sizes=[10, 20],
                         train_pct=0.1, val_pct=0.1, sep=&#39;,&#39;, 
                         holdout_pct=None, 
                         holdout_for_inductive=False,
                         missing_label_value=None,
                         random_state=None,
                         verbose=1):
    &#34;&#34;&#34;
    Loads graph data from CSV files. 
    Returns generators for links in graph for use with GraphSAGE model.
    Args:
        nodes_filepath(str): file path to training CSV containing node attributes
        links_filepath(str): file path to training CSV describing links among nodes
        sample_sizes(int): Number of nodes to sample at each neighborhood level.
        train_pct(float): Proportion of edges to use for training.
                          Default is 0.1.
                          Note that train_pct is applied after val_pct is applied.
        val_pct(float): Proportion of edges to use for validation
        sep (str):  delimiter for CSVs. Default is comma.
        random_state (int):  random seed for train/test split
        verbose (boolean): verbosity
    Return:
        tuple of EdgeSequenceWrapper objects for train and validation sets and LinkPreprocessor
    &#34;&#34;&#34;

    # import stellargraph
    try:
        import stellargraph as sg
        from stellargraph.data import EdgeSplitter
    except:
        raise Exception(SG_ERRMSG)
    if version.parse(sg.__version__) &lt; version.parse(&#39;0.8&#39;):
        raise Exception(SG_ERRMSG)


    #----------------------------------------------------------------
    # read graph structure
    #----------------------------------------------------------------
    nx_sep = None if sep in [&#39; &#39;, &#39;\t&#39;] else sep
    G = nx.read_edgelist(path=links_filepath, delimiter=nx_sep)
    print(nx.info(G))




    #----------------------------------------------------------------
    # read node attributes
    #----------------------------------------------------------------
    node_attr = pd.read_csv(nodes_filepath, sep=sep, header=None)
    num_features = len(node_attr.columns.values) - 1 # subract ID and treat all other columns as features
    feature_names = [&#34;w_{}&#34;.format(ii) for ii in range(num_features)]
    node_data = pd.read_csv(nodes_filepath, header=None, names=feature_names, sep=sep)
    node_data.index = node_data.index.map(str)
    df = node_data[node_data.index.isin(list(G.nodes()))]
    for col in feature_names:
        if not isinstance(node_data[col].values[0], str): continue
        df = pd.concat([df, df[col].astype(&#39;str&#39;).str.get_dummies().add_prefix(col+&#39;_&#39;)], axis=1, sort=False)
        df = df.drop([col], axis=1)
    feature_names = df.columns.values
    node_data = df
    node_features = node_data[feature_names].values
    for nid, f in zip(node_data.index, node_features):
        G.node[nid][sg.globalvar.TYPE_ATTR_NAME] = &#34;node&#34;  
        G.node[nid][&#34;feature&#34;] = f


    #----------------------------------------------------------------
    # train/validation sets
    #----------------------------------------------------------------
    edge_splitter_test = EdgeSplitter(G)
    G_test, edge_ids_test, edge_labels_test = edge_splitter_test.train_test_split(p=val_pct, method=&#34;global&#34;, keep_connected=True)
    edge_splitter_train = EdgeSplitter(G_test)
    G_train, edge_ids_train, edge_labels_train = edge_splitter_train.train_test_split(p=train_pct, method=&#34;global&#34;, keep_connected=True)
    epp = LinkPreprocessor(G, sample_sizes=sample_sizes)
    trn = epp.preprocess_train(G_train, edge_ids_train, edge_labels_train)
    val = epp.preprocess_valid(G_test, edge_ids_test, edge_labels_test)
    
    return (trn, val, epp)</code></pre>
</details>
</dd>
<dt id="ktrain.graph.graph_node_classifier"><code class="name flex">
<span>def <span class="ident">graph_node_classifier</span></span>(<span>name, train_data, layer_sizes=[32, 32], verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Build and return a neural node classification model.
Notes: Only mutually-exclusive class labels are supported.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>one of:
- 'graphsage' for GraphSAGE model
(only GraphSAGE currently supported)</dd>
<dt><strong><code>train_data</code></strong> :&ensp;<code>NodeSequenceWrapper</code></dt>
<dd>a ktrain.graph.sg_wrappers.NodeSequenceWrapper object</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>verbosity of output</dd>
</dl>
<h2 id="return">Return</h2>
<p>model (Model): A Keras Model instance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def graph_node_classifier(name, train_data, layer_sizes=[32,32], verbose=1):
    &#34;&#34;&#34;
    Build and return a neural node classification model.
    Notes: Only mutually-exclusive class labels are supported.

    Args:
        name (string): one of:
                      - &#39;graphsage&#39; for GraphSAGE model 
                      (only GraphSAGE currently supported)

        train_data (NodeSequenceWrapper): a ktrain.graph.sg_wrappers.NodeSequenceWrapper object
        verbose (boolean): verbosity of output
    Return:
        model (Model): A Keras Model instance
    &#34;&#34;&#34;
    from .sg_wrappers import NodeSequenceWrapper

    # check argument
    if not isinstance(train_data, NodeSequenceWrapper):
        err =&#34;&#34;&#34;
            train_data must be a ktrain.graph.sg_wrappers.NodeSequenceWrapper object
            &#34;&#34;&#34;
        raise Exception(err)
    if len(layer_sizes) != 2:
        raise ValueError(&#39;layer_sizes must be of length 2&#39;)

    num_classes = U.nclasses_from_data(train_data)

    # determine multilabel
    multilabel = U.is_multilabel(train_data)
    if multilabel:
        raise ValueError(&#39;Multi-label classification not currently supported for graphs.&#39;)
    U.vprint(&#34;Is Multi-Label? %s&#34; % (multilabel), verbose=verbose)

    # set loss and activations
    loss_func = &#39;categorical_crossentropy&#39;
    activation = &#39;softmax&#39;

    # import stellargraph
    try:
        import stellargraph as sg
        from stellargraph.layer import GraphSAGE
    except:
        raise Exception(SG_ERRMSG)
    if version.parse(sg.__version__) &lt; version.parse(&#39;0.8&#39;):
        raise Exception(SG_ERRMSG)





    # build a GraphSAGE node classification model
    graphsage_model = GraphSAGE(
        layer_sizes=layer_sizes,
        generator=train_data,
        bias=True,
        dropout=0.5,
        )
    #x_inp, x_out = graphsage_model.default_model(flatten_output=True)
    x_inp, x_out = graphsage_model.build()
    prediction = Dense(units=num_classes, activation=activation)(x_out)
    model = Model(inputs=x_inp, outputs=prediction)
    model.compile(optimizer=&#39;adam&#39;,
                  loss=loss_func,
                  metrics=[&#34;accuracy&#34;])
    U.vprint(&#39;done&#39;, verbose=verbose)
    return model</code></pre>
</details>
</dd>
<dt id="ktrain.graph.graph_nodes_from_csv"><code class="name flex">
<span>def <span class="ident">graph_nodes_from_csv</span></span>(<span>nodes_filepath, links_filepath, use_lcc=True, sample_size=10, train_pct=0.1, sep=',', holdout_pct=None, holdout_for_inductive=False, missing_label_value=None, random_state=None, verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads graph data from CSV files.
Returns generators for nodes in graph for use with GraphSAGE model.</p>
<h2 id="args">Args</h2>
<dl>
<dt>nodes_filepath(str): file path to training CSV containing node attributes</dt>
<dt>links_filepath(str): file path to training CSV describing links among nodes</dt>
<dt>use_lcc(bool):
If True, consider the largest connected component only.</dt>
<dt>sample_size(int): Number of nodes to sample at each neighborhood level</dt>
<dt>train_pct(float): Proportion of nodes to use for training.</dt>
<dt>Default is 0.1.</dt>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>delimiter for CSVs. Default is comma.</dd>
</dl>
<p>holdout_pct(float): Percentage of nodes to remove and return separately
for later transductive/inductive inference.
Example &ndash;&gt;
train_pct=0.1 and holdout_pct=0.2:</p>
<pre><code>            Out of 1000 nodes, 200 (holdout_pct*1000) will be held out.
            Of the remaining 800, 80 (train_pct*800) will be used for training
            and 720 ((1-train_pct)*800) will be used for validation.
            200 nodes will be used for transductive or inductive inference.

            Note that holdout_pct is ignored if at least one node has
            a missing label in nodes_filepath, in which case
            these nodes are assumed to be the holdout set.
</code></pre>
<dl>
<dt>holdout_for_inductive(bool):
If True, the holdout nodes will be removed from</dt>
<dt>training graph and their features will not be visible</dt>
<dt>during training.
Only features of training and</dt>
<dt>validation nodes will be visible.</dt>
<dt>If False, holdout nodes will be included in graph</dt>
<dt>and their features (but not labels) are accessible</dt>
<dt>during training.</dt>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code></dt>
<dd>random seed for train/test split</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>boolean</code></dt>
<dd>verbosity</dd>
</dl>
<h2 id="return">Return</h2>
<p>tuple of NodeSequenceWrapper objects for train and validation sets and NodePreprocessor
If holdout_pct is not None or number of nodes with missing labels is non-zero,
fourth and fifth return values are pd.DataFrame and nx.Graph
comprising the held out nodes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def graph_nodes_from_csv(nodes_filepath, 
                         links_filepath,
                         use_lcc=True,
                         sample_size=10,
                         train_pct=0.1, sep=&#39;,&#39;, 
                         holdout_pct=None, 
                         holdout_for_inductive=False,
                         missing_label_value=None,
                         random_state=None,
                         verbose=1):
    &#34;&#34;&#34;
    Loads graph data from CSV files. 
    Returns generators for nodes in graph for use with GraphSAGE model.
    Args:
        nodes_filepath(str): file path to training CSV containing node attributes
        links_filepath(str): file path to training CSV describing links among nodes
        use_lcc(bool):  If True, consider the largest connected component only.
        sample_size(int): Number of nodes to sample at each neighborhood level
        train_pct(float): Proportion of nodes to use for training.
                          Default is 0.1.
        sep (str):  delimiter for CSVs. Default is comma.
        holdout_pct(float): Percentage of nodes to remove and return separately
                        for later transductive/inductive inference.
                        Example --&gt;  train_pct=0.1 and holdout_pct=0.2:

                        Out of 1000 nodes, 200 (holdout_pct*1000) will be held out.
                        Of the remaining 800, 80 (train_pct*800) will be used for training
                        and 720 ((1-train_pct)*800) will be used for validation.
                        200 nodes will be used for transductive or inductive inference.

                        Note that holdout_pct is ignored if at least one node has
                        a missing label in nodes_filepath, in which case
                        these nodes are assumed to be the holdout set.
        holdout_for_inductive(bool):  If True, the holdout nodes will be removed from 
                                      training graph and their features will not be visible
                                      during training.  Only features of training and
                                      validation nodes will be visible.
                                      If False, holdout nodes will be included in graph
                                      and their features (but not labels) are accessible
                                      during training.
        random_state (int):  random seed for train/test split
        verbose (boolean): verbosity
    Return:
        tuple of NodeSequenceWrapper objects for train and validation sets and NodePreprocessor
        If holdout_pct is not None or number of nodes with missing labels is non-zero, 
        fourth and fifth return values are pd.DataFrame and nx.Graph
        comprising the held out nodes.
    &#34;&#34;&#34;

    #----------------------------------------------------------------
    # read graph structure
    #----------------------------------------------------------------
    nx_sep = None if sep in [&#39; &#39;, &#39;\t&#39;] else sep
    g_nx = nx.read_edgelist(path=links_filepath, delimiter=nx_sep)

    # read node attributes
    #node_attr = pd.read_csv(nodes_filepath, sep=sep, header=None)

    # store class labels within graph nodes
    #values = { str(row.tolist()[0]): row.tolist()[-1] for _, row in node_attr.iterrows()}
    #nx.set_node_attributes(g_nx, values, &#39;target&#39;)

    # select largest connected component
    if use_lcc:
        g_nx_ccs = (g_nx.subgraph(c).copy() for c in nx.connected_components(g_nx))
        g_nx = max(g_nx_ccs, key=len)
        if verbose:
            print(&#34;Largest subgraph statistics: {} nodes, {} edges&#34;.format(
            g_nx.number_of_nodes(), g_nx.number_of_edges()))


    #----------------------------------------------------------------
    # read node attributes and split into train/validation
    #----------------------------------------------------------------
    node_attr = pd.read_csv(nodes_filepath, sep=sep, header=None)
    num_features = len(node_attr.columns.values) - 2 # subract ID and target
    feature_names = [&#34;w_{}&#34;.format(ii) for ii in range(num_features)]
    column_names =  feature_names + [&#34;target&#34;]
    node_data = pd.read_csv(nodes_filepath, header=None, names=column_names, sep=sep)
    node_data.index = node_data.index.map(str)
    node_data = node_data[node_data.index.isin(list(g_nx.nodes()))]


    #----------------------------------------------------------------
    # check for holdout nodes
    #----------------------------------------------------------------
    num_null = node_data[node_data.target.isnull()].shape[0]
    num_missing = 0
    if missing_label_value is not None:
        num_missing = node_data[node_data.target == missing_label_value].shape[0]

    if num_missing &gt; 0 and num_null &gt;0:
        raise ValueError(&#39;Param missing_label_value is not None but there are &#39; +\
                         &#39;NULLs in last column. Replace these with missing_label_value.&#39;)

    if (num_null &gt; 0 or num_missing &gt; 0) and holdout_pct is not None:
        warnings.warn(&#39;Number of nodes in having NULL  or missing_label_value in target &#39;+\
                      &#39;column is non-zero. Using these as holdout nodes and ignoring holdout_pct.&#39;)



    #----------------------------------------------------------------
    # set df and G and optionally holdout nodes
    #----------------------------------------------------------------
    if num_null &gt; 0:
        df_annotated = node_data[~node_data.target.isnull()]
        df_holdout = node_data[~node_data.target.isnull()]
        G_holdout = g_nx
        df_G = df_annotated if holdout_for_inductive else node_data
        G = g_nx.subgraph(df_annotated.index).copy() if holdout_for_inductive else g_nx
        U.vprint(&#39;using %s nodes with target=NULL as holdout set&#39; % (num_null), verbose=verbose)
    elif num_missing &gt; 0:
        df_annotated = node_data[node_data.target != missing_label_value]
        df_holdout = node_data[node_data.target == missing_label_value]
        G_holdout = g_nx
        df_G = df_annotated if holdout_for_inductive else node_data
        G = g_nx.subgraph(df_annotated.index).copy() if holdout_for_inductive else g_nx
        U.vprint(&#39;using %s nodes with missing target as holdout set&#39; % (num_missing), verbose=verbose)
    elif holdout_pct is not None:
        df_annotated = node_data.sample(frac=1-holdout_pct, replace=False, random_state=None)
        df_holdout = node_data[~node_data.index.isin(df_annotated.index)]
        G_holdout = g_nx
        df_G = df_annotated if holdout_for_inductive else node_data
        G = g_nx.subgraph(df_annotated.index).copy() if holdout_for_inductive else g_nx
    else:
        if holdout_for_inductive:
            warnings.warn(&#39;holdout_for_inductive is True but no nodes were heldout &#39;
                          &#39;because holdout_pct is None and no missing targets&#39;)
        df_annotated = node_data
        df_holdout = None
        G_holdout = None
        df_G = node_data
        G = g_nx


    #----------------------------------------------------------------
    # split into train and validation
    #----------------------------------------------------------------
    tr_data, te_data = sklearn.model_selection.train_test_split(df_annotated, 
                                                        train_size=train_pct,
                                                        test_size=None,
                                                        stratify=df_annotated[&#39;target&#39;], 
                                                        random_state=random_state)
    #te_data, test_data = sklearn.model_selection.train_test_split(test_data,
                                                                #train_size=0.2,
                                                                #test_size=None,
                                                                 #stratify=test_data[&#34;target&#34;],
                                                                 #random_state=100)

    #----------------------------------------------------------------
    # print summary
    #----------------------------------------------------------------
    if verbose:
        print(&#34;Size of training graph: %s nodes&#34; % (G.number_of_nodes()))
        print(&#34;Training nodes: %s&#34; % (tr_data.shape[0]))
        print(&#34;Validation nodes: %s&#34; % (te_data.shape[0]))
        if df_holdout is not None and G_holdout is not None:
            print(&#34;Nodes treated as unlabeled for testing/inference: %s&#34; % (df_holdout.shape[0]))
            if holdout_for_inductive:
                print(&#34;Size of graph with added holdout nodes: %s&#34; % (G_holdout.number_of_nodes()))
                print(&#34;Holdout node features are not visible during training (inductive inference)&#34;)
            else:
                print(&#34;Holdout node features are visible during training (transductive inference)&#34;)
        print()



    #----------------------------------------------------------------
    # Preprocess training and validation datasets using NodePreprocessor
    #----------------------------------------------------------------
    preproc = NodePreprocessor(G, df_G, sample_size=sample_size, missing_label_value=missing_label_value)
    trn = preproc.preprocess_train(list(tr_data.index))
    val = preproc.preprocess_valid(list(te_data.index))
    if df_holdout is not None and G_holdout is not None: 
        return (trn, val, preproc, df_holdout, G_holdout)
    else:
        return (trn, val, preproc)</code></pre>
</details>
</dd>
<dt id="ktrain.graph.print_link_predictors"><code class="name flex">
<span>def <span class="ident">print_link_predictors</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_link_predictors():
    for k,v in LINK_PREDICTORS.items():
        print(&#34;%s: %s&#34; % (k,v))</code></pre>
</details>
</dd>
<dt id="ktrain.graph.print_node_classifiers"><code class="name flex">
<span>def <span class="ident">print_node_classifiers</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_node_classifiers():
    for k,v in NODE_CLASSIFIERS.items():
        print(&#34;%s: %s&#34; % (k,v))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ktrain" href="../index.html">ktrain</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="ktrain.graph.data" href="data.html">ktrain.graph.data</a></code></li>
<li><code><a title="ktrain.graph.learner" href="learner.html">ktrain.graph.learner</a></code></li>
<li><code><a title="ktrain.graph.models" href="models.html">ktrain.graph.models</a></code></li>
<li><code><a title="ktrain.graph.predictor" href="predictor.html">ktrain.graph.predictor</a></code></li>
<li><code><a title="ktrain.graph.preprocessor" href="preprocessor.html">ktrain.graph.preprocessor</a></code></li>
<li><code><a title="ktrain.graph.sg_wrappers" href="sg_wrappers.html">ktrain.graph.sg_wrappers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ktrain.graph.graph_link_predictor" href="#ktrain.graph.graph_link_predictor">graph_link_predictor</a></code></li>
<li><code><a title="ktrain.graph.graph_links_from_csv" href="#ktrain.graph.graph_links_from_csv">graph_links_from_csv</a></code></li>
<li><code><a title="ktrain.graph.graph_node_classifier" href="#ktrain.graph.graph_node_classifier">graph_node_classifier</a></code></li>
<li><code><a title="ktrain.graph.graph_nodes_from_csv" href="#ktrain.graph.graph_nodes_from_csv">graph_nodes_from_csv</a></code></li>
<li><code><a title="ktrain.graph.print_link_predictors" href="#ktrain.graph.print_link_predictors">print_link_predictors</a></code></li>
<li><code><a title="ktrain.graph.print_node_classifiers" href="#ktrain.graph.print_node_classifiers">print_node_classifiers</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>