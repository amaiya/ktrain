<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>ktrain.vision API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ktrain.vision</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .data import (
    get_data_aug,
    images_from_array,
    images_from_csv,
    images_from_fname,
    images_from_folder,
    preprocess_csv,
    preview_data_aug,
    show_image,
    show_random_images,
)
from .models import (
    image_classifier,
    image_regression_model,
    print_image_classifiers,
    print_image_regression_models,
)
from .predictor import ImagePredictor

__all__ = [
    &#34;image_classifier&#34;,
    &#34;image_regression_model&#34;,
    &#34;print_image_classifiers&#34;,
    &#34;print_image_regression_models&#34;,
    &#34;images_from_folder&#34;,
    &#34;images_from_csv&#34;,
    &#34;images_from_array&#34;,
    &#34;images_from_fname&#34;,
    &#34;get_data_aug&#34;,
    &#34;preprocess_csv&#34;,
    &#34;ImagePredictor&#34;,
    &#34;show_image&#34;,
    &#34;show_random_images&#34;,
    &#34;preview_data_aug&#34;,
]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="ktrain.vision.caption" href="caption/index.html">ktrain.vision.caption</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.vision.data" href="data.html">ktrain.vision.data</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.vision.learner" href="learner.html">ktrain.vision.learner</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.vision.models" href="models.html">ktrain.vision.models</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.vision.object_detection" href="object_detection/index.html">ktrain.vision.object_detection</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.vision.predictor" href="predictor.html">ktrain.vision.predictor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.vision.preprocessor" href="preprocessor.html">ktrain.vision.preprocessor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="ktrain.vision.wrn" href="wrn.html">ktrain.vision.wrn</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ktrain.vision.get_data_aug"><code class="name flex">
<span>def <span class="ident">get_data_aug</span></span>(<span>rotation_range=40, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=False, vertical_flip=False, featurewise_center=True, featurewise_std_normalization=True, samplewise_center=False, samplewise_std_normalization=False, rescale=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>This function is simply a wrapper around ImageDataGenerator
with some reasonable defaults for data augmentation.
Returns the default image_data_generator to support
data augmentation and data normalization.
Parameters can be adjusted by caller.
Note that the ktrain.vision.model.image_classifier
function may adjust these as needed.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data_aug(
    rotation_range=40,
    zoom_range=0.2,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=False,
    vertical_flip=False,
    featurewise_center=True,
    featurewise_std_normalization=True,
    samplewise_center=False,
    samplewise_std_normalization=False,
    rescale=None,
    **kwargs
):
    &#34;&#34;&#34;
    ```
    This function is simply a wrapper around ImageDataGenerator
    with some reasonable defaults for data augmentation.
    Returns the default image_data_generator to support
    data augmentation and data normalization.
    Parameters can be adjusted by caller.
    Note that the ktrain.vision.model.image_classifier
    function may adjust these as needed.
    ```
    &#34;&#34;&#34;

    data_aug = keras.preprocessing.image.ImageDataGenerator(
        rotation_range=rotation_range,
        zoom_range=zoom_range,
        width_shift_range=width_shift_range,
        height_shift_range=height_shift_range,
        horizontal_flip=horizontal_flip,
        vertical_flip=vertical_flip,
        featurewise_center=featurewise_center,
        featurewise_std_normalization=featurewise_std_normalization,
        samplewise_center=samplewise_center,
        samplewise_std_normalization=samplewise_std_normalization,
        rescale=rescale,
        **kwargs
    )
    return data_aug</code></pre>
</details>
</dd>
<dt id="ktrain.vision.image_classifier"><code class="name flex">
<span>def <span class="ident">image_classifier</span></span>(<span>name, train_data, val_data=None, freeze_layers=None, metrics=None, optimizer_name=&lt;keras.optimizers.optimizer_v2.adam.Adam object&gt;, multilabel=None, pt_fc=[], pt_ps=[], verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Returns a pre-defined/pre-trained model ready to be trained/fine-tuned
for multi-class classification. By default, all layers are
trainable/unfrozen.


Args:
    name (string): one of model shown on ktrain.vision.print_image_classifiers
    train_data (image.Iterator): train data. Note: Will be manipulated here!
    val_data (image.Iterator): validation data.  Note: Will be manipulated here!
    freeze_layers (int):  number of beginning layers to make untrainable
                        If None, then all layers except new Dense layers
                        will be frozen/untrainable.
    metrics (list):  metrics to use
    metrics(list): List of metrics to use.  If None: 'accuracy' is used for binar/multiclass,
                   'binary_accuracy' is used for multilabel classification, and 'mae' is used for regression
    optimizer_name(str|obj): name of Keras optimizer (e.g., 'adam', 'sgd') or instance of keras Optimizer
    multilabel(bool):  If True, model will be build to support
                       multilabel classification (labels are not mutually exclusive).
                       If False, binary/multiclassification model will be returned.
                       If None, multilabel status will be inferred from data.
    pt_fc (list of ints): number of hidden units in extra Dense layers
                            before final Dense layer of pretrained model.
                            Only takes effect if name in PRETRAINED_MODELS
    pt_ps (list of floats): dropout probabilities to use before
                            each extra Dense layer in pretrained model.
                            Only takes effect if name in PRETRAINED_MODELS
    verbose (int):         verbosity
Return:
    model(Model):  the compiled model ready to be fine-tuned/trained

</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def image_classifier(
    name,
    train_data,
    val_data=None,
    freeze_layers=None,
    metrics=None,
    optimizer_name=U.DEFAULT_OPT,
    multilabel=None,
    pt_fc=[],
    pt_ps=[],
    verbose=1,
):
    &#34;&#34;&#34;
    ```
    Returns a pre-defined/pre-trained model ready to be trained/fine-tuned
    for multi-class classification. By default, all layers are
    trainable/unfrozen.


    Args:
        name (string): one of model shown on ktrain.vision.print_image_classifiers
        train_data (image.Iterator): train data. Note: Will be manipulated here!
        val_data (image.Iterator): validation data.  Note: Will be manipulated here!
        freeze_layers (int):  number of beginning layers to make untrainable
                            If None, then all layers except new Dense layers
                            will be frozen/untrainable.
        metrics (list):  metrics to use
        metrics(list): List of metrics to use.  If None: &#39;accuracy&#39; is used for binar/multiclass,
                       &#39;binary_accuracy&#39; is used for multilabel classification, and &#39;mae&#39; is used for regression
        optimizer_name(str|obj): name of Keras optimizer (e.g., &#39;adam&#39;, &#39;sgd&#39;) or instance of keras Optimizer
        multilabel(bool):  If True, model will be build to support
                           multilabel classification (labels are not mutually exclusive).
                           If False, binary/multiclassification model will be returned.
                           If None, multilabel status will be inferred from data.
        pt_fc (list of ints): number of hidden units in extra Dense layers
                                before final Dense layer of pretrained model.
                                Only takes effect if name in PRETRAINED_MODELS
        pt_ps (list of floats): dropout probabilities to use before
                                each extra Dense layer in pretrained model.
                                Only takes effect if name in PRETRAINED_MODELS
        verbose (int):         verbosity
    Return:
        model(Model):  the compiled model ready to be fine-tuned/trained

    ```
    &#34;&#34;&#34;
    return image_model(
        name,
        train_data,
        val_data=val_data,
        freeze_layers=freeze_layers,
        metrics=metrics,
        optimizer_name=optimizer_name,
        multilabel=multilabel,
        pt_fc=pt_fc,
        pt_ps=pt_ps,
        verbose=verbose,
    )</code></pre>
</details>
</dd>
<dt id="ktrain.vision.image_regression_model"><code class="name flex">
<span>def <span class="ident">image_regression_model</span></span>(<span>name, train_data, val_data=None, freeze_layers=None, metrics=['mae'], optimizer_name=&lt;keras.optimizers.optimizer_v2.adam.Adam object&gt;, pt_fc=[], pt_ps=[], verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Returns a pre-defined/pre-trained model ready to be trained/fine-tuned
for multi-class classification. By default, all layers are
trainable/unfrozen.


Args:
    name (string): one of model shown on ktrain.vision.print_image_regression_models
    train_data (image.Iterator): train data. Note: Will be manipulated here!
    val_data (image.Iterator): validation data.  Note: Will be manipulated here!
    freeze_layers (int):  number of beginning layers to make untrainable
                        If None, then all layers except new Dense layers
                        will be frozen/untrainable.
    metrics (list):  metrics to use
    optimizer_name(str): name of Keras optimizer (e.g., 'adam', 'sgd')
    multilabel(bool):  If True, model will be build to support
                       multilabel classificaiton (labels are not mutually exclusive).
                       If False, binary/multiclassification model will be returned.
                       If None, multilabel status will be inferred from data.
    pt_fc (list of ints): number of hidden units in extra Dense layers
                            before final Dense layer of pretrained model.
                            Only takes effect if name in PRETRAINED_MODELS
    pt_ps (list of floats): dropout probabilities to use before
                            each extra Dense layer in pretrained model.
                            Only takes effect if name in PRETRAINED_MODELS
    verbose (int):         verbosity
Return:
    model(Model):  the compiled model ready to be fine-tuned/trained

</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def image_regression_model(
    name,
    train_data,
    val_data=None,
    freeze_layers=None,
    metrics=[&#34;mae&#34;],
    optimizer_name=U.DEFAULT_OPT,
    pt_fc=[],
    pt_ps=[],
    verbose=1,
):
    &#34;&#34;&#34;
    ```
    Returns a pre-defined/pre-trained model ready to be trained/fine-tuned
    for multi-class classification. By default, all layers are
    trainable/unfrozen.


    Args:
        name (string): one of model shown on ktrain.vision.print_image_regression_models
        train_data (image.Iterator): train data. Note: Will be manipulated here!
        val_data (image.Iterator): validation data.  Note: Will be manipulated here!
        freeze_layers (int):  number of beginning layers to make untrainable
                            If None, then all layers except new Dense layers
                            will be frozen/untrainable.
        metrics (list):  metrics to use
        optimizer_name(str): name of Keras optimizer (e.g., &#39;adam&#39;, &#39;sgd&#39;)
        multilabel(bool):  If True, model will be build to support
                           multilabel classificaiton (labels are not mutually exclusive).
                           If False, binary/multiclassification model will be returned.
                           If None, multilabel status will be inferred from data.
        pt_fc (list of ints): number of hidden units in extra Dense layers
                                before final Dense layer of pretrained model.
                                Only takes effect if name in PRETRAINED_MODELS
        pt_ps (list of floats): dropout probabilities to use before
                                each extra Dense layer in pretrained model.
                                Only takes effect if name in PRETRAINED_MODELS
        verbose (int):         verbosity
    Return:
        model(Model):  the compiled model ready to be fine-tuned/trained

    ```
    &#34;&#34;&#34;

    return image_model(
        name,
        train_data,
        val_data=val_data,
        freeze_layers=freeze_layers,
        metrics=metrics,
        optimizer_name=optimizer_name,
        multilabel=False,
        pt_fc=pt_fc,
        pt_ps=pt_ps,
        verbose=verbose,
    )</code></pre>
</details>
</dd>
<dt id="ktrain.vision.images_from_array"><code class="name flex">
<span>def <span class="ident">images_from_array</span></span>(<span>x_train, y_train, validation_data=None, val_pct=0.1, random_state=None, data_aug=None, classes=None, class_names=None, is_regression=False)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Returns image generator (Iterator instance) from training
and validation data in the form of NumPy arrays.
This function only supports image classification.
For image regression, please use images_from_df.

Args:
  x_train(numpy.ndarray):  training gdata
  y_train(numpy.ndarray):  labels must either be:
                           1. one-hot (or multi-hot) encoded arrays
                           2. integer values representing the label
  validation_data (tuple): tuple of numpy.ndarrays for validation data.
                           labels should be in one of the formats listed above.
  val_pct(float): percentage of training data to use for validaton if validation_data is None
  random_state(int): random state to use for splitting data
  data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
  classes(str): old name for class_names - should no longer be used
  class_names(str): list of strings to use as class names
  is_regression(bool): If True, task is treated as regression.
                       Used when there is single column of numeric values and
                       numeric values should be treated as numeric targets as opposed to class labels
Returns:
  batches: a tuple of two image.Iterator - one for train and one for test and ImagePreprocessor instance
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def images_from_array(
    x_train,
    y_train,
    validation_data=None,
    val_pct=0.1,
    random_state=None,
    data_aug=None,
    classes=None,
    class_names=None,
    is_regression=False,
):
    &#34;&#34;&#34;
    ```
    Returns image generator (Iterator instance) from training
    and validation data in the form of NumPy arrays.
    This function only supports image classification.
    For image regression, please use images_from_df.

    Args:
      x_train(numpy.ndarray):  training gdata
      y_train(numpy.ndarray):  labels must either be:
                               1. one-hot (or multi-hot) encoded arrays
                               2. integer values representing the label
      validation_data (tuple): tuple of numpy.ndarrays for validation data.
                               labels should be in one of the formats listed above.
      val_pct(float): percentage of training data to use for validaton if validation_data is None
      random_state(int): random state to use for splitting data
      data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
      classes(str): old name for class_names - should no longer be used
      class_names(str): list of strings to use as class names
      is_regression(bool): If True, task is treated as regression.
                           Used when there is single column of numeric values and
                           numeric values should be treated as numeric targets as opposed to class labels
    Returns:
      batches: a tuple of two image.Iterator - one for train and one for test and ImagePreprocessor instance
    ```
    &#34;&#34;&#34;
    if classes is not None:
        raise ValueError(&#39;Please use class_names argument instead of &#34;classes&#34;.&#39;)
    if class_names and is_regression:
        warnings.warn(
            &#34;is_regression=True, but class_names is not empty.  Task being treated as regression.&#34;
        )

    # split out validation set if necessary
    if validation_data:
        x_test = validation_data[0]
        y_test = validation_data[1]
    elif val_pct is not None and val_pct &gt; 0:
        x_train, x_test, y_train, y_test = train_test_split(
            x_train, y_train, test_size=val_pct, random_state=random_state
        )
    else:
        x_test = None
        y_test = None

    # transform labels
    ytrans = U.YTransform(class_names=class_names if not is_regression else [])
    y_train = ytrans.apply_train(y_train)
    y_test = ytrans.apply_test(y_test)
    class_names = ytrans.get_classes()

    # train and test data generators
    (train_datagen, test_datagen) = process_datagen(data_aug, train_array=x_train)

    # Image preprocessor
    preproc = ImagePreprocessor(
        test_datagen, class_names, target_size=None, color_mode=None
    )

    # training data
    batches_tr = train_datagen.flow(x_train, y_train, shuffle=True)

    # validation data
    batches_te = None
    if x_test is not None and y_test is not None:
        batches_te = test_datagen.flow(x_test, y_test, shuffle=False)
    return (batches_tr, batches_te, preproc)</code></pre>
</details>
</dd>
<dt id="ktrain.vision.images_from_csv"><code class="name flex">
<span>def <span class="ident">images_from_csv</span></span>(<span>train_filepath, image_column, label_columns=[], directory=None, suffix='', val_filepath=None, is_regression=False, target_size=(224, 224), color_mode='rgb', data_aug=None, val_pct=0.1, random_state=None)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Returns image generator (Iterator instance).
Assumes output will be 2D one-hot-encoded labels for categorization.
Note: This function preprocesses the input in preparation
      for a ResNet50 model.

Args:
train_filepath (string): path to training dataset in CSV format with header row
image_column (string): name of column containing the filenames of images
                       If values in image_column do not have a file extension,
                       the extension should be supplied with suffix argument.
                       If values in image_column are not full file paths,
                       then the path to directory containing images should be supplied
                       as directory argument.

label_columns(list or str): list or str representing the columns that store labels
                            Labels can be in any one of the following formats:
                            1. a single column string string (or integer) labels

                               image_fname,label
                               -----------------
                               image01,cat
                               image02,dog

                            2. multiple columns for one-hot-encoded labels
                               image_fname,cat,dog
                               image01,1,0
                               image02,0,1

                            3. a single column of numeric values for image regression
                               image_fname,age
                               -----------------
                               image01,68
                               image02,18

directory (string): path to directory containing images
                    not required if image_column contains full filepaths
suffix(str): will be appended to each entry in image_column
             Used when the filenames in image_column do not contain file extensions.
             The extension in suffx should include &quot;.&quot;.
val_filepath (string): path to validation dataset in CSV format
suffix(string): suffix to add to file names in image_column
is_regression(bool): If True, task is treated as regression.
                     Used when there is single column of numeric values and
                     numeric values should be treated as numeric targets as opposed to class labels
target_size (tuple):  image dimensions
color_mode (string):  color mode
data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
                              for data augmentation
val_pct(float):  proportion of training data to be used for validation
                 only used if val_filepath is None
random_state(int): random seed for train/test split

Returns:
batches: a tuple of two Iterators - one for train and one for test
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def images_from_csv(
    train_filepath,
    image_column,
    label_columns=[],
    directory=None,
    suffix=&#34;&#34;,
    val_filepath=None,
    is_regression=False,
    target_size=(224, 224),
    color_mode=&#34;rgb&#34;,
    data_aug=None,
    val_pct=0.1,
    random_state=None,
):
    &#34;&#34;&#34;
    ```
    Returns image generator (Iterator instance).
    Assumes output will be 2D one-hot-encoded labels for categorization.
    Note: This function preprocesses the input in preparation
          for a ResNet50 model.

    Args:
    train_filepath (string): path to training dataset in CSV format with header row
    image_column (string): name of column containing the filenames of images
                           If values in image_column do not have a file extension,
                           the extension should be supplied with suffix argument.
                           If values in image_column are not full file paths,
                           then the path to directory containing images should be supplied
                           as directory argument.

    label_columns(list or str): list or str representing the columns that store labels
                                Labels can be in any one of the following formats:
                                1. a single column string string (or integer) labels

                                   image_fname,label
                                   -----------------
                                   image01,cat
                                   image02,dog

                                2. multiple columns for one-hot-encoded labels
                                   image_fname,cat,dog
                                   image01,1,0
                                   image02,0,1

                                3. a single column of numeric values for image regression
                                   image_fname,age
                                   -----------------
                                   image01,68
                                   image02,18

    directory (string): path to directory containing images
                        not required if image_column contains full filepaths
    suffix(str): will be appended to each entry in image_column
                 Used when the filenames in image_column do not contain file extensions.
                 The extension in suffx should include &#34;.&#34;.
    val_filepath (string): path to validation dataset in CSV format
    suffix(string): suffix to add to file names in image_column
    is_regression(bool): If True, task is treated as regression.
                         Used when there is single column of numeric values and
                         numeric values should be treated as numeric targets as opposed to class labels
    target_size (tuple):  image dimensions
    color_mode (string):  color mode
    data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
                                  for data augmentation
    val_pct(float):  proportion of training data to be used for validation
                     only used if val_filepath is None
    random_state(int): random seed for train/test split

    Returns:
    batches: a tuple of two Iterators - one for train and one for test
    ```
    &#34;&#34;&#34;

    # convert to dataframes
    train_df = pd.read_csv(train_filepath)
    val_df = None
    if val_filepath is not None:
        val_df = pd.read_csv(val_filepath)

    return images_from_df(
        train_df,
        image_column,
        label_columns=label_columns,
        directory=directory,
        suffix=suffix,
        val_df=val_df,
        is_regression=is_regression,
        target_size=target_size,
        color_mode=color_mode,
        data_aug=data_aug,
        val_pct=val_pct,
        random_state=random_state,
    )</code></pre>
</details>
</dd>
<dt id="ktrain.vision.images_from_fname"><code class="name flex">
<span>def <span class="ident">images_from_fname</span></span>(<span>train_folder, pattern='([^/]+)_\\d+.jpg$', val_folder=None, is_regression=False, target_size=(224, 224), color_mode='rgb', data_aug=None, val_pct=0.1, random_state=None, verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Returns image generator (Iterator instance).

Args:
train_folder (str): directory containing images
pat (str):  regular expression to extract class from file name of each image
            Example: r'([^/]+)_\d+.jpg$' to match 'english_setter' in 'english_setter_140.jpg'
            By default, it will extract classes from file names of the form:
               &lt;class_name&gt;_&lt;numbers&gt;.jpg
val_folder (str): directory containing validation images. default:None
is_regression(bool): If True, task is treated as regression.
                     Used when there is single column of numeric values and
                     numeric values should be treated as numeric targets as opposed to class labels
target_size (tuple):  image dimensions
color_mode (string):  color mode
data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
                              for data augmentation
val_pct(float):  proportion of training data to be used for validation
                 only used if val_folder is None
random_state(int): random seed for train/test split
verbose(bool):   verbosity

Returns:
batches: a tuple of two Iterators - one for train and one for test
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def images_from_fname(
    train_folder,
    pattern=r&#34;([^/]+)_\d+.jpg$&#34;,
    val_folder=None,
    is_regression=False,
    target_size=(224, 224),
    color_mode=&#34;rgb&#34;,
    data_aug=None,
    val_pct=0.1,
    random_state=None,
    verbose=1,
):
    &#34;&#34;&#34;
    ```
    Returns image generator (Iterator instance).

    Args:
    train_folder (str): directory containing images
    pat (str):  regular expression to extract class from file name of each image
                Example: r&#39;([^/]+)_\d+.jpg$&#39; to match &#39;english_setter&#39; in &#39;english_setter_140.jpg&#39;
                By default, it will extract classes from file names of the form:
                   &lt;class_name&gt;_&lt;numbers&gt;.jpg
    val_folder (str): directory containing validation images. default:None
    is_regression(bool): If True, task is treated as regression.
                         Used when there is single column of numeric values and
                         numeric values should be treated as numeric targets as opposed to class labels
    target_size (tuple):  image dimensions
    color_mode (string):  color mode
    data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
                                  for data augmentation
    val_pct(float):  proportion of training data to be used for validation
                     only used if val_folder is None
    random_state(int): random seed for train/test split
    verbose(bool):   verbosity

    Returns:
    batches: a tuple of two Iterators - one for train and one for test
    ```
    &#34;&#34;&#34;

    image_column = &#34;image_name&#34;
    label_column = &#34;label&#34;
    train_df = _img_fnames_to_df(
        train_folder,
        pattern,
        image_column=image_column,
        label_column=label_column,
        verbose=verbose,
    )
    val_df = None
    if val_folder is not None:
        val_df = _img_fnames_to_df(
            val_folder,
            pattern,
            image_column=image_column,
            label_column=label_column,
            verbose=verbose,
        )
    return images_from_df(
        train_df,
        image_column,
        label_columns=label_column,
        directory=train_folder,
        val_directory=val_folder,
        val_df=val_df,
        is_regression=is_regression,
        target_size=target_size,
        color_mode=color_mode,
        data_aug=data_aug,
        val_pct=val_pct,
        random_state=random_state,
    )</code></pre>
</details>
</dd>
<dt id="ktrain.vision.images_from_folder"><code class="name flex">
<span>def <span class="ident">images_from_folder</span></span>(<span>datadir, target_size=(224, 224), classes=None, color_mode='rgb', train_test_names=['train', 'test'], data_aug=None, verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Returns image generator (Iterator instance).
Assumes output will be 2D one-hot-encoded labels for categorization.
Note: This function preprocesses the input in preparation
      for a ResNet50 model.

Args:
datadir (string): path to training (or validation/test) dataset
    Assumes folder follows this structure:
    ├── datadir
    │   ├── train
    │   │   ├── class0       # folder containing documents of class 0
    │   │   ├── class1       # folder containing documents of class 1
    │   │   ├── class2       # folder containing documents of class 2
    │   │   └── classN       # folder containing documents of class N
    │   └── test
    │       ├── class0       # folder containing documents of class 0
    │       ├── class1       # folder containing documents of class 1
    │       ├── class2       # folder containing documents of class 2
    │       └── classN       # folder containing documents of class N

target_size (tuple):  image dimensions
classes (list):  optional list of class subdirectories (e.g., ['cats','dogs'])
color_mode (string):  color mode
train_test_names(list): names for train and test subfolders
data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
                              for data augmentation
verbose (bool):               verbosity

Returns:
batches: a tuple of two Iterators - one for train and one for test
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def images_from_folder(
    datadir,
    target_size=(224, 224),
    classes=None,
    color_mode=&#34;rgb&#34;,
    train_test_names=[&#34;train&#34;, &#34;test&#34;],
    data_aug=None,
    verbose=1,
):
    &#34;&#34;&#34;
    ```
    Returns image generator (Iterator instance).
    Assumes output will be 2D one-hot-encoded labels for categorization.
    Note: This function preprocesses the input in preparation
          for a ResNet50 model.

    Args:
    datadir (string): path to training (or validation/test) dataset
        Assumes folder follows this structure:
        ├── datadir
        │   ├── train
        │   │   ├── class0       # folder containing documents of class 0
        │   │   ├── class1       # folder containing documents of class 1
        │   │   ├── class2       # folder containing documents of class 2
        │   │   └── classN       # folder containing documents of class N
        │   └── test
        │       ├── class0       # folder containing documents of class 0
        │       ├── class1       # folder containing documents of class 1
        │       ├── class2       # folder containing documents of class 2
        │       └── classN       # folder containing documents of class N

    target_size (tuple):  image dimensions
    classes (list):  optional list of class subdirectories (e.g., [&#39;cats&#39;,&#39;dogs&#39;])
    color_mode (string):  color mode
    train_test_names(list): names for train and test subfolders
    data_aug(ImageDataGenerator):  a keras.preprocessing.image.ImageDataGenerator
                                  for data augmentation
    verbose (bool):               verbosity

    Returns:
    batches: a tuple of two Iterators - one for train and one for test
    ```
    &#34;&#34;&#34;

    # train/test names
    train_str = train_test_names[0]
    test_str = train_test_names[1]
    train_dir = os.path.join(datadir, train_str)
    test_dir = os.path.join(datadir, test_str)

    # color mode warning
    if PIL_INSTALLED:
        inferred_color_mode = detect_color_mode(train_dir)
        if inferred_color_mode is not None and (inferred_color_mode != color_mode):
            U.vprint(
                &#34;color_mode detected (%s) different than color_mode selected (%s)&#34;
                % (inferred_color_mode, color_mode),
                verbose=verbose,
            )

    # get train and test data generators
    (train_datagen, test_datagen) = process_datagen(
        data_aug,
        train_directory=train_dir,
        target_size=target_size,
        color_mode=color_mode,
    )
    batches_tr = train_datagen.flow_from_directory(
        train_dir,
        target_size=target_size,
        classes=classes,
        class_mode=&#34;categorical&#34;,
        shuffle=True,
        interpolation=&#34;bicubic&#34;,
        color_mode=color_mode,
    )

    batches_te = test_datagen.flow_from_directory(
        test_dir,
        target_size=target_size,
        classes=classes,
        class_mode=&#34;categorical&#34;,
        shuffle=False,
        interpolation=&#34;bicubic&#34;,
        color_mode=color_mode,
    )

    # setup preprocessor
    class_tup = sorted(batches_tr.class_indices.items(), key=operator.itemgetter(1))
    preproc = ImagePreprocessor(
        test_datagen,
        [x[0] for x in class_tup],
        target_size=target_size,
        color_mode=color_mode,
    )
    return (batches_tr, batches_te, preproc)</code></pre>
</details>
</dd>
<dt id="ktrain.vision.preprocess_csv"><code class="name flex">
<span>def <span class="ident">preprocess_csv</span></span>(<span>csv_in, csv_out, x_col='filename', y_col=None, sep=',', label_sep=' ', suffix='', split_by=None)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Takes a CSV where the one column contains a file name and a column
containing a string representations of the class(es) like here:
image_name,tags
01, sunny|hot
02, cloudy|cold
03, cloudy|hot

.... and one-hot encodes the classes to produce a CSV as follows:
image_name, cloudy, cold, hot, sunny
01.jpg,0,0,1,1
02.jpg,1,1,0,0
03.jpg,1,0,1,0
Args:
    csv_in (str):  filepath to input CSV file
    csv_out (str): filepath to output CSV file
    x_col (str):  name of column containing file names
    y_col (str): name of column containing the classes
    sep (str): field delimiter of entire file (e.g., comma fore CSV)
    label_sep (str): delimiter for column containing classes
    suffix (str): adds suffix to x_col values
    split_by(str): name of column. A separate CSV will be
                   created for each value in column. Useful
                   for splitting a CSV based on whether a column
                   contains 'train' or 'valid'.
Return:
    list :  the list of clases (and csv_out will be new CSV file)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_csv(
    csv_in,
    csv_out,
    x_col=&#34;filename&#34;,
    y_col=None,
    sep=&#34;,&#34;,
    label_sep=&#34; &#34;,
    suffix=&#34;&#34;,
    split_by=None,
):
    &#34;&#34;&#34;
    ```
    Takes a CSV where the one column contains a file name and a column
    containing a string representations of the class(es) like here:
    image_name,tags
    01, sunny|hot
    02, cloudy|cold
    03, cloudy|hot

    .... and one-hot encodes the classes to produce a CSV as follows:
    image_name, cloudy, cold, hot, sunny
    01.jpg,0,0,1,1
    02.jpg,1,1,0,0
    03.jpg,1,0,1,0
    Args:
        csv_in (str):  filepath to input CSV file
        csv_out (str): filepath to output CSV file
        x_col (str):  name of column containing file names
        y_col (str): name of column containing the classes
        sep (str): field delimiter of entire file (e.g., comma fore CSV)
        label_sep (str): delimiter for column containing classes
        suffix (str): adds suffix to x_col values
        split_by(str): name of column. A separate CSV will be
                       created for each value in column. Useful
                       for splitting a CSV based on whether a column
                       contains &#39;train&#39; or &#39;valid&#39;.
    Return:
        list :  the list of clases (and csv_out will be new CSV file)
    ```
    &#34;&#34;&#34;
    if not y_col and not suffix:
        raise ValueError(&#34;one or both of y_col and suffix should be supplied&#34;)
    df = pd.read_csv(csv_in, sep=sep)
    f_csv_out = open(csv_out, &#34;w&#34;)
    writer = csv.writer(f_csv_out, delimiter=sep)
    if y_col:
        df[y_col] = df[y_col].apply(str)

    # write header
    if y_col:
        classes = set()
        for row in df.iterrows():
            data = row[1]
            tags = data[y_col].split(label_sep)
            classes.update(tags)
        classes = list(classes)
        classes.sort()
        writer.writerow([x_col] + classes)
    else:
        classes = df.columns[:-1]
        write.writerow(df.columns)

    # write rows
    for row in df.iterrows():
        data = row[1]
        data[x_col] = data[x_col] + suffix
        if y_col:
            out = list(data[[x_col]].values)
            tags = set(data[y_col].strip().split(label_sep))
            for c in classes:
                if c in tags:
                    out.append(1)
                else:
                    out.append(0)
        else:
            out = data
        writer.writerow(out)
    f_csv_out.close()
    return classes</code></pre>
</details>
</dd>
<dt id="ktrain.vision.preview_data_aug"><code class="name flex">
<span>def <span class="ident">preview_data_aug</span></span>(<span>img_path, data_aug, rows=1, n=4)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Preview data augmentation (ImageDatagenerator)
on a supplied image.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preview_data_aug(img_path, data_aug, rows=1, n=4):
    &#34;&#34;&#34;
    ```
    Preview data augmentation (ImageDatagenerator)
    on a supplied image.
    ```
    &#34;&#34;&#34;
    if type(img_path) != type(&#34;&#34;) or not os.path.isfile(img_path):
        raise ValueError(&#34;img_path must be valid file path to image&#34;)
    idg = copy.copy(data_aug)
    idg.featurewise_center = False
    idg.featurewise_std_normalization = False
    idg.samplewise_center = False
    idg.samplewise_std_normalization = False
    idg.rescale = None
    idg.zca_whitening = False
    idg.preprocessing_function = None

    img = keras.preprocessing.image.load_img(img_path)
    x = img_to_array(img)
    x = x / 255.0
    x = x.reshape((1,) + x.shape)
    i = 0
    ims = []
    for batch in idg.flow(x, batch_size=1):
        ims.append(np.squeeze(batch))
        i += 1
        if i &gt;= n:
            break
    U.plots(ims, rows=rows)
    return</code></pre>
</details>
</dd>
<dt id="ktrain.vision.print_image_classifiers"><code class="name flex">
<span>def <span class="ident">print_image_classifiers</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_image_classifiers():
    for k, v in IMAGE_CLASSIFIERS.items():
        print(&#34;%s: %s&#34; % (k, v))</code></pre>
</details>
</dd>
<dt id="ktrain.vision.print_image_regression_models"><code class="name flex">
<span>def <span class="ident">print_image_regression_models</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_image_regression_models():
    for k, v in IMAGE_CLASSIFIERS.items():
        print(&#34;%s: %s&#34; % (k, v))</code></pre>
</details>
</dd>
<dt id="ktrain.vision.show_image"><code class="name flex">
<span>def <span class="ident">show_image</span></span>(<span>img_path)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Given file path to image, show it in Jupyter notebook
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_image(img_path):
    &#34;&#34;&#34;
    ```
    Given file path to image, show it in Jupyter notebook
    ```
    &#34;&#34;&#34;
    if not os.path.isfile(img_path):
        raise ValueError(&#34;%s is not valid file&#34; % (img_path))
    img = plt.imread(img_path)
    out = plt.imshow(img)
    return out</code></pre>
</details>
</dd>
<dt id="ktrain.vision.show_random_images"><code class="name flex">
<span>def <span class="ident">show_random_images</span></span>(<span>img_folder, n=4, rows=1)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>display random images from a img_folder
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_random_images(img_folder, n=4, rows=1):
    &#34;&#34;&#34;
    ```
    display random images from a img_folder
    ```
    &#34;&#34;&#34;
    fnames = []
    for ext in (&#34;*.gif&#34;, &#34;*.png&#34;, &#34;*.jpg&#34;):
        fnames.extend(glob.glob(os.path.join(img_folder, ext)))
    ims = []
    for i in range(n):
        img_path = random.choice(fnames)
        img = keras.preprocessing.image.load_img(img_path)
        x = img_to_array(img)
        x = x / 255.0
        ims.append(x)
    U.plots(ims, rows=rows)
    return</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ktrain.vision.ImagePredictor"><code class="flex name class">
<span>class <span class="ident">ImagePredictor</span></span>
<span>(</span><span>model, preproc, batch_size=32)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>predicts image classes
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ImagePredictor(Predictor):
    &#34;&#34;&#34;
    ```
    predicts image classes
    ```
    &#34;&#34;&#34;

    def __init__(self, model, preproc, batch_size=U.DEFAULT_BS):
        if not isinstance(model, keras.Model):
            raise ValueError(&#34;model must be of instance keras.Model&#34;)
        if not isinstance(preproc, ImagePreprocessor):
            raise ValueError(&#34;preproc must be instance of ImagePreprocessor&#34;)
        self.model = model
        self.preproc = preproc
        self.datagen = self.preproc.get_preprocessor()
        self.c = self.preproc.get_classes()
        self.batch_size = batch_size

    def get_classes(self):
        return self.c

    def explain(self, img_fpath):
        &#34;&#34;&#34;
        ```
        Highlights image to explain prediction
        ```
        &#34;&#34;&#34;
        try:
            import eli5
        except:
            msg = (
                &#34;ktrain requires a forked version of eli5 to support tf.keras. &#34;
                + &#34;Install with: pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip&#34;
            )
            warnings.warn(msg)
            return

        if not DISABLE_V2_BEHAVIOR:
            warnings.warn(
                &#34;Please add os.environ[&#39;DISABLE_V2_BEHAVIOR&#39;] = &#39;1&#39; at top of your script or notebook.&#34;
            )
            msg = (
                &#34;\nFor image classification, the explain method currently requires disabling V2 behavior in TensorFlow 2.\n&#34;
                + &#34;Please add the following to the top of your script or notebook BEFORE you import ktrain and restart Colab runtime or Jupyter kernel:\n\n&#34;
                + &#34;import os\n&#34;
                + &#34;os.environ[&#39;DISABLE_V2_BEHAVIOR&#39;] = &#39;1&#39;\n&#34;
            )
            print(msg)
            return

        img = keras.preprocessing.image.load_img(
            img_fpath,
            target_size=self.preproc.target_size,
            color_mode=self.preproc.color_mode,
        )
        x = keras.preprocessing.image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        return eli5.show_prediction(self.model, x)

    def predict(self, data, return_proba=False, verbose=0):
        &#34;&#34;&#34;
        ```
        Predicts class from image in array format.
        If return_proba is True, returns probabilities of each class.
        ```
        &#34;&#34;&#34;
        if not isinstance(data, np.ndarray):
            raise ValueError(&#34;data must be numpy.ndarray&#34;)
        (generator, steps) = self.preproc.preprocess(data, batch_size=self.batch_size)
        return self.predict_generator(
            generator, steps=steps, return_proba=return_proba, verbose=verbose
        )

    def predict_filename(self, img_path, return_proba=False, verbose=0):
        &#34;&#34;&#34;
        ```
        Predicts class from filepath to single image file.
        If return_proba is True, returns probabilities of each class.
        ```
        &#34;&#34;&#34;
        if not os.path.isfile(img_path):
            raise ValueError(&#34;img_path must be valid file&#34;)
        (generator, steps) = self.preproc.preprocess(
            img_path, batch_size=self.batch_size
        )
        return self.predict_generator(
            generator, steps=steps, return_proba=return_proba, verbose=verbose
        )

    def predict_folder(self, folder, return_proba=False, verbose=0):
        &#34;&#34;&#34;
        ```
        Predicts the classes of all images in a folder.
        If return_proba is True, returns probabilities of each class.
        ```

        &#34;&#34;&#34;
        if not os.path.isdir(folder):
            raise ValueError(&#34;folder must be valid directory&#34;)
        (generator, steps) = self.preproc.preprocess(folder, batch_size=self.batch_size)
        result = self.predict_generator(
            generator, steps=steps, return_proba=return_proba, verbose=verbose
        )
        if len(result) != len(generator.filenames):
            raise Exception(&#34;number of results does not equal number of filenames&#34;)
        return list(zip(generator.filenames, result))

    def predict_generator(self, generator, steps=None, return_proba=False, verbose=0):
        # loss = self.model.loss
        # if callable(loss): loss = loss.__name__
        # treat_multilabel = False
        # if loss != &#39;categorical_crossentropy&#39; and not return_proba:
        #    return_proba=True
        #    treat_multilabel = True
        classification, multilabel = U.is_classifier(self.model)
        if not classification:
            return_proba = True
        # *_generator methods are deprecated from TF 2.1.0
        # preds =  self.model.predict_generator(generator, steps=steps)
        preds = self.model.predict(generator, steps=steps, verbose=verbose)
        result = (
            preds
            if return_proba or multilabel
            else [self.c[np.argmax(pred)] for pred in preds]
        )
        if multilabel and not return_proba:
            return [list(zip(self.c, r)) for r in result]
        if not classification:
            return np.squeeze(result, axis=1)
        else:
            return result

    def predict_proba(self, data, verbose=0):
        return self.predict(data, return_proba=True, verbose=verbose)

    def predict_proba_folder(self, folder, verbose=0):
        return self.predict_folder(folder, return_proba=True, verbose=verbose)

    def predict_proba_filename(self, img_path, verbose=0):
        return self.predict_filename(img_path, return_proba=True, verbose=verbose)

    def predict_proba_generator(self, generator, steps=None, verbose=0):
        return self.predict_proba_generator(
            generator, steps=steps, return_proba=True, verbose=verbose
        )

    def analyze_valid(self, generator, print_report=True, multilabel=None):
        &#34;&#34;&#34;
        ```
        Makes predictions on validation set and returns the confusion matrix.
        Accepts as input a genrator (e.g., DirectoryIterator, DataframeIterator)
        representing the validation set.


        Optionally prints a classification report.
        Currently, this method is only supported for binary and multiclass
        problems, not multilabel classification problems.
        ```
        &#34;&#34;&#34;
        if multilabel is None:
            multilabel = U.is_multilabel(generator)
        if multilabel:
            warnings.warn(&#34;multilabel_confusion_matrix not yet supported - skipping&#34;)
            return

        y_true = generator.classes
        # *_generator methods are deprecated from TF 2.1.0
        # y_pred = self.model.predict_generator(generator)
        y_pred = self.model.predict(generator)
        y_pred = np.argmax(y_pred, axis=1)
        if print_report:
            print(classification_report(y_true, y_pred, target_names=self.c))
        if not multilabel:
            cm_func = confusion_matrix
            cm = cm_func(y_true, y_pred)
        else:
            cm = None
        return cm

    def _save_preproc(self, fpath):
        preproc_name = &#34;tf_model.preproc&#34;
        with open(os.path.join(fpath, preproc_name), &#34;wb&#34;) as f:
            datagen = self.preproc.get_preprocessor()
            pfunc = datagen.preprocessing_function
            datagen.preprocessing_function = None
            pickle.dump(self.preproc, f)
            datagen.preprocessing_function = pfunc
        return</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ktrain.predictor.Predictor" href="../predictor.html#ktrain.predictor.Predictor">Predictor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ktrain.vision.ImagePredictor.analyze_valid"><code class="name flex">
<span>def <span class="ident">analyze_valid</span></span>(<span>self, generator, print_report=True, multilabel=None)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Makes predictions on validation set and returns the confusion matrix.
Accepts as input a genrator (e.g., DirectoryIterator, DataframeIterator)
representing the validation set.


Optionally prints a classification report.
Currently, this method is only supported for binary and multiclass
problems, not multilabel classification problems.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def analyze_valid(self, generator, print_report=True, multilabel=None):
    &#34;&#34;&#34;
    ```
    Makes predictions on validation set and returns the confusion matrix.
    Accepts as input a genrator (e.g., DirectoryIterator, DataframeIterator)
    representing the validation set.


    Optionally prints a classification report.
    Currently, this method is only supported for binary and multiclass
    problems, not multilabel classification problems.
    ```
    &#34;&#34;&#34;
    if multilabel is None:
        multilabel = U.is_multilabel(generator)
    if multilabel:
        warnings.warn(&#34;multilabel_confusion_matrix not yet supported - skipping&#34;)
        return

    y_true = generator.classes
    # *_generator methods are deprecated from TF 2.1.0
    # y_pred = self.model.predict_generator(generator)
    y_pred = self.model.predict(generator)
    y_pred = np.argmax(y_pred, axis=1)
    if print_report:
        print(classification_report(y_true, y_pred, target_names=self.c))
    if not multilabel:
        cm_func = confusion_matrix
        cm = cm_func(y_true, y_pred)
    else:
        cm = None
    return cm</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.explain"><code class="name flex">
<span>def <span class="ident">explain</span></span>(<span>self, img_fpath)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Highlights image to explain prediction
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def explain(self, img_fpath):
    &#34;&#34;&#34;
    ```
    Highlights image to explain prediction
    ```
    &#34;&#34;&#34;
    try:
        import eli5
    except:
        msg = (
            &#34;ktrain requires a forked version of eli5 to support tf.keras. &#34;
            + &#34;Install with: pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip&#34;
        )
        warnings.warn(msg)
        return

    if not DISABLE_V2_BEHAVIOR:
        warnings.warn(
            &#34;Please add os.environ[&#39;DISABLE_V2_BEHAVIOR&#39;] = &#39;1&#39; at top of your script or notebook.&#34;
        )
        msg = (
            &#34;\nFor image classification, the explain method currently requires disabling V2 behavior in TensorFlow 2.\n&#34;
            + &#34;Please add the following to the top of your script or notebook BEFORE you import ktrain and restart Colab runtime or Jupyter kernel:\n\n&#34;
            + &#34;import os\n&#34;
            + &#34;os.environ[&#39;DISABLE_V2_BEHAVIOR&#39;] = &#39;1&#39;\n&#34;
        )
        print(msg)
        return

    img = keras.preprocessing.image.load_img(
        img_fpath,
        target_size=self.preproc.target_size,
        color_mode=self.preproc.color_mode,
    )
    x = keras.preprocessing.image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    return eli5.show_prediction(self.model, x)</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.get_classes"><code class="name flex">
<span>def <span class="ident">get_classes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_classes(self):
    return self.c</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, data, return_proba=False, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Predicts class from image in array format.
If return_proba is True, returns probabilities of each class.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, data, return_proba=False, verbose=0):
    &#34;&#34;&#34;
    ```
    Predicts class from image in array format.
    If return_proba is True, returns probabilities of each class.
    ```
    &#34;&#34;&#34;
    if not isinstance(data, np.ndarray):
        raise ValueError(&#34;data must be numpy.ndarray&#34;)
    (generator, steps) = self.preproc.preprocess(data, batch_size=self.batch_size)
    return self.predict_generator(
        generator, steps=steps, return_proba=return_proba, verbose=verbose
    )</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict_filename"><code class="name flex">
<span>def <span class="ident">predict_filename</span></span>(<span>self, img_path, return_proba=False, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Predicts class from filepath to single image file.
If return_proba is True, returns probabilities of each class.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_filename(self, img_path, return_proba=False, verbose=0):
    &#34;&#34;&#34;
    ```
    Predicts class from filepath to single image file.
    If return_proba is True, returns probabilities of each class.
    ```
    &#34;&#34;&#34;
    if not os.path.isfile(img_path):
        raise ValueError(&#34;img_path must be valid file&#34;)
    (generator, steps) = self.preproc.preprocess(
        img_path, batch_size=self.batch_size
    )
    return self.predict_generator(
        generator, steps=steps, return_proba=return_proba, verbose=verbose
    )</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict_folder"><code class="name flex">
<span>def <span class="ident">predict_folder</span></span>(<span>self, folder, return_proba=False, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><pre><code>Predicts the classes of all images in a folder.
If return_proba is True, returns probabilities of each class.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_folder(self, folder, return_proba=False, verbose=0):
    &#34;&#34;&#34;
    ```
    Predicts the classes of all images in a folder.
    If return_proba is True, returns probabilities of each class.
    ```

    &#34;&#34;&#34;
    if not os.path.isdir(folder):
        raise ValueError(&#34;folder must be valid directory&#34;)
    (generator, steps) = self.preproc.preprocess(folder, batch_size=self.batch_size)
    result = self.predict_generator(
        generator, steps=steps, return_proba=return_proba, verbose=verbose
    )
    if len(result) != len(generator.filenames):
        raise Exception(&#34;number of results does not equal number of filenames&#34;)
    return list(zip(generator.filenames, result))</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict_generator"><code class="name flex">
<span>def <span class="ident">predict_generator</span></span>(<span>self, generator, steps=None, return_proba=False, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_generator(self, generator, steps=None, return_proba=False, verbose=0):
    # loss = self.model.loss
    # if callable(loss): loss = loss.__name__
    # treat_multilabel = False
    # if loss != &#39;categorical_crossentropy&#39; and not return_proba:
    #    return_proba=True
    #    treat_multilabel = True
    classification, multilabel = U.is_classifier(self.model)
    if not classification:
        return_proba = True
    # *_generator methods are deprecated from TF 2.1.0
    # preds =  self.model.predict_generator(generator, steps=steps)
    preds = self.model.predict(generator, steps=steps, verbose=verbose)
    result = (
        preds
        if return_proba or multilabel
        else [self.c[np.argmax(pred)] for pred in preds]
    )
    if multilabel and not return_proba:
        return [list(zip(self.c, r)) for r in result]
    if not classification:
        return np.squeeze(result, axis=1)
    else:
        return result</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict_proba"><code class="name flex">
<span>def <span class="ident">predict_proba</span></span>(<span>self, data, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_proba(self, data, verbose=0):
    return self.predict(data, return_proba=True, verbose=verbose)</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict_proba_filename"><code class="name flex">
<span>def <span class="ident">predict_proba_filename</span></span>(<span>self, img_path, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_proba_filename(self, img_path, verbose=0):
    return self.predict_filename(img_path, return_proba=True, verbose=verbose)</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict_proba_folder"><code class="name flex">
<span>def <span class="ident">predict_proba_folder</span></span>(<span>self, folder, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_proba_folder(self, folder, verbose=0):
    return self.predict_folder(folder, return_proba=True, verbose=verbose)</code></pre>
</details>
</dd>
<dt id="ktrain.vision.ImagePredictor.predict_proba_generator"><code class="name flex">
<span>def <span class="ident">predict_proba_generator</span></span>(<span>self, generator, steps=None, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_proba_generator(self, generator, steps=None, verbose=0):
    return self.predict_proba_generator(
        generator, steps=steps, return_proba=True, verbose=verbose
    )</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ktrain.predictor.Predictor" href="../predictor.html#ktrain.predictor.Predictor">Predictor</a></b></code>:
<ul class="hlist">
<li><code><a title="ktrain.predictor.Predictor.create_onnx_session" href="../predictor.html#ktrain.predictor.Predictor.create_onnx_session">create_onnx_session</a></code></li>
<li><code><a title="ktrain.predictor.Predictor.export_model_to_onnx" href="../predictor.html#ktrain.predictor.Predictor.export_model_to_onnx">export_model_to_onnx</a></code></li>
<li><code><a title="ktrain.predictor.Predictor.export_model_to_tflite" href="../predictor.html#ktrain.predictor.Predictor.export_model_to_tflite">export_model_to_tflite</a></code></li>
<li><code><a title="ktrain.predictor.Predictor.save" href="../predictor.html#ktrain.predictor.Predictor.save">save</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ktrain" href="../index.html">ktrain</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="ktrain.vision.caption" href="caption/index.html">ktrain.vision.caption</a></code></li>
<li><code><a title="ktrain.vision.data" href="data.html">ktrain.vision.data</a></code></li>
<li><code><a title="ktrain.vision.learner" href="learner.html">ktrain.vision.learner</a></code></li>
<li><code><a title="ktrain.vision.models" href="models.html">ktrain.vision.models</a></code></li>
<li><code><a title="ktrain.vision.object_detection" href="object_detection/index.html">ktrain.vision.object_detection</a></code></li>
<li><code><a title="ktrain.vision.predictor" href="predictor.html">ktrain.vision.predictor</a></code></li>
<li><code><a title="ktrain.vision.preprocessor" href="preprocessor.html">ktrain.vision.preprocessor</a></code></li>
<li><code><a title="ktrain.vision.wrn" href="wrn.html">ktrain.vision.wrn</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ktrain.vision.get_data_aug" href="#ktrain.vision.get_data_aug">get_data_aug</a></code></li>
<li><code><a title="ktrain.vision.image_classifier" href="#ktrain.vision.image_classifier">image_classifier</a></code></li>
<li><code><a title="ktrain.vision.image_regression_model" href="#ktrain.vision.image_regression_model">image_regression_model</a></code></li>
<li><code><a title="ktrain.vision.images_from_array" href="#ktrain.vision.images_from_array">images_from_array</a></code></li>
<li><code><a title="ktrain.vision.images_from_csv" href="#ktrain.vision.images_from_csv">images_from_csv</a></code></li>
<li><code><a title="ktrain.vision.images_from_fname" href="#ktrain.vision.images_from_fname">images_from_fname</a></code></li>
<li><code><a title="ktrain.vision.images_from_folder" href="#ktrain.vision.images_from_folder">images_from_folder</a></code></li>
<li><code><a title="ktrain.vision.preprocess_csv" href="#ktrain.vision.preprocess_csv">preprocess_csv</a></code></li>
<li><code><a title="ktrain.vision.preview_data_aug" href="#ktrain.vision.preview_data_aug">preview_data_aug</a></code></li>
<li><code><a title="ktrain.vision.print_image_classifiers" href="#ktrain.vision.print_image_classifiers">print_image_classifiers</a></code></li>
<li><code><a title="ktrain.vision.print_image_regression_models" href="#ktrain.vision.print_image_regression_models">print_image_regression_models</a></code></li>
<li><code><a title="ktrain.vision.show_image" href="#ktrain.vision.show_image">show_image</a></code></li>
<li><code><a title="ktrain.vision.show_random_images" href="#ktrain.vision.show_random_images">show_random_images</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ktrain.vision.ImagePredictor" href="#ktrain.vision.ImagePredictor">ImagePredictor</a></code></h4>
<ul class="">
<li><code><a title="ktrain.vision.ImagePredictor.analyze_valid" href="#ktrain.vision.ImagePredictor.analyze_valid">analyze_valid</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.explain" href="#ktrain.vision.ImagePredictor.explain">explain</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.get_classes" href="#ktrain.vision.ImagePredictor.get_classes">get_classes</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict" href="#ktrain.vision.ImagePredictor.predict">predict</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict_filename" href="#ktrain.vision.ImagePredictor.predict_filename">predict_filename</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict_folder" href="#ktrain.vision.ImagePredictor.predict_folder">predict_folder</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict_generator" href="#ktrain.vision.ImagePredictor.predict_generator">predict_generator</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict_proba" href="#ktrain.vision.ImagePredictor.predict_proba">predict_proba</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict_proba_filename" href="#ktrain.vision.ImagePredictor.predict_proba_filename">predict_proba_filename</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict_proba_folder" href="#ktrain.vision.ImagePredictor.predict_proba_folder">predict_proba_folder</a></code></li>
<li><code><a title="ktrain.vision.ImagePredictor.predict_proba_generator" href="#ktrain.vision.ImagePredictor.predict_proba_generator">predict_proba_generator</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>